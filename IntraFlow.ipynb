{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字段数据行数和缺失值统计结果:\n",
      "                data_rows  missing_values\n",
      "Field Name                               \n",
      "FieldID          11613323               0\n",
      "PaperID          11613323               0\n",
      "Citation_Count   11613323               0\n",
      "C_f              11613320               3\n",
      "Year             11613320               3\n",
      "Team_size        11613156             167\n",
      "IMCft             9399247         2214076\n",
      "IMCp              9115777         2497546\n",
      "C5                8528029         3085294\n",
      "Disruption        6901701         4711622\n",
      "C10               5688842         5924481\n",
      "SB_B              4189479         7423844\n",
      "SB_T              4189479         7423844\n",
      "Atyp_Median_Z     3797147         7816176\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Merged_IMC_多字段.tsv'  # 替换为你的文件路径\n",
    "\n",
    "def analyze_tsv_file(file_path):\n",
    "    \"\"\"\n",
    "    分析大型 TSV 文件，统计每个字段的数据行数和缺失值数量。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV 文件的路径。\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 包含字段分析结果的 DataFrame。\n",
    "    \"\"\"\n",
    "\n",
    "    column_data = {}  # 存储每列的数据行数和缺失值数量\n",
    "\n",
    "    try:\n",
    "        # 使用 chunksize 分块读取大型 TSV 文件，避免一次性加载到内存\n",
    "        chunk_size = 100000  # 可以根据内存情况调整 chunk 大小\n",
    "        tsv_reader = pd.read_csv(file_path, sep='\\t', chunksize=chunk_size, iterator=True)\n",
    "\n",
    "        for chunk_df in tsv_reader:\n",
    "            for column in chunk_df.columns:\n",
    "                if column not in column_data:\n",
    "                    column_data[column] = {'total_rows': 0, 'missing_values': 0}\n",
    "\n",
    "                column_data[column]['total_rows'] += chunk_df[column].count()  # 统计非缺失值行数\n",
    "                column_data[column]['missing_values'] += chunk_df[column].isnull().sum() # 统计缺失值行数\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"文件未找到，请检查文件路径是否正确。\"\n",
    "    except Exception as e:\n",
    "        return f\"读取文件时发生错误: {e}\"\n",
    "\n",
    "    # 将结果转换为 DataFrame 方便展示\n",
    "    results_df = pd.DataFrame.from_dict(column_data, orient='index')\n",
    "    results_df['data_rows'] = results_df['total_rows']  # 更直观的列名\n",
    "    results_df = results_df[['data_rows', 'missing_values']] # 调整列顺序\n",
    "    results_df.index.name = 'Field Name' # 设置索引列名\n",
    "    results_df = results_df.sort_values(by='data_rows', ascending=False) # 按数据行数排序\n",
    "\n",
    "    return results_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analysis_result = analyze_tsv_file(file_path)\n",
    "\n",
    "    if isinstance(analysis_result, str):\n",
    "        print(analysis_result) # 打印错误信息\n",
    "    else:\n",
    "        print(\"字段数据行数和缺失值统计结果:\")\n",
    "        print(analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件中唯一的 PaperID 总共有: 9399247 个\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r'D:\\BaiduNetdiskDownload\\SciSci\\2-IMC Calculate\\Corrected_Paper_Field_Citing_With_FieldID.tsv' # 使用 raw string 避免路径问题\n",
    "\n",
    "def count_unique_paper_ids(file_path):\n",
    "    \"\"\"\n",
    "    检查 TSV 文件，统计唯一 PaperID 的数量，并处理大型文件。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV 文件的完整路径。\n",
    "\n",
    "    Returns:\n",
    "        int: 唯一 PaperID 的数量。\n",
    "        str: 如果发生错误，则返回错误信息字符串。\n",
    "    \"\"\"\n",
    "    unique_paper_ids = set() # 使用 set 存储唯一的 PaperID，提高效率\n",
    "\n",
    "    try:\n",
    "        chunk_size = 100000  # 分块大小，可以根据内存调整\n",
    "        tsv_reader = pd.read_csv(file_path, sep='\\t', chunksize=chunk_size, iterator=True)\n",
    "\n",
    "        for chunk_df in tsv_reader:\n",
    "            # 将当前 chunk 的 PaperID 列的唯一值添加到 set 中\n",
    "            unique_paper_ids.update(chunk_df['PaperID'].unique())\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"文件未找到，请检查文件路径是否正确。\"\n",
    "    except Exception as e:\n",
    "        return f\"读取文件时发生错误: {e}\"\n",
    "\n",
    "    return len(unique_paper_ids)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unique_count_result = count_unique_paper_ids(file_path)\n",
    "\n",
    "    if isinstance(unique_count_result, str):\n",
    "        print(unique_count_result) # 打印错误信息\n",
    "    else:\n",
    "        print(f\"文件中唯一的 PaperID 总共有: {unique_count_result} 个\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文件大小: 11.68 GB\n",
      "开始处理文件...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:   8%|▊         | 10/125 [00:08<01:38,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 10,000,000 行，保留 4,325,638 行第一作者数据\n",
      "处理速度: 1154908 行/秒, 已用时间: 8.7 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:  16%|█▌        | 20/125 [00:17<01:40,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 20,000,000 行，保留 9,187,135 行第一作者数据\n",
      "处理速度: 1137428 行/秒, 已用时间: 17.6 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:  24%|██▍       | 30/125 [00:27<01:34,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 30,000,000 行，保留 13,123,306 行第一作者数据\n",
      "处理速度: 1102762 行/秒, 已用时间: 27.2 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:  32%|███▏      | 40/125 [00:35<01:13,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 40,000,000 行，保留 16,743,867 行第一作者数据\n",
      "处理速度: 1113218 行/秒, 已用时间: 35.9 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:  40%|████      | 50/125 [00:44<01:05,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 50,000,000 行，保留 19,844,291 行第一作者数据\n",
      "处理速度: 1114520 行/秒, 已用时间: 44.9 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:  48%|████▊     | 60/125 [00:53<00:57,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 60,000,000 行，保留 22,926,627 行第一作者数据\n",
      "处理速度: 1119209 行/秒, 已用时间: 53.6 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:  56%|█████▌    | 70/125 [01:02<00:46,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 70,000,000 行，保留 26,004,150 行第一作者数据\n",
      "处理速度: 1124550 行/秒, 已用时间: 62.2 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:  64%|██████▍   | 80/125 [01:11<00:39,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 80,000,000 行，保留 29,079,900 行第一作者数据\n",
      "处理速度: 1123341 行/秒, 已用时间: 71.2 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:  72%|███████▏  | 90/125 [01:20<00:31,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 90,000,000 行，保留 32,163,237 行第一作者数据\n",
      "处理速度: 1124488 行/秒, 已用时间: 80.0 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:  80%|████████  | 100/125 [01:28<00:20,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 100,000,000 行，保留 35,241,521 行第一作者数据\n",
      "处理速度: 1129513 行/秒, 已用时间: 88.5 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:  88%|████████▊ | 110/125 [01:37<00:13,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 110,000,000 行，保留 38,321,750 行第一作者数据\n",
      "处理速度: 1132620 行/秒, 已用时间: 97.1 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:  96%|█████████▌| 120/125 [01:46<00:04,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 120,000,000 行，保留 41,393,405 行第一作者数据\n",
      "处理速度: 1131693 行/秒, 已用时间: 106.0 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 130it [01:54,  1.15it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 130,000,000 行，保留 44,473,627 行第一作者数据\n",
      "处理速度: 1132644 行/秒, 已用时间: 114.8 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 140it [02:03,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 140,000,000 行，保留 47,553,417 行第一作者数据\n",
      "处理速度: 1136444 行/秒, 已用时间: 123.2 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 150it [02:11,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 150,000,000 行，保留 50,637,000 行第一作者数据\n",
      "处理速度: 1137210 行/秒, 已用时间: 131.9 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 160it [02:20,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 160,000,000 行，保留 53,328,426 行第一作者数据\n",
      "处理速度: 1141214 行/秒, 已用时间: 140.2 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 170it [02:28,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 170,000,000 行，保留 55,959,880 行第一作者数据\n",
      "处理速度: 1145038 行/秒, 已用时间: 148.5 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 180it [02:36,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 180,000,000 行，保留 58,581,145 行第一作者数据\n",
      "处理速度: 1151068 行/秒, 已用时间: 156.4 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 190it [02:45,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 190,000,000 行，保留 61,272,028 行第一作者数据\n",
      "处理速度: 1150040 行/秒, 已用时间: 165.2 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 200it [02:53,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 200,000,000 行，保留 64,743,109 行第一作者数据\n",
      "处理速度: 1151364 行/秒, 已用时间: 173.7 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 210it [03:02,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 210,000,000 行，保留 68,424,017 行第一作者数据\n",
      "处理速度: 1149575 行/秒, 已用时间: 182.7 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 220it [03:11,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 220,000,000 行，保留 72,424,429 行第一作者数据\n",
      "处理速度: 1147995 行/秒, 已用时间: 191.6 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 230it [03:23,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 230,000,000 行，保留 79,061,220 行第一作者数据\n",
      "处理速度: 1131091 行/秒, 已用时间: 203.3 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 240it [03:31,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 240,000,000 行，保留 82,855,680 行第一作者数据\n",
      "处理速度: 1133849 行/秒, 已用时间: 211.7 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 250it [03:40,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 250,000,000 行，保留 87,194,764 行第一作者数据\n",
      "处理速度: 1131900 行/秒, 已用时间: 220.9 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 260it [03:49,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 260,000,000 行，保留 90,741,009 行第一作者数据\n",
      "处理速度: 1132571 行/秒, 已用时间: 229.6 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 270it [03:57,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 270,000,000 行，保留 93,782,410 行第一作者数据\n",
      "处理速度: 1136024 行/秒, 已用时间: 237.7 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 280it [04:05,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 280,000,000 行，保留 96,985,249 行第一作者数据\n",
      "处理速度: 1139191 行/秒, 已用时间: 245.8 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 290it [04:14,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 290,000,000 行，保留 99,911,194 行第一作者数据\n",
      "处理速度: 1141223 行/秒, 已用时间: 254.1 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 300it [04:22,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 300,000,000 行，保留 103,116,078 行第一作者数据\n",
      "处理速度: 1143459 行/秒, 已用时间: 262.4 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 310it [04:30,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 310,000,000 行，保留 105,970,459 行第一作者数据\n",
      "处理速度: 1145330 行/秒, 已用时间: 270.7 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 320it [04:38,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 320,000,000 行，保留 109,020,891 行第一作者数据\n",
      "处理速度: 1148059 行/秒, 已用时间: 278.7 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 330it [04:46,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 330,000,000 行，保留 111,995,396 行第一作者数据\n",
      "处理速度: 1150736 行/秒, 已用时间: 286.8 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 340it [04:54,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 340,000,000 行，保留 114,964,118 行第一作者数据\n",
      "处理速度: 1153876 行/秒, 已用时间: 294.7 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 350it [05:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 350,000,000 行，保留 117,969,681 行第一作者数据\n",
      "处理速度: 1158690 行/秒, 已用时间: 302.1 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 360it [05:10,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 360,000,000 行，保留 120,805,782 行第一作者数据\n",
      "处理速度: 1157776 行/秒, 已用时间: 310.9 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 370it [05:18,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 370,000,000 行，保留 123,583,653 行第一作者数据\n",
      "处理速度: 1161451 行/秒, 已用时间: 318.6 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 380it [05:25,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 380,000,000 行，保留 126,300,383 行第一作者数据\n",
      "处理速度: 1166357 行/秒, 已用时间: 325.8 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 390it [05:33,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 390,000,000 行，保留 129,352,800 行第一作者数据\n",
      "处理速度: 1169044 行/秒, 已用时间: 333.6 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 400it [05:41,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 400,000,000 行，保留 132,124,317 行第一作者数据\n",
      "处理速度: 1170396 行/秒, 已用时间: 341.8 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 410it [05:48,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已处理 410,000,000 行，保留 134,807,027 行第一作者数据\n",
      "处理速度: 1175137 行/秒, 已用时间: 348.9 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 414it [05:51,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理完成！结果已保存到: G:\\SciSciNet\\SciSciNet_PaperAuthorAffiliations_FirstAuthor.tsv\n",
      "总行数: 413,869,501\n",
      "保留的第一作者行数: 135,827,039 (32.82%)\n",
      "处理时间: 351.7 秒 (5.9 分钟)\n",
      "输入文件大小: 11.68 GB\n",
      "输出文件大小: 3.84 GB\n",
      "文件大小减少了: 67.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 文件路径\n",
    "input_file = r\"G:\\SciSciNet\\SciSciNet_PaperAuthorAffiliations.tsv\"\n",
    "output_file = r\"G:\\SciSciNet\\SciSciNet_PaperAuthorAffiliations_FirstAuthor.tsv\"\n",
    "\n",
    "# 获取文件大小\n",
    "file_size = os.path.getsize(input_file)\n",
    "print(f\"原始文件大小: {file_size / (1024**3):.2f} GB\")\n",
    "\n",
    "# 设置块大小\n",
    "chunk_size = 1000000  # 每次读取100万行，可根据可用内存调整\n",
    "\n",
    "# 计数器\n",
    "total_rows = 0\n",
    "first_author_rows = 0\n",
    "\n",
    "# 开始计时\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # 分块处理文件\n",
    "    print(\"开始处理文件...\")\n",
    "    \n",
    "    # 处理文件\n",
    "    is_first_chunk = True\n",
    "    \n",
    "    # 使用tqdm创建进度条 - 估计总块数\n",
    "    estimated_chunks = max(1, file_size // (chunk_size * 100))  # 假设每行平均100字节\n",
    "    \n",
    "    for i, chunk in enumerate(tqdm(pd.read_csv(input_file, sep='\\t', chunksize=chunk_size), \n",
    "                               total=estimated_chunks, desc=\"处理进度\")):\n",
    "        # 更新计数器\n",
    "        chunk_rows = len(chunk)\n",
    "        total_rows += chunk_rows\n",
    "        \n",
    "        # 筛选出第一作者数据(AuthorSequenceNumber=1)\n",
    "        first_authors = chunk[chunk['AuthorSequenceNumber'] == 1]\n",
    "        first_author_rows += len(first_authors)\n",
    "        \n",
    "        # 写入到输出文件\n",
    "        mode = 'w' if is_first_chunk else 'a'\n",
    "        header = is_first_chunk\n",
    "        first_authors.to_csv(output_file, sep='\\t', index=False, mode=mode, header=header)\n",
    "        \n",
    "        # 更新标记\n",
    "        is_first_chunk = False\n",
    "        \n",
    "        # 每10个块显示一次统计信息\n",
    "        if (i + 1) % 10 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            speed = total_rows / elapsed if elapsed > 0 else 0\n",
    "            print(f\"\\n已处理 {total_rows:,} 行，保留 {first_author_rows:,} 行第一作者数据\")\n",
    "            print(f\"处理速度: {speed:.0f} 行/秒, 已用时间: {elapsed:.1f} 秒\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"处理过程中发生错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# 显示最终统计信息\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\n处理完成！结果已保存到: {output_file}\")\n",
    "print(f\"总行数: {total_rows:,}\")\n",
    "print(f\"保留的第一作者行数: {first_author_rows:,} ({first_author_rows/total_rows*100:.2f}%)\")\n",
    "print(f\"处理时间: {elapsed_time:.1f} 秒 ({elapsed_time/60:.1f} 分钟)\")\n",
    "\n",
    "# 显示文件大小统计\n",
    "if os.path.exists(output_file):\n",
    "    output_size = os.path.getsize(output_file)\n",
    "    print(f\"输入文件大小: {file_size / (1024**3):.2f} GB\")\n",
    "    print(f\"输出文件大小: {output_size / (1024**3):.2f} GB\")\n",
    "    print(f\"文件大小减少了: {(1 - output_size/file_size) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始预处理 SciSciNet_Papers.tsv 文件...\n",
      "SciSciNet_Papers.tsv 文件预处理完成，Series 大小: 134129188\n",
      "开始合并年份数据...\n",
      "数据合并完成，开始保存文件...\n",
      "文件保存完成。\n",
      "数据合并完成，已保存到：Corrected_Paper_Field_Citing_With_Year_Optimized.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "citing_file_path = r'Corrected_Paper_Field_Citing_With_FieldID.tsv' # 第一个文件路径，请确保路径正确\n",
    "papers_file_path = r'SciSciNet_Papers.tsv' # 大数据集文件路径，请确保路径正确\n",
    "output_file_path = os.path.join(os.path.dirname(citing_file_path), 'Corrected_Paper_Field_Citing_With_Year_Optimized.tsv') # 输出文件路径，与第一个文件同目录\n",
    "\n",
    "def merge_paper_years_optimized(citing_file_path, papers_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    将 Corrected_Paper_Field_Citing_With_FieldID.tsv 文件中的 PaperID 和 Citing_PaperID\n",
    "    与 SciSciNet_Papers.tsv 文件中的 Year 字段进行匹配，添加论文发表年份信息，并保存到新文件 (优化版 - 使用 set_index() 和 map()).\n",
    "\n",
    "    Args:\n",
    "        citing_file_path (str): 第一个 TSV 文件的路径 (Corrected_Paper_Field_Citing_With_FieldID.tsv)。\n",
    "        papers_file_path (str): 大数据集 TSV 文件的路径 (SciSciNet_Papers.tsv)。\n",
    "        output_file_path (str): 输出 TSV 文件的路径。\n",
    "\n",
    "    Returns:\n",
    "        str: 如果成功完成，返回 \"数据合并完成，已保存到：[输出文件路径]\"。\n",
    "             如果发生错误，返回错误信息字符串。\n",
    "    \"\"\"\n",
    "\n",
    "    paper_year_series = None # 用于存储 PaperID 为索引，Year 为值的 Series\n",
    "\n",
    "    try:\n",
    "        print(\"开始预处理 SciSciNet_Papers.tsv 文件...\")\n",
    "        chunk_size_papers = 100000  # 针对 SciSciNet_Papers.tsv 的分块大小\n",
    "        papers_reader = pd.read_csv(papers_file_path, sep='\\t', chunksize=chunk_size_papers, iterator=True, usecols=['PaperID', 'Year']) # 只读取需要的两列\n",
    "        paper_year_chunks = [] # 存储分块的 Series\n",
    "\n",
    "        for chunk_papers in papers_reader:\n",
    "            # 将每个数据块转换为以 PaperID 为索引，Year 为值的 Series\n",
    "            chunk_series = chunk_papers.set_index('PaperID')['Year']\n",
    "            paper_year_chunks.append(chunk_series)\n",
    "\n",
    "        # 将所有分块的 Series 合并为一个大的 Series\n",
    "        paper_year_series = pd.concat(paper_year_chunks)\n",
    "        print(\"SciSciNet_Papers.tsv 文件预处理完成，Series 大小:\", len(paper_year_series))\n",
    "\n",
    "\n",
    "        enriched_chunks = [] # 存储合并后的数据块\n",
    "\n",
    "        print(\"开始合并年份数据...\")\n",
    "        chunk_size_citing = 100000 # 针对 Corrected_Paper_Field_Citing_With_FieldID.tsv 的分块大小\n",
    "        citing_reader = pd.read_csv(citing_file_path, sep='\\t', chunksize=chunk_size_citing, iterator=True)\n",
    "\n",
    "        for chunk_citing in citing_reader:\n",
    "            # 使用 map() 函数高效查找并添加年份列\n",
    "            chunk_citing['PaperYear'] = chunk_citing['PaperID'].map(paper_year_series)\n",
    "            chunk_citing['CitingPaperYear'] = chunk_citing['Citing_PaperID'].map(paper_year_series)\n",
    "\n",
    "            enriched_chunks.append(chunk_citing)\n",
    "\n",
    "\n",
    "        enriched_df = pd.concat(enriched_chunks, ignore_index=True)\n",
    "\n",
    "        print(\"数据合并完成，开始保存文件...\")\n",
    "        enriched_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "        print(\"文件保存完成。\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"文件未找到，请检查文件路径是否正确。\"\n",
    "    except KeyError as e:\n",
    "        return f\"列名错误，请检查列名是否正确: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"处理文件时发生错误: {e}\"\n",
    "\n",
    "    return f\"数据合并完成，已保存到：{output_file_path}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_result = merge_paper_years_optimized(citing_file_path, papers_file_path, output_file_path)\n",
    "    print(merge_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各字段缺失值统计结果:\n",
      "                 missing_values\n",
      "Field Name                     \n",
      "CitingPaperYear              28\n",
      "PaperID                       0\n",
      "FieldID                       0\n",
      "Citing_PaperID                0\n",
      "Citing_FieldID                0\n",
      "PaperYear                     0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "output_file_path = os.path.join(os.path.dirname(r'D:\\BaiduNetdiskDownload\\SciSci\\2-IMC Calculate\\3 filed cited_citing\\Corrected_Paper_Field_Citing_With_FieldID.tsv'), 'Corrected_Paper_Field_Citing_With_Year_Optimized.tsv') #  请确保路径与实际输出文件路径一致\n",
    "\n",
    "def check_missing_values(file_path):\n",
    "    \"\"\"\n",
    "    检查 TSV 文件中各个字段的缺失值数量。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV 文件的路径。\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 包含每个字段缺失值统计结果的 DataFrame。\n",
    "        str: 如果发生错误，返回错误信息字符串。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 直接读取整个文件，因为这个文件应该是之前处理后的结果，大小可控\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "        missing_value_counts = {}\n",
    "        for column in df.columns:\n",
    "            missing_count = df[column].isnull().sum()\n",
    "            missing_value_counts[column] = missing_count\n",
    "\n",
    "        # 将结果转换为 DataFrame 方便展示\n",
    "        results_df = pd.DataFrame.from_dict(missing_value_counts, orient='index', columns=['missing_values'])\n",
    "        results_df.index.name = 'Field Name' # 设置索引列名\n",
    "        results_df = results_df.sort_values(by='missing_values', ascending=False) # 按缺失值数量排序\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"文件未找到，请检查文件路径是否正确。\"\n",
    "    except Exception as e:\n",
    "        return f\"读取文件时发生错误: {e}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    missing_value_result = check_missing_values(output_file_path)\n",
    "\n",
    "    if isinstance(missing_value_result, str):\n",
    "        print(missing_value_result) # 打印错误信息\n",
    "    else:\n",
    "        print(\"各字段缺失值统计结果:\")\n",
    "        print(missing_value_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始预处理 SciSciNet_Papers.tsv 文件...\n",
      "SciSciNet_Papers.tsv 文件预处理完成，Series 大小: 134129188\n",
      "开始合并年份数据...\n",
      "数据合并完成，开始保存文件...\n",
      "文件保存完成。\n",
      "数据合并完成，已保存到：Corrected_Paper_Field_Cited_With_Year_Optimized.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "citing_file_path = r'Corrected_Paper_Field_Cited_With_FieldID.tsv' # 第一个文件路径，请确保路径正确\n",
    "papers_file_path = r'SciSciNet_Papers.tsv' # 大数据集文件路径，请确保路径正确\n",
    "output_file_path = os.path.join(os.path.dirname(citing_file_path), 'Corrected_Paper_Field_Cited_With_Year_Optimized.tsv') # 输出文件路径，与第一个文件同目录\n",
    "\n",
    "def merge_paper_years_optimized(citing_file_path, papers_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    将 Corrected_Paper_Field_Citing_With_FieldID.tsv 文件中的 PaperID 和 Citing_PaperID\n",
    "    与 SciSciNet_Papers.tsv 文件中的 Year 字段进行匹配，添加论文发表年份信息，并保存到新文件 (优化版 - 使用 set_index() 和 map()).\n",
    "\n",
    "    Args:\n",
    "        citing_file_path (str): 第一个 TSV 文件的路径 (Corrected_Paper_Field_Citing_With_FieldID.tsv)。\n",
    "        papers_file_path (str): 大数据集 TSV 文件的路径 (SciSciNet_Papers.tsv)。\n",
    "        output_file_path (str): 输出 TSV 文件的路径。\n",
    "\n",
    "    Returns:\n",
    "        str: 如果成功完成，返回 \"数据合并完成，已保存到：[输出文件路径]\"。\n",
    "             如果发生错误，返回错误信息字符串。\n",
    "    \"\"\"\n",
    "\n",
    "    paper_year_series = None # 用于存储 PaperID 为索引，Year 为值的 Series\n",
    "\n",
    "    try:\n",
    "        print(\"开始预处理 SciSciNet_Papers.tsv 文件...\")\n",
    "        chunk_size_papers = 100000  # 针对 SciSciNet_Papers.tsv 的分块大小\n",
    "        papers_reader = pd.read_csv(papers_file_path, sep='\\t', chunksize=chunk_size_papers, iterator=True, usecols=['PaperID', 'Year']) # 只读取需要的两列\n",
    "        paper_year_chunks = [] # 存储分块的 Series\n",
    "\n",
    "        for chunk_papers in papers_reader:\n",
    "            # 将每个数据块转换为以 PaperID 为索引，Year 为值的 Series\n",
    "            chunk_series = chunk_papers.set_index('PaperID')['Year']\n",
    "            paper_year_chunks.append(chunk_series)\n",
    "\n",
    "        # 将所有分块的 Series 合并为一个大的 Series\n",
    "        paper_year_series = pd.concat(paper_year_chunks)\n",
    "        print(\"SciSciNet_Papers.tsv 文件预处理完成，Series 大小:\", len(paper_year_series))\n",
    "\n",
    "\n",
    "        enriched_chunks = [] # 存储合并后的数据块\n",
    "\n",
    "        print(\"开始合并年份数据...\")\n",
    "        chunk_size_citing = 100000 # 针对 Corrected_Paper_Field_Cited_With_FieldID.tsv 的分块大小\n",
    "        citing_reader = pd.read_csv(citing_file_path, sep='\\t', chunksize=chunk_size_citing, iterator=True)\n",
    "\n",
    "        for chunk_citing in citing_reader:\n",
    "            # 使用 map() 函数高效查找并添加年份列\n",
    "            chunk_citing['PaperYear'] = chunk_citing['PaperID'].map(paper_year_series)\n",
    "            chunk_citing['CitingPaperYear'] = chunk_citing['Cited_PaperID'].map(paper_year_series)\n",
    "\n",
    "            enriched_chunks.append(chunk_citing)\n",
    "\n",
    "\n",
    "        enriched_df = pd.concat(enriched_chunks, ignore_index=True)\n",
    "\n",
    "        print(\"数据合并完成，开始保存文件...\")\n",
    "        enriched_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "        print(\"文件保存完成。\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"文件未找到，请检查文件路径是否正确。\"\n",
    "    except KeyError as e:\n",
    "        return f\"列名错误，请检查列名是否正确: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"处理文件时发生错误: {e}\"\n",
    "\n",
    "    return f\"数据合并完成，已保存到：{output_file_path}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_result = merge_paper_years_optimized(citing_file_path, papers_file_path, output_file_path)\n",
    "    print(merge_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nfii 和 聚合 Nfji 值计算完成，已保存到：Paper_Nfii_Nfji_Values_Optimized_V3.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "file_path = 'Corrected_Paper_Field_Cited_With_Year_Optimized.tsv' # 替换为你的文件路径\n",
    "output_file_path = 'Paper_Nfii_Nfji_Values_Optimized_V3.tsv' # 输出文件路径\n",
    "\n",
    "def calculate_nfii_nfji_aggregated_v2(file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    计算 Corrected_Paper_Field_Cited_With_Year_Optimized.tsv 文件中每篇论文的 Nfii 和 聚合 Nfji 值，\n",
    "    仅考虑发表 5 年以内的引用 (优化版 V3 - 避免 groupby().apply(), 更高效向量化聚合).\n",
    "\n",
    "    Args:\n",
    "        file_path (str): 输入 TSV 文件的路径。\n",
    "        output_file_path (str): 输出 TSV 文件的路径。\n",
    "\n",
    "    Returns:\n",
    "        str: 如果成功完成，返回 \"Nfii 和 聚合 Nfji 值计算完成，已保存到：[输出文件路径]\"。\n",
    "             如果发生错误，返回错误信息字符串。\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    try:\n",
    "        chunk_size = 100000\n",
    "        tsv_reader = pd.read_csv(file_path, sep='\\t', chunksize=chunk_size, iterator=True)\n",
    "\n",
    "\n",
    "        for chunk in tsv_reader:\n",
    "            # 5-year citation window filtering (提前进行，chunk 级别)\n",
    "            valid_citations_chunk = chunk[\n",
    "                (chunk['PaperYear'] >= chunk['CitingPaperYear']) & (chunk['PaperYear'] <= chunk['CitingPaperYear'] + 5)\n",
    "            ].copy() # 显式 copy，避免 SettingWithCopyWarning\n",
    "\n",
    "            unique_cited_paper_ids = valid_citations_chunk['Cited_PaperID'].unique()\n",
    "\n",
    "            for cited_paper_id in unique_cited_paper_ids:\n",
    "                if pd.isna(cited_paper_id): # 跳过 NaN Cited_PaperID\n",
    "                    continue\n",
    "\n",
    "                cited_paper_data = valid_citations_chunk[valid_citations_chunk['Cited_PaperID'] == cited_paper_id]\n",
    "                if cited_paper_data.empty: # 理论上不应该为空，double check\n",
    "                    continue\n",
    "\n",
    "                cited_paper_field_id = cited_paper_data['Cited_FieldID'].iloc[0]\n",
    "                cited_paper_year = cited_paper_data['CitingPaperYear'].iloc[0] # CitingPaperYear is actually year of Cited_PaperID\n",
    "\n",
    "                if pd.isna(cited_paper_field_id) or pd.isna(cited_paper_year): # 检查缺失值\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # 向量化计算 Nfii 和 Nfji (无需 groupby().apply(), 直接在 chunk 内向量化)\n",
    "                nfii_count = (valid_citations_chunk['Cited_PaperID'] == cited_paper_id) & (valid_citations_chunk['FieldID'] == cited_paper_field_id)\n",
    "                nfii_sum_chunk = nfii_count.sum()\n",
    "\n",
    "\n",
    "                nfji_count = (valid_citations_chunk['Cited_PaperID'] == cited_paper_id) & (valid_citations_chunk['FieldID'] != cited_paper_field_id)\n",
    "                nfji_sum_chunk = nfji_count.sum()\n",
    "\n",
    "\n",
    "                results.append({\n",
    "                    'PaperID': cited_paper_id,\n",
    "                    'FieldID': cited_paper_field_id,\n",
    "                    'PaperYear': cited_paper_year,\n",
    "                    'Nfii': nfii_sum_chunk,\n",
    "                    'Nfji': nfji_sum_chunk\n",
    "                })\n",
    "\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"文件未找到，请检查文件路径是否正确。\"\n",
    "    except KeyError as e:\n",
    "        return f\"列名错误，请检查列名是否正确: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"处理文件时发生错误: {e}\"\n",
    "\n",
    "    return f\"Nfii 和 聚合 Nfji 值计算完成，已保存到：{output_file_path}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result_message = calculate_nfii_nfji_aggregated_v2(file_path, output_file_path)\n",
    "    print(result_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FieldID 列数据和频数统计结果:\n",
      "           frequency\n",
      "FieldID             \n",
      "41008148   101659629\n",
      "127413603   35910693\n",
      "162324750   31720120\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_path = 'Corrected_Paper_Field_Cited_With_Year_Optimized.tsv' # 替换为你的文件路径\n",
    "\n",
    "def analyze_fieldid_frequency(file_path):\n",
    "    \"\"\"\n",
    "    检查 Corrected_Paper_Field_Cited_With_Year_Optimized.tsv 文件中 FieldID 列的数据和频数。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): 输入 TSV 文件的路径。\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 包含 FieldID 数据和频数的 DataFrame。\n",
    "        str: 如果发生错误，返回错误信息字符串。\n",
    "    \"\"\"\n",
    "\n",
    "    fieldid_counts = {}\n",
    "\n",
    "    try:\n",
    "        chunk_size = 100000\n",
    "        tsv_reader = pd.read_csv(file_path, sep='\\t', chunksize=chunk_size, iterator=True, usecols=['FieldID']) # 只读取 FieldID 列\n",
    "\n",
    "        for chunk in tsv_reader:\n",
    "            fieldid_value_counts_chunk = chunk['FieldID'].value_counts() # 计算当前 chunk 的 FieldID 频数\n",
    "\n",
    "            for field_id, count in fieldid_value_counts_chunk.items():\n",
    "                fieldid_counts[field_id] = fieldid_counts.get(field_id, 0) + count # 累加频数\n",
    "\n",
    "        # 将结果转换为 DataFrame 方便展示\n",
    "        results_df = pd.DataFrame.from_dict(fieldid_counts, orient='index', columns=['frequency'])\n",
    "        results_df.index.name = 'FieldID' # 设置索引列名\n",
    "        results_df = results_df.sort_values(by='frequency', ascending=False) # 按频数降序排序\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"文件未找到，请检查文件路径是否正确。\"\n",
    "    except KeyError as e:\n",
    "        return f\"列名错误，请检查列名是否正确: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"处理文件时发生错误: {e}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    frequency_result = analyze_fieldid_frequency(file_path)\n",
    "\n",
    "    if isinstance(frequency_result, str):\n",
    "        print(frequency_result) # 打印错误信息\n",
    "    else:\n",
    "        print(\"FieldID 列数据和频数统计结果:\")\n",
    "        print(frequency_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nfii 和 聚合 Nfji 值计算完成，已保存到：Paper_Nfii_Nfji_Values_Final.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_path = 'Corrected_Paper_Field_Cited_With_Year_Optimized.tsv' # 替换为你的文件路径\n",
    "output_file_path = 'Paper_Nfii_Nfji_Values_Final.tsv' # 输出文件路径\n",
    "\n",
    "def calculate_nfii_nfji_final(file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    计算 Corrected_Paper_Field_Cited_With_Year_Optimized.tsv 文件中每篇论文的 Nfii 和 聚合 Nfji 值，\n",
    "    仅考虑发表 5 年以内的引用 (最终修正版 - 变量名更清晰, 修正 5 年窗口过滤条件).\n",
    "\n",
    "    Args:\n",
    "        file_path (str): 输入 TSV 文件的路径。\n",
    "        output_file_path (str): 输出 TSV 文件的路径。\n",
    "\n",
    "    Returns:\n",
    "        str: 如果成功完成，返回 \"Nfii 和 聚合 Nfji 值计算完成，已保存到：[输出文件路径]\"。\n",
    "             如果发生错误，返回错误信息字符串。\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    try:\n",
    "        chunk_size = 100000\n",
    "        tsv_reader = pd.read_csv(file_path, sep='\\t', chunksize=chunk_size, iterator=True)\n",
    "\n",
    "\n",
    "        for chunk in tsv_reader:\n",
    "            # 5-year citation window filtering (提前进行，chunk 级别) - **已修正过滤条件**\n",
    "            valid_citations_chunk = chunk[\n",
    "                (chunk['CitingPaperYear'] >= chunk['PaperYear']) & (chunk['CitingPaperYear'] <= chunk['PaperYear'] + 5)\n",
    "            ].copy() # 显式 copy，避免 SettingWithCopyWarning\n",
    "\n",
    "            unique_paper_ids = valid_citations_chunk['PaperID'].unique() # 使用 PaperID 作为被引论文 ID\n",
    "\n",
    "            for paper_id in unique_paper_ids: # 循环遍历被引论文 PaperID\n",
    "                if pd.isna(paper_id): # 跳过 NaN PaperID\n",
    "                    continue\n",
    "\n",
    "                paper_data = valid_citations_chunk[valid_citations_chunk['PaperID'] == paper_id] # 使用 PaperID 筛选\n",
    "                if paper_data.empty: # 理论上不应该为空，double check\n",
    "                    continue\n",
    "\n",
    "                paper_field_id = paper_data['FieldID'].iloc[0] # 被引论文的 FieldID\n",
    "                paper_year = paper_data['PaperYear'].iloc[0] # 被引论文的 PaperYear\n",
    "\n",
    "                if pd.isna(paper_field_id) or pd.isna(paper_year): # 检查缺失值\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # 向量化计算 Nfii 和 Nfji (无需 groupby().apply(), 直接在 chunk 内向量化) - 使用 PaperID 筛选\n",
    "                nfii_count = (paper_data['PaperID'] == paper_id) & (paper_data['Cited_FieldID'] == paper_field_id) # 使用 Cited_FieldID 和 paper_field_id 比较\n",
    "                nfii_sum_chunk = nfii_count.sum()\n",
    "\n",
    "\n",
    "                nfji_count = (paper_data['PaperID'] == paper_id) & (paper_data['Cited_FieldID'] != paper_field_id) # 使用 Cited_FieldID 和 paper_field_id 比较\n",
    "                nfji_sum_chunk = nfji_count.sum()\n",
    "\n",
    "\n",
    "                results.append({\n",
    "                    'PaperID': paper_id, # 输出 PaperID (被引论文 ID)\n",
    "                    'FieldID': paper_field_id, # 输出 FieldID (被引论文学科 ID)\n",
    "                    'PaperYear': paper_year, # 输出 PaperYear (被引论文发表年份)\n",
    "                    'Nfii': nfii_sum_chunk,\n",
    "                    'Nfji': nfji_sum_chunk\n",
    "                })\n",
    "\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"文件未找到，请检查文件路径是否正确。\"\n",
    "    except KeyError as e:\n",
    "        return f\"列名错误，请检查列名是否正确: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"处理文件时发生错误: {e}\"\n",
    "\n",
    "    return f\"Nfii 和 聚合 Nfji 值计算完成，已保存到：{output_file_path}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result_message = calculate_nfii_nfji_aggregated_v2(file_path, output_file_path) # 注意：这里调用的是最终修正版的函数名\n",
    "    print(result_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nfii 和 聚合 Nfji 值计算完成，已保存到：Paper_Nfii_Nfji_Values_Final_Corrected_V2.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_path = 'Corrected_Paper_Field_Cited_With_Year_Optimized.tsv' # 替换为你的文件路径\n",
    "output_file_path = 'Paper_Nfii_Nfji_Values_Final_Corrected_V2.tsv' # 输出文件路径\n",
    "\n",
    "def calculate_nfii_nfji_final_corrected_v2(file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    计算 Corrected_Paper_Field_Cited_With_Year_Optimized.tsv 文件中每篇论文的 Nfii 和 聚合 Nfji 值，\n",
    "    仅考虑发表 5 年以内的引用 (真正最终修正版 V2 - 变量名笔误修正).\n",
    "\n",
    "    Args:\n",
    "        file_path (str): 输入 TSV 文件的路径。\n",
    "        output_file_path (str): 输出 TSV 文件的路径。\n",
    "\n",
    "    Returns:\n",
    "        str: 如果成功完成，返回 \"Nfii 和 聚合 Nfji 值计算完成，已保存到：[输出文件路径]\"。\n",
    "             如果发生错误，返回错误信息字符串。\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    try:\n",
    "        chunk_size = 100000\n",
    "        tsv_reader = pd.read_csv(file_path, sep='\\t', chunksize=chunk_size, iterator=True)\n",
    "\n",
    "\n",
    "        for chunk in tsv_reader:\n",
    "            unique_paper_ids = chunk['PaperID'].unique() # 正确地循环遍历 PaperID (被引论文 ID)\n",
    "\n",
    "            for paper_id in unique_paper_ids: # 正确地以内循环 PaperID 为中心\n",
    "                if pd.isna(paper_id): # 跳过 NaN PaperID\n",
    "                    continue\n",
    "\n",
    "                paper_data = chunk[chunk['PaperID'] == paper_id] # 正确地筛选 PaperID 的数据 (所有引用 PaperID 的文献)\n",
    "                if paper_data.empty: # 理论上不应该为空，double check\n",
    "                    continue\n",
    "\n",
    "                paper_field_id = paper_data['FieldID'].iloc[0] # 被引论文的 FieldID\n",
    "                paper_year = paper_data['PaperYear'].iloc[0] # 被引论文的 PaperYear\n",
    "\n",
    "                if pd.isna(paper_field_id) or pd.isna(paper_year): # 检查缺失值\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # 5-year citation window filtering (提前进行，chunk 级别) - **已修正过滤条件 和 数据筛选**\n",
    "                valid_citations_chunk = paper_data[ # **基于 paper_data 进行 5 年窗口过滤**\n",
    "                    (paper_data['CitingPaperYear'] >= paper_year) & (paper_data['CitingPaperYear'] <= paper_year + 5)\n",
    "                ]\n",
    "\n",
    "                # 向量化计算 Nfii 和 Nfji (无需 groupby().apply(), 直接在 chunk 内向量化) - **基于 paper_data 和 valid_citations_chunk 计算**\n",
    "                nfii_count = (valid_citations_chunk['Cited_FieldID'] == paper_field_id).sum() # **基于 valid_citations_chunk 和 paper_field_id 比较**\n",
    "                nfji_count = len(valid_citations_chunk) - nfii_count # **基于 valid_citations_chunk 计算总数**\n",
    "\n",
    "\n",
    "                results.append({\n",
    "                    'PaperID': paper_id, # 输出 PaperID (被引论文 ID)\n",
    "                    'FieldID': paper_field_id, # 输出 FieldID (被引论文学科 ID)\n",
    "                    'PaperYear': paper_year, # 输出 PaperYear (被引论文发表年份)\n",
    "                    'Nfii': nfii_count, # **更正为 nfii_count**\n",
    "                    'Nfji': nfji_count # **更正为 nfji_count**\n",
    "                })\n",
    "\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"文件未找到，请检查文件路径是否正确。\"\n",
    "    except KeyError as e:\n",
    "        return f\"列名错误，请检查列名是否正确: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"处理文件时发生错误: {e}\"\n",
    "\n",
    "    return f\"Nfii 和 聚合 Nfji 值计算完成，已保存到：{output_file_path}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result_message = calculate_nfii_nfji_final_corrected_v2(file_path, output_file_path) # 注意：这里调用的是最终修正版的函数名\n",
    "    print(result_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功处理文件：Merged_IMC_多字段.tsv\n",
      "已覆盖原始文件。\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def remove_empty_quotes_in_tsv(input_filepath, output_filepath=None):\n",
    "    \"\"\"\n",
    "    读取 TSV 文件，将字段中的 \"\" 替换为空字符串，并写入新的 TSV 文件或覆盖原文件。\n",
    "\n",
    "    Args:\n",
    "        input_filepath (str): 输入 TSV 文件的路径。\n",
    "        output_filepath (str, optional): 输出 TSV 文件的路径。\n",
    "                                        如果为 None，则覆盖原始文件。默认为 None。\n",
    "    \"\"\"\n",
    "\n",
    "    if output_filepath is None:\n",
    "        output_filepath = input_filepath  # 默认覆盖原文件\n",
    "\n",
    "    try:\n",
    "        with open(input_filepath, 'r', encoding='utf-8') as infile, \\\n",
    "             open(output_filepath, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "            reader = csv.reader(infile, delimiter='\\t')  # 创建 TSV 读取器，分隔符为制表符\n",
    "            writer = csv.writer(outfile, delimiter='\\t', lineterminator='\\n') # 创建 TSV 写入器，分隔符为制表符，行尾符为换行符\n",
    "\n",
    "            for row in reader:\n",
    "                cleaned_row = []\n",
    "                for field in row:\n",
    "                    if field == \"\":\n",
    "                        cleaned_row.append(\"\")  # 将 \"\" 替换为空字符串\n",
    "                    else:\n",
    "                        cleaned_row.append(field)\n",
    "                writer.writerow(cleaned_row)\n",
    "\n",
    "        print(f\"成功处理文件：{input_filepath}\")\n",
    "        if output_filepath != input_filepath:\n",
    "            print(f\"结果已保存到：{output_filepath}\")\n",
    "        else:\n",
    "            print(\"已覆盖原始文件。\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：文件未找到：{input_filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生错误：{e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_tsv_file = \"Merged_IMC_多字段.tsv\"  # 请替换为你的 TSV 文件名\n",
    "    # 可以选择指定输出文件，或者留空 output_filepath 参数来覆盖原文件\n",
    "    # output_tsv_file = \"Merged_IMC_多字段_cleaned.tsv\"\n",
    "    # remove_empty_quotes_in_tsv(input_tsv_file, output_tsv_file)\n",
    "\n",
    "    remove_empty_quotes_in_tsv(input_tsv_file) # 覆盖原始文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_27644\\2059783378.py:7: DtypeWarning: Columns (2,3,4,5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep='\\t', keep_default_na=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "file_path = 'Merged_IMC_多字段.tsv'\n",
    "\n",
    "# 读取TSV文件，指定分隔符为制表符，并避免默认空值转换\n",
    "df = pd.read_csv(file_path, sep='\\t', keep_default_na=False)\n",
    "\n",
    "# 将所有字段中的空字符串\"\"替换为None\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: None if x == \"\" else x)\n",
    "\n",
    "# 保存处理后的数据回TSV文件，空值处不写入内容\n",
    "df.to_csv(file_path, sep='\\t', index=False, na_rep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字段数据行数和缺失值统计结果:\n",
      "                data_rows  missing_values\n",
      "Field Name                               \n",
      "FieldID          11613323               0\n",
      "PaperID          11613323               0\n",
      "Citation_Count   11613323               0\n",
      "C_f              11613320               3\n",
      "Year             11613320               3\n",
      "Team_size        11613156             167\n",
      "IMCft             9399247         2214076\n",
      "IMCp              9115777         2497546\n",
      "C5                8528029         3085294\n",
      "Disruption        6901701         4711622\n",
      "C10               5688842         5924481\n",
      "SB_B              4189479         7423844\n",
      "SB_T              4189479         7423844\n",
      "Atyp_Median_Z     3797147         7816176\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Merged_IMC_多字段.tsv'  # 替换为你的文件路径\n",
    "\n",
    "def analyze_tsv_file(file_path):\n",
    "    \"\"\"\n",
    "    分析大型 TSV 文件，统计每个字段的数据行数和缺失值数量。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV 文件的路径。\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 包含字段分析结果的 DataFrame。\n",
    "    \"\"\"\n",
    "\n",
    "    column_data = {}  # 存储每列的数据行数和缺失值数量\n",
    "\n",
    "    try:\n",
    "        # 使用 chunksize 分块读取大型 TSV 文件，避免一次性加载到内存\n",
    "        chunk_size = 100000  # 可以根据内存情况调整 chunk 大小\n",
    "        tsv_reader = pd.read_csv(file_path, sep='\\t', chunksize=chunk_size, iterator=True)\n",
    "\n",
    "        for chunk_df in tsv_reader:\n",
    "            for column in chunk_df.columns:\n",
    "                if column not in column_data:\n",
    "                    column_data[column] = {'total_rows': 0, 'missing_values': 0}\n",
    "\n",
    "                column_data[column]['total_rows'] += chunk_df[column].count()  # 统计非缺失值行数\n",
    "                column_data[column]['missing_values'] += chunk_df[column].isnull().sum() # 统计缺失值行数\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"文件未找到，请检查文件路径是否正确。\"\n",
    "    except Exception as e:\n",
    "        return f\"读取文件时发生错误: {e}\"\n",
    "\n",
    "    # 将结果转换为 DataFrame 方便展示\n",
    "    results_df = pd.DataFrame.from_dict(column_data, orient='index')\n",
    "    results_df['data_rows'] = results_df['total_rows']  # 更直观的列名\n",
    "    results_df = results_df[['data_rows', 'missing_values']] # 调整列顺序\n",
    "    results_df.index.name = 'Field Name' # 设置索引列名\n",
    "    results_df = results_df.sort_values(by='data_rows', ascending=False) # 按数据行数排序\n",
    "\n",
    "    return results_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analysis_result = analyze_tsv_file(file_path)\n",
    "\n",
    "    if isinstance(analysis_result, str):\n",
    "        print(analysis_result) # 打印错误信息\n",
    "    else:\n",
    "        print(\"字段数据行数和缺失值统计结果:\")\n",
    "        print(analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功将 C5 数据从 Merged_IMC_多字段.tsv 合并到 Paper_Nfii_Nfji_Values_Final_Corrected_V2.tsv，结果已保存到 Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_added.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def merge_c5_data(file1_path, file2_path, output_file_path):\n",
    "    \"\"\"\n",
    "    根据 PaperID 将 Merged_IMC_多字段.tsv 文件中的 C5 列填充到 Paper_Nfii_Nfji_Values_Final_Corrected_V2.tsv 文件中。\n",
    "\n",
    "    Args:\n",
    "        file1_path (str): Paper_Nfii_Nfji_Values_Final_Corrected_V2.tsv 文件的路径。\n",
    "        file2_path (str): Merged_IMC_多字段.tsv 文件的路径。\n",
    "        output_file_path (str): 输出文件的路径。\n",
    "    \"\"\"\n",
    "\n",
    "    c5_data_dict = {}  # 创建一个字典，用于存储 PaperID 和 C5 的对应关系\n",
    "\n",
    "    # 读取 Merged_IMC_多字段.tsv 文件并构建 PaperID 到 C5 的字典\n",
    "    try:\n",
    "        with open(file2_path, 'r', encoding='utf-8') as file2:\n",
    "            reader2 = csv.reader(file2, delimiter='\\t')\n",
    "            header2 = next(reader2, None)  # 读取并跳过 header 行，如果存在\n",
    "            if header2:\n",
    "                paper_id_col_index_2 = 1  # PaperID 在第二列 (索引为 1)\n",
    "                c5_col_index_2 = -1 # 假设 C5 是最后一列，需要根据实际情况调整，或者根据header查找列索引\n",
    "                if 'C5' in header2:\n",
    "                    c5_col_index_2 = header2.index('C5')\n",
    "                else:\n",
    "                    print(f\"警告: 文件 {file2_path} 的header中没有找到 'C5' 列，假设最后一列为C5，请检查文件结构。\")\n",
    "                    c5_col_index_2 = len(header2) - 1 if header2 else -1 # 如果有header，取最后一个，否则默认-1\n",
    "\n",
    "                if c5_col_index_2 == -1:\n",
    "                    print(f\"错误: 无法确定文件 {file2_path} 中的 'C5' 列位置，请检查文件结构和header。\")\n",
    "                    return\n",
    "\n",
    "            else: # 如果没有header，假设 PaperID 是第二列，C5 是最后一列，需要根据实际情况调整\n",
    "                paper_id_col_index_2 = 1\n",
    "                c5_col_index_2 = -1 # 假设 C5 是最后一列，需要根据实际情况调整\n",
    "\n",
    "            for row in reader2:\n",
    "                if len(row) > max(paper_id_col_index_2, c5_col_index_2) and row[paper_id_col_index_2].strip() and row[c5_col_index_2].strip(): # 确保行有足够的列，且 PaperID 和 C5 不为空\n",
    "                    try:\n",
    "                        paper_id = row[paper_id_col_index_2].strip() # 获取 PaperID 并去除空格\n",
    "                        c5_value = row[c5_col_index_2].strip()      # 获取 C5 值并去除空格\n",
    "                        c5_data_dict[paper_id] = c5_value\n",
    "                    except IndexError:\n",
    "                        print(f\"警告: 行数据列数不足，跳过: {row}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"警告: 处理行数据时发生错误: {row}, 错误信息: {e}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 {file2_path} 未找到，请检查文件路径。\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件 {file2_path} 时发生错误: {e}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # 读取 Paper_Nfii_Nfji_Values_Final_Corrected_V2.tsv 文件，并添加 C5 列\n",
    "    try:\n",
    "        with open(file1_path, 'r', encoding='utf-8') as file1, open(output_file_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "            reader1 = csv.reader(file1, delimiter='\\t')\n",
    "            writer = csv.writer(outfile, delimiter='\\t')\n",
    "\n",
    "            header1 = next(reader1, None) # 读取 file1 的 header\n",
    "            if header1:\n",
    "                updated_header = header1 + ['C5'] # 在 header 中添加 'C5' 列名\n",
    "                writer.writerow(updated_header) # 写入新的 header\n",
    "            else:\n",
    "                writer.writerow(['PaperID', 'FieldID', 'PaperYear', 'OtherField1', 'OtherField2', 'C5']) # 如果 file1 没有 header，则写入默认 header\n",
    "\n",
    "\n",
    "            paper_id_col_index_1 = 0  # PaperID 在第一列 (索引为 0)\n",
    "\n",
    "            for row in reader1:\n",
    "                if len(row) > paper_id_col_index_1 and row[paper_id_col_index_1].strip(): # 确保行有足够的列，且 PaperID 不为空\n",
    "                    paper_id = row[paper_id_col_index_1].strip() # 获取 PaperID 并去除空格\n",
    "                    c5_value = c5_data_dict.get(paper_id, '') # 从字典中查找 C5 值，如果找不到则默认为空字符串\n",
    "                    updated_row = row + [c5_value] # 将 C5 值添加到行尾\n",
    "                    writer.writerow(updated_row) # 写入更新后的行\n",
    "                else:\n",
    "                    print(f\"警告: 行数据列数不足或 PaperID 为空，跳过: {row}\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 {file1_path} 未找到，请检查文件路径。\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件 {file1_path} 时发生错误: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"已成功将 C5 数据从 {file2_path} 合并到 {file1_path}，结果已保存到 {output_file_path}\")\n",
    "\n",
    "\n",
    "# 定义文件路径和输出文件路径\n",
    "file1_path = \"Paper_Nfii_Nfji_Values_Final_Corrected_V2.tsv\"\n",
    "file2_path = \"Merged_IMC_多字段.tsv\"\n",
    "output_file_path = \"Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_added.tsv\" # 输出到新文件，可以根据需要修改\n",
    "\n",
    "# 调用函数执行合并操作\n",
    "merge_c5_data(file1_path, file2_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功计算 InTraFlowf 并保存到 Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_InTraFlowf.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def calculate_intraflowf_corrected(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    计算 InTraFlowf 指标并添加到 TSV 文件中，处理非数值类型和空值。\n",
    "\n",
    "    InTraFlowf = (Nfji + 1 - Nfii) / C5\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径 (Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_added.tsv).\n",
    "        output_file_path (str): 输出 TSV 文件路径 (例如 Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_InTraFlowf.tsv).\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as infile, \\\n",
    "             open(output_file_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "            reader = csv.reader(infile, delimiter='\\t')\n",
    "            writer = csv.writer(outfile, delimiter='\\t')\n",
    "\n",
    "            header = next(reader)  # 读取 header 行\n",
    "            updated_header = header + ['InTraFlowf']  # 添加 'InTraFlowf' 到 header\n",
    "            writer.writerow(updated_header)  # 写入新的 header\n",
    "\n",
    "            for row_index, row in enumerate(reader): # 使用 enumerate 获取行索引，方便错误信息定位\n",
    "                if len(row) >= 6:  # 确保行至少有 6 列 (PaperID, FieldID, PaperYear, Nfii, Nfji, C5)\n",
    "                    try:\n",
    "                        nfii_str = row[3].strip()  # Nfii 在第 4 列 (索引 3)\n",
    "                        nfji_str = row[4].strip()  # Nfji 在第 5 列 (索引 4)\n",
    "                        c5_str = row[5].strip()    # C5 在第 6 列 (索引 5)\n",
    "\n",
    "                        nfii = 0.0 # 默认值\n",
    "                        nfji = 0.0 # 默认值\n",
    "                        c5 = 0.0   # 默认值\n",
    "\n",
    "                        try:\n",
    "                            nfii = float(nfii_str) if nfii_str else 0.0 # 如果为空字符串则默认为0\n",
    "                        except ValueError:\n",
    "                            print(f\"警告: 行 {row_index+2}: Nfii 列值 '{nfii_str}' 不是有效数值，已设置为 0。行数据: {row}\")\n",
    "\n",
    "                        try:\n",
    "                            nfji = float(nfji_str) if nfji_str else 0.0 # 如果为空字符串则默认为0\n",
    "                        except ValueError:\n",
    "                            print(f\"警告: 行 {row_index+2}: Nfji 列值 '{nfji_str}' 不是有效数值，已设置为 0。行数据: {row}\")\n",
    "\n",
    "                        try:\n",
    "                            c5 = float(c5_str) if c5_str else 0.0 # 如果为空字符串则默认为0\n",
    "                        except ValueError:\n",
    "                            print(f\"警告: 行 {row_index+2}: C5 列值 '{c5_str}' 不是有效数值，已设置为 0。行数据: {row}\")\n",
    "\n",
    "\n",
    "                        if c5 != 0:\n",
    "                            intraflowf = (nfji + 1 - nfii) / c5\n",
    "                        else:\n",
    "                            intraflowf = 'NaN'  # 如果 C5 为 0，则 InTraFlowf 设为 'NaN' (Not a Number) 表示未定义或无穷大\n",
    "\n",
    "                        updated_row = row + [intraflowf]  # 将 InTraFlowf 添加到行尾\n",
    "                        writer.writerow(updated_row)  # 写入更新后的行\n",
    "\n",
    "                    except IndexError:\n",
    "                        print(f\"警告: 行 {row_index+2}: 行数据列数不足，跳过计算 InTraFlowf，行: {row}\")\n",
    "                        writer.writerow(row + ['']) # 写入原始行，并在 InTraFlowf 列留空\n",
    "\n",
    "                else:\n",
    "                    print(f\"警告: 行 {row_index+2}: 行数据列数不足 (少于 6 列)，跳过，行: {row}\")\n",
    "                    writer.writerow(row + ['']) # 写入原始行，并在 InTraFlowf 列留空\n",
    "\n",
    "\n",
    "        print(f\"已成功计算 InTraFlowf 并保存到 {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\")\n",
    "\n",
    "\n",
    "# 定义输入和输出文件路径\n",
    "input_file_path = \"Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_added.tsv\"\n",
    "output_file_path = \"Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_InTraFlowf.tsv\"\n",
    "\n",
    "# 调用函数执行计算和写入操作\n",
    "calculate_intraflowf_corrected(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 'Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_InTraFlowf.tsv' 分析报告:\n",
      "\n",
      "字段: 'PaperID'\n",
      "  总行数 (不含 header): 9117368\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'FieldID'\n",
      "  总行数 (不含 header): 9117368\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'PaperYear'\n",
      "  总行数 (不含 header): 9117368\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'Nfii'\n",
      "  总行数 (不含 header): 9117368\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'Nfji'\n",
      "  总行数 (不含 header): 9117368\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'C5'\n",
      "  总行数 (不含 header): 9117368\n",
      "  空值 (空字符串) 数量: 1983820\n",
      "------------------------------\n",
      "字段: 'InTraFlowf'\n",
      "  总行数 (不含 header): 9117368\n",
      "  空值 (空字符串) 数量: 0\n",
      "  NaN 值 数量: 3048823\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def analyze_tsv_file(file_path):\n",
    "    \"\"\"\n",
    "    分析 TSV 文件，统计每个字段的行数、空值和 NaN 值。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV 文件的路径。\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as tsvfile:\n",
    "            reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "            header = next(reader, None)  # 读取 header 行\n",
    "\n",
    "            if not header:\n",
    "                print(f\"错误: 文件 '{file_path}' 没有 header 行或为空文件。\")\n",
    "                return\n",
    "\n",
    "            column_data = {field: [] for field in header} # 使用字典存储每列的数据\n",
    "\n",
    "            for row in reader:\n",
    "                for i, value in enumerate(row):\n",
    "                    if i < len(header): # 确保列索引在 header 范围内\n",
    "                        column_data[header[i]].append(value.strip()) # 去除值两端空格\n",
    "\n",
    "            print(f\"文件 '{file_path}' 分析报告:\\n\")\n",
    "\n",
    "            for field in header:\n",
    "                values = column_data[field]\n",
    "                total_rows = len(values)\n",
    "                empty_count = values.count('')\n",
    "                nan_count = values.count('NaN') if field == 'InTraFlowf' else 0 # 只对 InTraFlowf 列统计 NaN\n",
    "\n",
    "                print(f\"字段: '{field}'\")\n",
    "                print(f\"  总行数 (不含 header): {total_rows}\")\n",
    "                print(f\"  空值 (空字符串) 数量: {empty_count}\")\n",
    "                if field == 'InTraFlowf':\n",
    "                    print(f\"  NaN 值 数量: {nan_count}\") # 只在 InTraFlowf 列显示 NaN 计数\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{file_path}' 未找到，请检查文件路径。\")\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件 '{file_path}' 时发生错误: {e}\")\n",
    "\n",
    "\n",
    "# 定义要分析的文件路径\n",
    "file_path_to_analyze = \"Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_InTraFlowf.tsv\" # 替换为您要分析的文件路径\n",
    "analyze_tsv_file(file_path_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功将 InTraFlowf 数据从 Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_InTraFlowf.tsv 合并到 Merged_IMC_多字段.tsv, 结果已保存到 Merged_IMC_多字段_InTraFlowf_added.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def merge_intraflowf_to_merged_imc(intraflowf_file_path, merged_imc_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    根据 PaperID 将 Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_InTraFlowf.tsv 文件中的 InTraFlowf 列\n",
    "    匹配到 Merged_IMC_多字段.tsv 文件中。\n",
    "\n",
    "    Args:\n",
    "        intraflowf_file_path (str): Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_InTraFlowf.tsv 文件的路径。\n",
    "        merged_imc_file_path (str): Merged_IMC_多字段.tsv 文件的路径。\n",
    "        output_file_path (str): 输出文件的路径。\n",
    "    \"\"\"\n",
    "\n",
    "    intraflowf_dict = {}  # 创建一个字典，用于存储 PaperID 和 InTraFlowf 的对应关系\n",
    "\n",
    "    # 读取 Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_InTraFlowf.tsv 文件并构建 PaperID 到 InTraFlowf 的字典\n",
    "    try:\n",
    "        with open(intraflowf_file_path, 'r', encoding='utf-8') as intraflowf_file:\n",
    "            reader_intraflowf = csv.reader(intraflowf_file, delimiter='\\t')\n",
    "            header_intraflowf = next(reader_intraflowf, None)  # 读取并跳过 header 行，如果存在\n",
    "\n",
    "            if header_intraflowf and 'PaperID' in header_intraflowf and 'InTraFlowf' in header_intraflowf:\n",
    "                paper_id_col_index_intraflowf = header_intraflowf.index('PaperID')\n",
    "                intraflowf_col_index = header_intraflowf.index('InTraFlowf')\n",
    "            else:\n",
    "                print(f\"错误: 文件 {intraflowf_file_path} 的header中没有找到 'PaperID' 或 'InTraFlowf' 列，或者没有header行。请检查文件结构。假设 PaperID 在第1列， InTraFlowf 在最后一列。\")\n",
    "                paper_id_col_index_intraflowf = 0 # 假设 PaperID 是第一列\n",
    "                intraflowf_col_index = -1 # 假设 InTraFlowf 是最后一列\n",
    "\n",
    "            for row in reader_intraflowf:\n",
    "                if len(row) > max(paper_id_col_index_intraflowf, intraflowf_col_index) and row[paper_id_col_index_intraflowf].strip(): # 确保行有足够的列，且 PaperID 不为空\n",
    "                    try:\n",
    "                        paper_id = row[paper_id_col_index_intraflowf].strip() # 获取 PaperID 并去除空格\n",
    "                        intraflowf_value = row[intraflowf_col_index].strip() if intraflowf_col_index != -1 and row[intraflowf_col_index].strip() else '' # 获取 InTraFlowf 值并去除空格，如果列索引为-1或者值为空则设为空字符串\n",
    "                        intraflowf_dict[paper_id] = intraflowf_value\n",
    "                    except IndexError:\n",
    "                        print(f\"警告: 行数据列数不足，跳过: {row}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"警告: 处理行数据时发生错误: {row}, 错误信息: {e}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 {intraflowf_file_path} 未找到，请检查文件路径。\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件 {intraflowf_file_path} 时发生错误: {e}\")\n",
    "        return\n",
    "\n",
    "    # 读取 Merged_IMC_多字段.tsv 文件，并添加 InTraFlowf 列\n",
    "    try:\n",
    "        with open(merged_imc_file_path, 'r', encoding='utf-8') as merged_imc_file, \\\n",
    "             open(output_file_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "            reader_merged_imc = csv.reader(merged_imc_file, delimiter='\\t')\n",
    "            writer = csv.writer(outfile, delimiter='\\t')\n",
    "\n",
    "            header_merged_imc = next(reader_merged_imc, None) # 读取 merged_imc_file 的 header\n",
    "            if header_merged_imc:\n",
    "                updated_header = header_merged_imc + ['InTraFlowf'] # 在 header 中添加 'InTraFlowf' 列名\n",
    "                writer.writerow(updated_header) # 写入新的 header\n",
    "            else:\n",
    "                writer.writerow([''] + ['InTraFlowf']) # 如果 merged_imc_file 没有 header，则写入默认 header (假设第一列是空的，需要根据实际情况调整)\n",
    "                print(f\"警告: 文件 {merged_imc_file_path} 没有header行，输出文件header可能不正确，请检查。\")\n",
    "\n",
    "\n",
    "            paper_id_col_index_merged_imc = 1  # PaperID 在第二列 (索引为 1)\n",
    "\n",
    "            for row in reader_merged_imc:\n",
    "                if len(row) > paper_id_col_index_merged_imc and row[paper_id_col_index_merged_imc].strip(): # 确保行有足够的列，且 PaperID 不为空\n",
    "                    paper_id = row[paper_id_col_index_merged_imc].strip() # 获取 PaperID 并去除空格\n",
    "                    intraflowf_value = intraflowf_dict.get(paper_id, '') # 从字典中查找 InTraFlowf 值，如果找不到则默认为空字符串\n",
    "                    updated_row = row + [intraflowf_value] # 将 InTraFlowf 值添加到行尾\n",
    "                    writer.writerow(updated_row) # 写入更新后的行\n",
    "                else:\n",
    "                    print(f\"警告: 行数据列数不足或 PaperID 为空，跳过: {row}\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 {merged_imc_file_path} 未找到，请检查文件路径。\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件 {merged_imc_file_path} 时发生错误: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"已成功将 InTraFlowf 数据从 {intraflowf_file_path} 合并到 {merged_imc_file_path}, 结果已保存到 {output_file_path}\")\n",
    "\n",
    "\n",
    "# 定义文件路径和输出文件路径\n",
    "intraflowf_file_path = \"Paper_Nfii_Nfji_Values_Final_Corrected_V2_C5_InTraFlowf.tsv\"\n",
    "merged_imc_file_path = \"Merged_IMC_多字段.tsv\"\n",
    "output_file_path = \"Merged_IMC_多字段_InTraFlowf_added.tsv\" # 输出到新文件，可以根据需要修改\n",
    "\n",
    "# 调用函数执行合并操作\n",
    "merge_intraflowf_to_merged_imc(intraflowf_file_path, merged_imc_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 'Merged_IMC_多字段_InTraFlowf_added.tsv' 分析报告:\n",
      "\n",
      "字段: 'FieldID'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'PaperID'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'IMCp'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 2497546\n",
      "------------------------------\n",
      "字段: 'IMCft'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 2214076\n",
      "------------------------------\n",
      "字段: 'C_f'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3\n",
      "------------------------------\n",
      "字段: 'Year'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3\n",
      "------------------------------\n",
      "字段: 'Citation_Count'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'C10'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 5924481\n",
      "------------------------------\n",
      "字段: 'C5'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3085294\n",
      "------------------------------\n",
      "字段: 'Team_size'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 167\n",
      "------------------------------\n",
      "字段: 'Disruption'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 4711622\n",
      "------------------------------\n",
      "字段: 'Atyp_Median_Z'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7816176\n",
      "------------------------------\n",
      "字段: 'SB_B'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7423844\n",
      "------------------------------\n",
      "字段: 'SB_T'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7423844\n",
      "------------------------------\n",
      "字段: 'InTraFlowf'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 2497549\n",
      "  NaN 值 数量: 3048631\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def analyze_tsv_file(file_path):\n",
    "    \"\"\"\n",
    "    分析 TSV 文件，统计每个字段的行数、空值和 NaN 值。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV 文件的路径。\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as tsvfile:\n",
    "            reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "            header = next(reader, None)  # 读取 header 行\n",
    "\n",
    "            if not header:\n",
    "                print(f\"错误: 文件 '{file_path}' 没有 header 行或为空文件。\")\n",
    "                return\n",
    "\n",
    "            column_data = {field: [] for field in header} # 使用字典存储每列的数据\n",
    "\n",
    "            for row in reader:\n",
    "                for i, value in enumerate(row):\n",
    "                    if i < len(header): # 确保列索引在 header 范围内\n",
    "                        column_data[header[i]].append(value.strip()) # 去除值两端空格\n",
    "\n",
    "            print(f\"文件 '{file_path}' 分析报告:\\n\")\n",
    "\n",
    "            for field in header:\n",
    "                values = column_data[field]\n",
    "                total_rows = len(values)\n",
    "                empty_count = values.count('')\n",
    "                nan_count = values.count('NaN') if field == 'InTraFlowf' else 0 # 只对 InTraFlowf 列统计 NaN\n",
    "\n",
    "                print(f\"字段: '{field}'\")\n",
    "                print(f\"  总行数 (不含 header): {total_rows}\")\n",
    "                print(f\"  空值 (空字符串) 数量: {empty_count}\")\n",
    "                if field == 'InTraFlowf':\n",
    "                    print(f\"  NaN 值 数量: {nan_count}\") # 只在 InTraFlowf 列显示 NaN 计数\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{file_path}' 未找到，请检查文件路径。\")\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件 '{file_path}' 时发生错误: {e}\")\n",
    "\n",
    "\n",
    "# 定义要分析的文件路径\n",
    "file_path_to_analyze = \"Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv\" # 替换为您要分析的文件路径\n",
    "analyze_tsv_file(file_path_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功删除 'IMCft' 列并将结果保存到 Merged_IMC_多字段_InTraFlowf_no_IMCft.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def delete_column_imcft(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    删除 TSV 文件中的 'IMCft' 列。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径 (Merged_IMC_多字段_InTraFlowf_added.tsv).\n",
    "        output_file_path (str): 输出 TSV 文件路径 (例如 Merged_IMC_多字段_InTraFlowf_no_IMCft.tsv).\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as infile, \\\n",
    "             open(output_file_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "            reader = csv.reader(infile, delimiter='\\t')\n",
    "            writer = csv.writer(outfile, delimiter='\\t')\n",
    "\n",
    "            header = next(reader, None)  # 读取 header 行\n",
    "            if header:\n",
    "                try:\n",
    "                    imcft_col_index = header.index('IMCft')  # 查找 'IMCft' 列的索引\n",
    "                    updated_header = [h for i, h in enumerate(header) if i != imcft_col_index] # 创建不包含 'IMCft' 的新 header\n",
    "                    writer.writerow(updated_header) # 写入新的 header\n",
    "                except ValueError:\n",
    "                    print(f\"警告: 文件 '{input_file_path}' 的header中没有找到 'IMCft' 列，将复制所有列到输出文件。请检查header是否正确或列名是否拼写错误。\")\n",
    "                    writer.writerow(header) # 如果找不到 'IMCft' 列，则直接写入原 header\n",
    "                    imcft_col_index = -1 # 设置为 -1 表示找不到该列\n",
    "\n",
    "\n",
    "                for row in reader:\n",
    "                    if imcft_col_index != -1 and len(row) > imcft_col_index: # 如果找到了 'IMCft' 列且行有足够的列数\n",
    "                        updated_row = [value for i, value in enumerate(row) if i != imcft_col_index] # 创建不包含 'IMCft' 列值的新行\n",
    "                        writer.writerow(updated_row) # 写入新行\n",
    "                    else: # 如果找不到 'IMCft' 列或行数不足，则直接写入原行\n",
    "                        writer.writerow(row)\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(f\"警告: 文件 '{input_file_path}' 没有 header 行，将直接复制所有行到输出文件。\")\n",
    "                writerow = writer.writerow # 为了在循环内使用 writerow 方法，先赋值\n",
    "                for row in reader: # 直接复制所有行\n",
    "                    writerow(row)\n",
    "\n",
    "\n",
    "        print(f\"已成功删除 'IMCft' 列并将结果保存到 {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\")\n",
    "\n",
    "\n",
    "# 定义输入和输出文件路径\n",
    "input_file_path = \"Merged_IMC_多字段_InTraFlowf_added.tsv\"\n",
    "output_file_path = \"Merged_IMC_多字段_InTraFlowf_no_IMCft.tsv\" # 输出到新文件，可以根据需要修改\n",
    "\n",
    "# 调用函数执行删除列操作\n",
    "delete_column_imcft(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功计算 InTraFlow 和 N_InTraFlow 并保存到 Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def calculate_intraflow_n_intraflow(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    计算 InTraFlow 和 N_InTraFlow 指标并添加到 TSV 文件中。\n",
    "\n",
    "    InTraFlow = 0.5 * IMCp + 0.5 * InTraFlowf\n",
    "    N_InTraFlow = C_f * InTraFlow\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径 (Merged_IMC_多字段_InTraFlowf_no_IMCft.tsv).\n",
    "        output_file_path (str): 输出 TSV 文件路径 (例如 Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv).\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as infile, \\\n",
    "             open(output_file_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "            reader = csv.reader(infile, delimiter='\\t')\n",
    "            writer = csv.writer(outfile, delimiter='\\t')\n",
    "\n",
    "            header = next(reader)  # 读取 header 行\n",
    "            if not header:\n",
    "                print(f\"错误: 文件 '{input_file_path}' 没有 header 行。无法确定列索引。\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                imcp_col_index = header.index('IMCp')\n",
    "            except ValueError:\n",
    "                print(f\"警告: Header中未找到 'IMCp' 列. 计算 InTraFlow 时将 'IMCp' 视为 0.\")\n",
    "                imcp_col_index = -1\n",
    "\n",
    "            try:\n",
    "                intraflowf_col_index = header.index('InTraFlowf')\n",
    "            except ValueError:\n",
    "                print(f\"警告: Header中未找到 'InTraFlowf' 列. 计算 InTraFlow 时将 'InTraFlowf' 视为 0.\")\n",
    "                intraflowf_col_index = -1\n",
    "\n",
    "            try:\n",
    "                cf_col_index = header.index('C_f')\n",
    "            except ValueError:\n",
    "                print(f\"警告: Header中未找到 'C_f' 列. 计算 N_InTraFlow 时将 'C_f' 视为 1 (默认值).\") # C_f as multiplier, default to 1 if missing might be reasonable\n",
    "                cf_col_index = -1\n",
    "                default_cf = 1.0 # Default C_f value if column not found\n",
    "            else:\n",
    "                default_cf = None # No default needed if column is found\n",
    "\n",
    "            updated_header = header + ['InTraFlow', 'N_InTraFlow']  # 添加新列到 header\n",
    "            writer.writerow(updated_header)  # 写入新的 header\n",
    "\n",
    "            for row_index, row in enumerate(reader):\n",
    "                imcp_value = 0.0\n",
    "                intraflowf_value = 0.0\n",
    "                cf_value = default_cf if default_cf is not None else 0.0 # Default to 0 if column is found but value is missing/invalid, otherwise use default_cf set above\n",
    "\n",
    "                if imcp_col_index != -1 and len(row) > imcp_col_index:\n",
    "                    imcp_str = row[imcp_col_index].strip()\n",
    "                    try:\n",
    "                        imcp_value = float(imcp_str) if imcp_str else 0.0\n",
    "                    except ValueError:\n",
    "                        print(f\"警告: 行 {row_index+2}: 'IMCp' 列值 '{imcp_str}' 不是有效数值，已设置为 0。行数据: {row}\")\n",
    "\n",
    "                if intraflowf_col_index != -1 and len(row) > intraflowf_col_index:\n",
    "                    intraflowf_str = row[intraflowf_col_index].strip()\n",
    "                    try:\n",
    "                        intraflowf_value = float(intraflowf_str) if intraflowf_str and intraflowf_str != 'NaN' else 0.0 # Treat 'NaN' as 0 as well\n",
    "                    except ValueError:\n",
    "                        print(f\"警告: 行 {row_index+2}: 'InTraFlowf' 列值 '{intraflowf_str}' 不是有效数值，已设置为 0。行数据: {row}\")\n",
    "\n",
    "                if cf_col_index != -1 and len(row) > cf_col_index:\n",
    "                    cf_str = row[cf_col_index].strip()\n",
    "                    try:\n",
    "                        cf_value = float(cf_str) if cf_str else (default_cf if default_cf is not None else 0.0) # Use default_cf if column missing in header, otherwise 0 if value missing/invalid in row\n",
    "                    except ValueError:\n",
    "                        print(f\"警告: 行 {row_index+2}: 'C_f' 列值 '{cf_str}' 不是有效数值，已设置为 {default_cf if default_cf is not None else 0}。行数据: {row}\")\n",
    "                        cf_value = default_cf if default_cf is not None else 0.0\n",
    "\n",
    "\n",
    "                intraflow = 0.5 * imcp_value + 0.5 * intraflowf_value\n",
    "                n_intraflow = cf_value * intraflow\n",
    "\n",
    "                updated_row = row + [intraflow, n_intraflow]\n",
    "                writer.writerow(updated_row)\n",
    "\n",
    "        print(f\"已成功计算 InTraFlow 和 N_InTraFlow 并保存到 {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\")\n",
    "\n",
    "\n",
    "# 定义输入和输出文件路径\n",
    "input_file_path = \"Merged_IMC_多字段_InTraFlowf_no_IMCft.tsv\"\n",
    "output_file_path = \"Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv\"\n",
    "\n",
    "# 调用函数执行计算和写入操作\n",
    "calculate_intraflow_n_intraflow(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 'Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv' 分析报告:\n",
      "\n",
      "字段: 'FieldID'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'PaperID'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'IMCp'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 2497546\n",
      "------------------------------\n",
      "字段: 'C_f'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3\n",
      "------------------------------\n",
      "字段: 'Year'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3\n",
      "------------------------------\n",
      "字段: 'Citation_Count'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'C10'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 5924481\n",
      "------------------------------\n",
      "字段: 'C5'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3085294\n",
      "------------------------------\n",
      "字段: 'Team_size'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 167\n",
      "------------------------------\n",
      "字段: 'Disruption'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 4711622\n",
      "------------------------------\n",
      "字段: 'Atyp_Median_Z'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7816176\n",
      "------------------------------\n",
      "字段: 'SB_B'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7423844\n",
      "------------------------------\n",
      "字段: 'SB_T'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7423844\n",
      "------------------------------\n",
      "字段: 'InTraFlowf'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 2497549\n",
      "  NaN 值 数量: 3048631\n",
      "------------------------------\n",
      "字段: 'InTraFlow'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'N_InTraFlow'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def analyze_tsv_file(file_path):\n",
    "    \"\"\"\n",
    "    分析 TSV 文件，统计每个字段的行数、空值和 NaN 值。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV 文件的路径。\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as tsvfile:\n",
    "            reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "            header = next(reader, None)  # 读取 header 行\n",
    "\n",
    "            if not header:\n",
    "                print(f\"错误: 文件 '{file_path}' 没有 header 行或为空文件。\")\n",
    "                return\n",
    "\n",
    "            column_data = {field: [] for field in header} # 使用字典存储每列的数据\n",
    "\n",
    "            for row in reader:\n",
    "                for i, value in enumerate(row):\n",
    "                    if i < len(header): # 确保列索引在 header 范围内\n",
    "                        column_data[header[i]].append(value.strip()) # 去除值两端空格\n",
    "\n",
    "            print(f\"文件 '{file_path}' 分析报告:\\n\")\n",
    "\n",
    "            for field in header:\n",
    "                values = column_data[field]\n",
    "                total_rows = len(values)\n",
    "                empty_count = values.count('')\n",
    "                nan_count = values.count('NaN') if field == 'InTraFlowf' else 0 # 只对 InTraFlowf 列统计 NaN\n",
    "\n",
    "                print(f\"字段: '{field}'\")\n",
    "                print(f\"  总行数 (不含 header): {total_rows}\")\n",
    "                print(f\"  空值 (空字符串) 数量: {empty_count}\")\n",
    "                if field == 'InTraFlowf':\n",
    "                    print(f\"  NaN 值 数量: {nan_count}\") # 只在 InTraFlowf 列显示 NaN 计数\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{file_path}' 未找到，请检查文件路径。\")\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件 '{file_path}' 时发生错误: {e}\")\n",
    "\n",
    "\n",
    "# 定义要分析的文件路径\n",
    "file_path_to_analyze = \"Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv\" # 替换为您要分析的文件路径\n",
    "analyze_tsv_file(file_path_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取文件: Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "# 文件路径\n",
    "file_path = \"Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv\"\n",
    "\n",
    "# 检查文件是否存在\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"错误：文件 '{file_path}' 不存在。\")\n",
    "else:\n",
    "    try:\n",
    "        # 读取TSV文件\n",
    "        print(f\"正在读取文件: {file_path}\")\n",
    "        data = pd.read_csv(file_path, sep='\\t')\n",
    "        \n",
    "        # 检查列是否存在\n",
    "        if 'InTraFlow' not in data.columns or 'N_InTraFlow' not in data.columns:\n",
    "            print(\"错误：文件中未找到'InTraFlow'或'N_InTraFlow'列。\")\n",
    "            print(f\"可用列: {', '.join(data.columns)}\")\n",
    "        else:\n",
    "            # 创建一个包含分布图和QQ图的子图\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "            \n",
    "            # 绘制数据分布直方图\n",
    "            sns.histplot(data['InTraFlow'].dropna(), kde=True, ax=axs[0, 0], color='skyblue')\n",
    "            axs[0, 0].set_title('InTraFlow 分布图', fontsize=14)\n",
    "            axs[0, 0].set_xlabel('InTraFlow', fontsize=12)\n",
    "            axs[0, 0].set_ylabel('频次', fontsize=12)\n",
    "            \n",
    "            sns.histplot(data['N_InTraFlow'].dropna(), kde=True, ax=axs[0, 1], color='salmon')\n",
    "            axs[0, 1].set_title('N_InTraFlow 分布图', fontsize=14)\n",
    "            axs[0, 1].set_xlabel('N_InTraFlow', fontsize=12)\n",
    "            axs[0, 1].set_ylabel('频次', fontsize=12)\n",
    "            \n",
    "            # 创建QQ图\n",
    "            stats.probplot(data['InTraFlow'].dropna(), dist=\"norm\", plot=axs[1, 0])\n",
    "            axs[1, 0].set_title('InTraFlow 的QQ图', fontsize=14)\n",
    "            \n",
    "            stats.probplot(data['N_InTraFlow'].dropna(), dist=\"norm\", plot=axs[1, 1])\n",
    "            axs[1, 1].set_title('N_InTraFlow 的QQ图', fontsize=14)\n",
    "            \n",
    "            # 调整布局\n",
    "            plt.tight_layout()\n",
    "            plt.suptitle('InTraFlow 和 N_InTraFlow 的分布和正态性分析', fontsize=16, y=1.02)\n",
    "            \n",
    "            # 保存图像\n",
    "            plt.savefig('分布和QQ图分析.png', dpi=300, bbox_inches='tight')\n",
    "            print(\"图像已保存为 '分布和QQ图分析.png'\")\n",
    "            \n",
    "            # 创建额外的对比图\n",
    "            fig2, axs2 = plt.subplots(1, 2, figsize=(16, 6))\n",
    "            \n",
    "            # 箱线图对比\n",
    "            sns.boxplot(data=data[['InTraFlow', 'N_InTraFlow']], ax=axs2[0])\n",
    "            axs2[0].set_title('箱线图对比', fontsize=14)\n",
    "            axs2[0].set_ylabel('值', fontsize=12)\n",
    "            \n",
    "            # 散点图查看关系\n",
    "            sns.scatterplot(x='InTraFlow', y='N_InTraFlow', data=data, ax=axs2[1])\n",
    "            axs2[1].set_title('InTraFlow 与 N_InTraFlow 的关系', fontsize=14)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('字段对比图.png', dpi=300, bbox_inches='tight')\n",
    "            print(\"对比图已保存为 '字段对比图.png'\")\n",
    "            \n",
    "            # 显示所有图形\n",
    "            plt.show()\n",
    "            \n",
    "            # 打印基本统计信息\n",
    "            print(\"\\nInTraFlow 的统计信息:\")\n",
    "            print(data['InTraFlow'].describe())\n",
    "            print(\"\\nN_InTraFlow 的统计信息:\")\n",
    "            print(data['N_InTraFlow'].describe())\n",
    "            \n",
    "            # 计算相关性\n",
    "            correlation = data['InTraFlow'].corr(data['N_InTraFlow'])\n",
    "            print(f\"\\nInTraFlow 和 N_InTraFlow 之间的相关性: {correlation:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"发生错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# 读取TSV文件\n",
    "file_path = 'Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv'  # 替换为你的文件路径\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 提取InTraFlow和N_InTraFlow字段\n",
    "intraflow = data['InTraFlow']\n",
    "n_intraflow = data['N_InTraFlow']\n",
    "\n",
    "# 数据清理，移除NaN和无穷大值\n",
    "intraflow = intraflow[np.isfinite(intraflow)]\n",
    "n_intraflow = n_intraflow[np.isfinite(n_intraflow)]\n",
    "\n",
    "# 绘制数据分布情况\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# InTraFlow的分布\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(intraflow, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('InTraFlow Distribution')\n",
    "plt.xlabel('InTraFlow')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# N_InTraFlow的分布\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(n_intraflow, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('N_InTraFlow Distribution')\n",
    "plt.xlabel('N_InTraFlow')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 显示分布图\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 绘制QQ图\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# InTraFlow的QQ图\n",
    "plt.subplot(1, 2, 1)\n",
    "stats.probplot(intraflow, dist=\"norm\", plot=plt)\n",
    "plt.title('InTraFlow QQ Plot')\n",
    "\n",
    "# N_InTraFlow的QQ图\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(n_intraflow, dist=\"norm\", plot=plt)\n",
    "plt.title('N_InTraFlow QQ Plot')\n",
    "\n",
    "# 显示QQ图\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.161332e+07\n",
      "mean              inf\n",
      "std               NaN\n",
      "min     -7.452790e+03\n",
      "25%     -8.459716e-02\n",
      "50%      0.000000e+00\n",
      "75%      2.068098e-01\n",
      "max               inf\n",
      "Name: N_InTraFlow, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看N_InTraFlow字段的基本统计信息\n",
    "print(data['N_InTraFlow'].describe())\n",
    "\n",
    "# 画出数据的箱形图，以便检测异常值\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(data['N_InTraFlow'].dropna())\n",
    "plt.title('Boxplot of N_InTraFlow')\n",
    "plt.ylabel('N_InTraFlow')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.156943e+07\n",
      "mean     7.912248e-02\n",
      "std      7.322907e+00\n",
      "min     -7.452790e+03\n",
      "25%     -8.477602e-02\n",
      "50%      0.000000e+00\n",
      "75%      2.013384e-01\n",
      "max      7.266723e+03\n",
      "Name: N_InTraFlow, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 移除N_InTraFlow中的inf和NaN值\n",
    "cleaned_n_intraflow = data['N_InTraFlow'].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# 重新统计清理后的数据\n",
    "print(cleaned_n_intraflow.describe())\n",
    "\n",
    "# 绘制箱形图以查看清理后的数据分布\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(cleaned_n_intraflow)\n",
    "plt.title('Boxplot of Cleaned N_InTraFlow')\n",
    "plt.ylabel('N_InTraFlow')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_28604\\1568316129.py:5: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(cleaned_n_intraflow, shade=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# 绘制N_InTraFlow字段的PDF图（在-1到1之间）\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.kdeplot(cleaned_n_intraflow, shade=True)\n",
    "\n",
    "# 设置横坐标限制在-1到1之间\n",
    "plt.xlim(-100, 100)\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title('PDF of Cleaned N_InTraFlow')\n",
    "plt.xlabel('N_InTraFlow')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总行数: 11613323\n",
      "空值数量: 43895\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取源文件\n",
    "file_path = 'Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv'  # 替换为你的文件路径\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 清洗数据，去掉N_InTraFlow中的无穷大和NaN\n",
    "data['N_InTraFlow'] = data['N_InTraFlow'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 统计总行数和清洗后的空值数量\n",
    "total_rows = data.shape[0]\n",
    "missing_values = data['N_InTraFlow'].isna().sum()\n",
    "\n",
    "# 打印统计信息\n",
    "print(f\"总行数: {total_rows}\")\n",
    "print(f\"空值数量: {missing_values}\")\n",
    "\n",
    "# 如果你需要将空值对应的行置为空值，可以使用以下代码：\n",
    "# 如果只是对`N_InTraFlow`字段为空值的行进行处理，留下空值:\n",
    "data.loc[data['N_InTraFlow'].isna(), 'N_InTraFlow'] = np.nan\n",
    "\n",
    "# 如果你需要将清洗后的数据保存为新文件，可以使用以下代码：\n",
    "cleaned_file_path = 'cleaned_Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv'\n",
    "data.to_csv(cleaned_file_path, sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'IMCp'字段已删除。\n",
      "修改后的文件已保存为: cleaned_Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取源文件\n",
    "file_path = 'InTraFlow_Cleanned.tsv'  # 替换为你的文件路径\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 删除'IMCp'字段\n",
    "if 'IMCp' in data.columns:\n",
    "    data = data.drop(columns=['IMCp'])\n",
    "    print(\"'IMCp'字段已删除。\")\n",
    "else:\n",
    "    print(\"'IMCp'字段不存在。\")\n",
    "\n",
    "# 保存删除字段后的文件\n",
    "cleaned_file_path = 'cleaned_Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv'  # 设置保存的新文件路径\n",
    "data.to_csv(cleaned_file_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"修改后的文件已保存为: {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取源文件\n",
    "file_path = 'InTraFlow_Cleanned.tsv'  # 替换为你的文件路径\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 删除'IMCp'字段\n",
    "if 'IMCp' in data.columns:\n",
    "    data = data.drop(columns=['IMCp'])\n",
    "    print(\"'IMCp'字段已删除。\")\n",
    "else:\n",
    "    print(\"'IMCp'字段不存在。\")\n",
    "\n",
    "# 保存删除字段后的文件\n",
    "cleaned_file_path = 'cleaned_Merged_IMC_多字段_InTraFlow_N_InTraFlow.tsv'  # 设置保存的新文件路径\n",
    "data.to_csv(cleaned_file_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"修改后的文件已保存为: {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始合并操作...\n",
      "读取较小的文件...\n",
      "小文件读取完成。形状: (11613323, 15)\n",
      "第二列: PaperID\n",
      "从小文件中提取了 11613323 个唯一PaperID\n",
      "以分块方式处理大文件...\n",
      "已处理 10 个分块，找到 779799 条匹配记录...\n",
      "还剩 10833524 个PaperID未匹配\n",
      "已处理 20 个分块，找到 1645605 条匹配记录...\n",
      "还剩 9967718 个PaperID未匹配\n",
      "已处理 30 个分块，找到 2512650 条匹配记录...\n",
      "还剩 9100673 个PaperID未匹配\n",
      "已处理 40 个分块，找到 3377434 条匹配记录...\n",
      "还剩 8235889 个PaperID未匹配\n",
      "已处理 50 个分块，找到 4244098 条匹配记录...\n",
      "还剩 7369225 个PaperID未匹配\n",
      "已处理 60 个分块，找到 5108397 条匹配记录...\n",
      "还剩 6504926 个PaperID未匹配\n",
      "已处理 70 个分块，找到 5973844 条匹配记录...\n",
      "还剩 5639479 个PaperID未匹配\n",
      "已处理 80 个分块，找到 6840381 条匹配记录...\n",
      "还剩 4772942 个PaperID未匹配\n",
      "已处理 90 个分块，找到 7706442 条匹配记录...\n",
      "还剩 3906881 个PaperID未匹配\n",
      "已处理 100 个分块，找到 8573283 条匹配记录...\n",
      "还剩 3040040 个PaperID未匹配\n",
      "已处理 110 个分块，找到 9440767 条匹配记录...\n",
      "还剩 2172556 个PaperID未匹配\n",
      "已处理 120 个分块，找到 10305154 条匹配记录...\n",
      "还剩 1308169 个PaperID未匹配\n",
      "已处理 130 个分块，找到 11170635 条匹配记录...\n",
      "还剩 442688 个PaperID未匹配\n",
      "已找到所有匹配的PaperID，停止处理\n",
      "大文件处理完成。找到 11613323 条匹配记录。\n",
      "合并数据帧...\n",
      "合并完成。合并后数据的形状: (11613323, 18)\n",
      "保存合并后的数据...\n",
      "数据已成功保存到 Merged_Cleaned_InTraFlow.tsv\n",
      "总执行时间: 349.96 秒\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 开始计时\n",
    "start_time = time.time()\n",
    "\n",
    "# 文件路径\n",
    "file1_path = \"Cleaned_InTraFlow.tsv\"  # 原始文件\n",
    "file2_path = \"SciSciNet_Papers.tsv\"  # 大文件 (16.3GB)\n",
    "output_path = \"Merged_Cleaned_InTraFlow.tsv\"  # 输出文件\n",
    "\n",
    "print(f\"开始合并操作...\")\n",
    "\n",
    "try:\n",
    "    # 读取较小的文件\n",
    "    print(f\"读取较小的文件...\")\n",
    "    df_small = pd.read_csv(file1_path, sep='\\t')\n",
    "    \n",
    "    print(f\"小文件读取完成。形状: {df_small.shape}\")\n",
    "    \n",
    "    # 验证PaperID在第二列\n",
    "    columns = df_small.columns.tolist()\n",
    "    if len(columns) >= 2:\n",
    "        print(f\"第二列: {columns[1]}\")\n",
    "    \n",
    "    # 创建PaperID集合用于快速查找\n",
    "    paper_ids = set(df_small['PaperID'].unique())\n",
    "    \n",
    "    print(f\"从小文件中提取了 {len(paper_ids)} 个唯一PaperID\")\n",
    "    \n",
    "    # 初始化DataFrame存储大文件中匹配的记录\n",
    "    large_columns = ['PaperID', 'Patent_Count', 'NIH_Count', 'NSF_Count']\n",
    "    df_matches = pd.DataFrame(columns=large_columns)\n",
    "    \n",
    "    # 分块处理大文件\n",
    "    print(f\"以分块方式处理大文件...\")\n",
    "    \n",
    "    chunk_size = 1000000  # 根据可用内存调整\n",
    "    chunks_read = 0\n",
    "    total_matches = 0\n",
    "    paper_ids_to_find = paper_ids.copy()  # 创建副本用于跟踪\n",
    "    \n",
    "    # 读取并处理大文件\n",
    "    for chunk in pd.read_csv(file2_path, sep='\\t', \n",
    "                          usecols=large_columns,\n",
    "                          chunksize=chunk_size):\n",
    "        chunks_read += 1\n",
    "        if chunks_read % 10 == 0:\n",
    "            print(f\"已处理 {chunks_read} 个分块，找到 {total_matches} 条匹配记录...\")\n",
    "            print(f\"还剩 {len(paper_ids_to_find)} 个PaperID未匹配\")\n",
    "        \n",
    "        # 过滤匹配的PaperID\n",
    "        matches = chunk[chunk['PaperID'].isin(paper_ids_to_find)]\n",
    "        total_matches += len(matches)\n",
    "        \n",
    "        # 添加到匹配集合\n",
    "        df_matches = pd.concat([df_matches, matches])\n",
    "        \n",
    "        # 从待查找集合中移除已匹配ID\n",
    "        matched_ids = set(matches['PaperID'])\n",
    "        paper_ids_to_find -= matched_ids\n",
    "        \n",
    "        # 如果已找到所有ID，停止处理\n",
    "        if len(paper_ids_to_find) == 0:\n",
    "            print(f\"已找到所有匹配的PaperID，停止处理\")\n",
    "            break\n",
    "    \n",
    "    print(f\"大文件处理完成。找到 {total_matches} 条匹配记录。\")\n",
    "    \n",
    "    # 执行合并\n",
    "    print(f\"合并数据帧...\")\n",
    "    df_merged = pd.merge(df_small, df_matches, on='PaperID', how='left')\n",
    "    \n",
    "    print(f\"合并完成。合并后数据的形状: {df_merged.shape}\")\n",
    "    \n",
    "    # 保存合并后的数据\n",
    "    print(f\"保存合并后的数据...\")\n",
    "    df_merged.to_csv(output_path, sep='\\t', index=False)\n",
    "    \n",
    "    print(f\"数据已成功保存到 {output_path}\")\n",
    "    \n",
    "    # 计算并显示总运行时间\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"总执行时间: {elapsed_time:.2f} 秒\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"发生错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 'Merged_Cleaned_InTraFlow.tsv' 分析报告:\n",
      "\n",
      "字段: 'FieldID'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'PaperID'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'C_f'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3\n",
      "------------------------------\n",
      "字段: 'Year'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3\n",
      "------------------------------\n",
      "字段: 'Citation_Count'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'C10'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 5924481\n",
      "------------------------------\n",
      "字段: 'C5'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3085294\n",
      "------------------------------\n",
      "字段: 'Team_size'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 167\n",
      "------------------------------\n",
      "字段: 'Disruption'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 4711622\n",
      "------------------------------\n",
      "字段: 'Atyp_Median_Z'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7816176\n",
      "------------------------------\n",
      "字段: 'SB_B'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7423844\n",
      "------------------------------\n",
      "字段: 'SB_T'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7423844\n",
      "------------------------------\n",
      "字段: 'InTraFlowf'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 5546180\n",
      "  NaN 值 数量: 0\n",
      "------------------------------\n",
      "字段: 'InTraFlow'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'N_InTraFlow'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 43895\n",
      "------------------------------\n",
      "字段: 'Patent_Count'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'NIH_Count'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'NSF_Count'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def analyze_tsv_file(file_path):\n",
    "    \"\"\"\n",
    "    分析 TSV 文件，统计每个字段的行数、空值和 NaN 值。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV 文件的路径。\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as tsvfile:\n",
    "            reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "            header = next(reader, None)  # 读取 header 行\n",
    "\n",
    "            if not header:\n",
    "                print(f\"错误: 文件 '{file_path}' 没有 header 行或为空文件。\")\n",
    "                return\n",
    "\n",
    "            column_data = {field: [] for field in header} # 使用字典存储每列的数据\n",
    "\n",
    "            for row in reader:\n",
    "                for i, value in enumerate(row):\n",
    "                    if i < len(header): # 确保列索引在 header 范围内\n",
    "                        column_data[header[i]].append(value.strip()) # 去除值两端空格\n",
    "\n",
    "            print(f\"文件 '{file_path}' 分析报告:\\n\")\n",
    "\n",
    "            for field in header:\n",
    "                values = column_data[field]\n",
    "                total_rows = len(values)\n",
    "                empty_count = values.count('')\n",
    "                nan_count = values.count('NaN') if field == 'InTraFlowf' else 0 # 只对 InTraFlowf 列统计 NaN\n",
    "\n",
    "                print(f\"字段: '{field}'\")\n",
    "                print(f\"  总行数 (不含 header): {total_rows}\")\n",
    "                print(f\"  空值 (空字符串) 数量: {empty_count}\")\n",
    "                if field == 'InTraFlowf':\n",
    "                    print(f\"  NaN 值 数量: {nan_count}\") # 只在 InTraFlowf 列显示 NaN 计数\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{file_path}' 未找到，请检查文件路径。\")\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件 '{file_path}' 时发生错误: {e}\")\n",
    "\n",
    "\n",
    "# 定义要分析的文件路径\n",
    "file_path_to_analyze = \"Merged_Cleaned_InTraFlow.tsv\" # 替换为您要分析的文件路径\n",
    "analyze_tsv_file(file_path_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功计算 'Fund' 字段并删除 'NIH_Count' 和 'NSF_Count' 列。\n",
      "结果已保存到 Merged_Cleaned_InTraFlow_Fund.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_fund_and_drop_counts(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    计算 'Fund' 字段 (NIH_Count + NSF_Count) 并删除 'NIH_Count' 和 'NSF_Count' 列。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径 (Merged_Cleaned_InTraFlow.tsv).\n",
    "        output_file_path (str): 输出 TSV 文件路径 (例如 Merged_Cleaned_InTraFlow_Fund.tsv).\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 读取 Merged_Cleaned_InTraFlow.tsv 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "        # 检查 'NIH_Count' 和 'NSF_Count' 列是否存在\n",
    "        if 'NIH_Count' not in df.columns or 'NSF_Count' not in df.columns:\n",
    "            print(f\"错误: 文件 '{input_file_path}' 缺少 'NIH_Count' 或 'NSF_Count' 列，请检查文件。\")\n",
    "            return\n",
    "\n",
    "        # 将 'NIH_Count' 和 'NSF_Count' 列转换为数值类型，并将无法转换的值转换为 NaN\n",
    "        df['NIH_Count'] = pd.to_numeric(df['NIH_Count'], errors='coerce')\n",
    "        df['NSF_Count'] = pd.to_numeric(df['NSF_Count'], errors='coerce')\n",
    "\n",
    "        # 使用 fillna(0) 将 NaN 值替换为 0，然后计算 'Fund' 列\n",
    "        df['Fund'] = df['NIH_Count'].fillna(0) + df['NSF_Count'].fillna(0)\n",
    "\n",
    "        # 删除 'NIH_Count' 和 'NSF_Count' 列\n",
    "        df.drop(columns=['NIH_Count', 'NSF_Count'], inplace=True)\n",
    "\n",
    "        # 保存修改后的 DataFrame 到新的 TSV 文件\n",
    "        df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"已成功计算 'Fund' 字段并删除 'NIH_Count' 和 'NSF_Count' 列。\")\n",
    "        print(f\"结果已保存到 {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 定义输入和输出文件路径\n",
    "input_file_path = \"Merged_Cleaned_InTraFlow.tsv\"  # 修改为你的 Merged_Cleaned_InTraFlow.tsv 文件路径\n",
    "output_file_path = \"Merged_Cleaned_InTraFlow_Fund.tsv\" # 输出文件路径\n",
    "\n",
    "# 调用函数执行计算和删除列操作\n",
    "calculate_fund_and_drop_counts(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功创建 Field_CS, Field_Eng, Field_Eco 哑变量。\n",
      "结果已保存到 Merged_Cleaned_InTraFlow_Fund_Dummies.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_field_dummies(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    根据 FieldID 列创建 Field_CS, Field_Eng, Field_Eco 三个学科哑变量。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径 (Merged_Cleaned_InTraFlow_Fund.tsv).\n",
    "        output_file_path (str): 输出 TSV 文件路径 (例如 Merged_Cleaned_InTraFlow_Fund_Dummies.tsv).\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 读取 Merged_Cleaned_InTraFlow_Fund.tsv 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "        # 目标 FieldID 和对应的哑变量列名\n",
    "        field_targets = {\n",
    "            41008148: 'Field_CS',\n",
    "            127413603: 'Field_Eng',\n",
    "            162324750: 'Field_Eco'\n",
    "        }\n",
    "\n",
    "        # 创建新的哑变量列，并初始化为 0\n",
    "        for field_name in field_targets.values():\n",
    "            df[field_name] = 0\n",
    "\n",
    "        # 遍历 DataFrame 的每一行\n",
    "        for index, row in df.iterrows():\n",
    "            field_id_value = row['FieldID'] # 获取 FieldID 值\n",
    "\n",
    "            # 检查 FieldID 是否匹配任何目标学科 ID\n",
    "            for target_field_id, dummy_column_name in field_targets.items():\n",
    "                # 考虑到 FieldID 可能是浮点数或整数，进行类型转换后比较\n",
    "                if pd.notna(field_id_value) and float(field_id_value) == float(target_field_id):\n",
    "                    df.at[index, dummy_column_name] = 1 # 设置对应的哑变量列为 1\n",
    "                    break # 如果匹配到一个学科，则跳出内层循环\n",
    "\n",
    "        # 保存修改后的 DataFrame 到新的 TSV 文件\n",
    "        df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"已成功创建 Field_CS, Field_Eng, Field_Eco 哑变量。\")\n",
    "        print(f\"结果已保存到 {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\")\n",
    "    except KeyError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 缺少 'FieldID' 列，请检查文件结构。\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 定义输入和输出文件路径\n",
    "input_file_path = \"Merged_Cleaned_InTraFlow_Fund.tsv\"  # 修改为你的 Merged_Cleaned_InTraFlow_Fund.tsv 文件路径\n",
    "output_file_path = \"Merged_Cleaned_InTraFlow_Fund_Dummies.tsv\" # 输出文件路径\n",
    "\n",
    "# 调用函数执行创建哑变量操作\n",
    "create_field_dummies(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功对列 ['Team_size', 'C5', 'Patent_Count', 'Fund'] 进行对数转换，并保存到 Merged_Cleaned_InTraFlow_Fund_Dummies_Log.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_log_transformations(input_file_path, output_file_path, columns_to_log):\n",
    "    \"\"\"\n",
    "    对指定的列进行对数 (自然对数) 转换，并生成新的变量。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径 (Merged_Cleaned_InTraFlow_Fund_Dummies.tsv).\n",
    "        output_file_path (str): 输出 TSV 文件路径 (例如 Merged_Cleaned_InTraFlow_Fund_Dummies_Log.tsv).\n",
    "        columns_to_log (list): 需要进行对数转换的列名列表.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "        for column in columns_to_log:\n",
    "            if column not in df.columns:\n",
    "                print(f\"警告: 列 '{column}' 未在文件中找到，跳过对数转换。\")\n",
    "                continue\n",
    "\n",
    "            # 将列转换为数值类型，并将无法转换的值转换为 NaN\n",
    "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "            # 应用对数 (自然对数) 转换，使用 log1p 处理 0 值和负数\n",
    "            log_column_name = 'Log_' + column  # 新的对数转换后的列名\n",
    "            df[log_column_name] = np.log1p(df[column].fillna(0)) # fillna(0) to handle NaN values before log transform, log1p(x) = log(1+x)\n",
    "\n",
    "        # 保存修改后的 DataFrame 到新的 TSV 文件\n",
    "        df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"已成功对列 {columns_to_log} 进行对数转换，并保存到 {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\")\n",
    "    except KeyError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 缺少指定列，请检查文件结构。\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 定义输入和输出文件路径\n",
    "input_file_path = \"Merged_Cleaned_InTraFlow_Fund_Dummies.tsv\"  # 修改为你的输入文件路径\n",
    "output_file_path = \"Merged_Cleaned_InTraFlow_Fund_Dummies_Log.tsv\" # 输出文件路径\n",
    "columns_to_log = ['Team_size', 'C5', 'Patent_Count', 'Fund'] # 需要进行对数转换的列名列表\n",
    "\n",
    "# 调用函数执行对数转换操作\n",
    "calculate_log_transformations(input_file_path, output_file_path, columns_to_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 'Merged_Cleaned_InTraFlow.tsv' 的列名:\n",
      "  列 1: FieldID\n",
      "  列 2: PaperID\n",
      "  列 3: C_f\n",
      "  列 4: Year\n",
      "  列 5: Citation_Count\n",
      "  列 6: C10\n",
      "  列 7: C5\n",
      "  列 8: Team_size\n",
      "  列 9: Disruption\n",
      "  列 10: Atyp_Median_Z\n",
      "  列 11: SB_B\n",
      "  列 12: SB_T\n",
      "  列 13: InTraFlowf\n",
      "  列 14: InTraFlow\n",
      "  列 15: N_InTraFlow\n",
      "  列 16: Patent_Count\n",
      "  列 17: Fund\n",
      "  列 18: Field_CS\n",
      "  列 19: Field_Eng\n",
      "  列 20: Field_Eco\n",
      "  列 21: Log_Team_size\n",
      "  列 22: Log_C5\n",
      "  列 23: Log_Patent_Count\n",
      "  列 24: Log_Fund\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def get_tsv_column_names(file_path):\n",
    "    \"\"\"\n",
    "    读取 TSV 文件的 header 行并打印所有列名。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV 文件的路径.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as tsvfile:\n",
    "            reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "            header = next(reader, None)  # 读取第一行作为 header\n",
    "\n",
    "            if header:\n",
    "                print(f\"文件 '{file_path}' 的列名:\")\n",
    "                for i, column_name in enumerate(header):\n",
    "                    print(f\"  列 {i+1}: {column_name}\")\n",
    "            else:\n",
    "                print(f\"错误: 文件 '{file_path}' 没有 header 行或为空文件。\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{file_path}' 未找到，请检查文件路径。\")\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件 '{file_path}' 时发生错误: {e}\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 定义要读取列名的文件路径\n",
    "file_path_to_read_columns = \"Merged_Cleaned_InTraFlow.tsv\" # 修改为你的新生成的文件路径\n",
    "\n",
    "# 调用函数读取并打印列名\n",
    "get_tsv_column_names(file_path_to_read_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理文件时发生错误: x and y must have the same length.\n",
      "x and y must have the same length.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def calculate_and_export_correlations_descriptive(input_file_path, output_excel_path, variables):\n",
    "    \"\"\"\n",
    "    计算指定变量之间的相关性、均值和标准差，输出到 Excel 文件，并标记相关性显著性。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径.\n",
    "        output_excel_path (str): 输出 Excel 文件路径.\n",
    "        variables (list): 需要计算相关性和描述性统计的变量名列表.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "        # 检查变量是否存在于 DataFrame 中\n",
    "        missing_variables = [var for var in variables if var not in df.columns]\n",
    "        if missing_variables:\n",
    "            print(f\"警告: 以下变量未在文件中找到，将跳过这些变量: {missing_variables}\")\n",
    "            variables = [var for var in variables if var in df.columns]\n",
    "            if not variables:\n",
    "                print(\"错误: 指定的变量列表中没有找到任何有效的列名，无法计算相关性和描述性统计。\")\n",
    "                return\n",
    "\n",
    "        # 提取需要计算的变量列\n",
    "        data = df[variables]\n",
    "\n",
    "        # 计算相关性矩阵 (Pearson correlation)\n",
    "        correlation_matrix = data.corr(method='pearson')\n",
    "\n",
    "        # 计算 p-value 矩阵\n",
    "        p_value_matrix = pd.DataFrame(index=correlation_matrix.index, columns=correlation_matrix.columns)\n",
    "        for col in correlation_matrix.columns:\n",
    "            for row in correlation_matrix.index:\n",
    "                if row != col: # Avoid calculating p-value for correlation of variable with itself\n",
    "                    corr_val = correlation_matrix.loc[row, col]\n",
    "                    if pd.notna(corr_val): # Check for NaN correlation values\n",
    "                        p_value = stats.pearsonr(data[row].dropna(), data[col].dropna())[1] # Use dropna to handle potential NaNs\n",
    "                        p_value_matrix.loc[row, col] = p_value\n",
    "                    else:\n",
    "                        p_value_matrix.loc[row, col] = np.nan\n",
    "                else:\n",
    "                    p_value_matrix.loc[row, col] = np.nan # No p-value for self-correlation\n",
    "\n",
    "\n",
    "        # 定义显著性标记函数\n",
    "        def get_significance_stars(p_value):\n",
    "            if pd.isna(p_value): # Handle NaN p-values\n",
    "                return \"\"\n",
    "            if p_value < 0.001:\n",
    "                return \"***\"\n",
    "            elif p_value < 0.01:\n",
    "                return \"**\"\n",
    "            elif p_value < 0.05:\n",
    "                return \"*\"\n",
    "            else:\n",
    "                return \"\"\n",
    "\n",
    "        # 应用显著性标记到相关性矩阵\n",
    "        correlation_matrix_with_stars = correlation_matrix.copy()\n",
    "        for col in correlation_matrix.columns:\n",
    "            for row in correlation_matrix.index:\n",
    "                if row != col:\n",
    "                    p_val = p_value_matrix.loc[row, col]\n",
    "                    stars = get_significance_stars(p_val)\n",
    "                    correlation_matrix_with_stars.loc[row, col] = f\"{correlation_matrix.loc[row, col]:.2f}{stars}\" # Format to 2 decimal places\n",
    "\n",
    "        # 计算均值和标准差\n",
    "        descriptive_stats = pd.DataFrame({\n",
    "            'Mean': data.mean(),\n",
    "            'Standard Deviation': data.std()\n",
    "        })\n",
    "\n",
    "        # 将结果输出到 Excel 文件\n",
    "        with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "            correlation_matrix_with_stars.to_excel(writer, sheet_name='Correlation Matrix', index=True)\n",
    "            correlation_matrix.to_excel(writer, sheet_name='Correlation Values (Raw)', index=True)\n",
    "            p_value_matrix.to_excel(writer, sheet_name='P-Values', index=True)\n",
    "            descriptive_stats.to_excel(writer, sheet_name='Descriptive Statistics', index=True) # 添加描述性统计到新的 sheet\n",
    "\n",
    "        print(f\"已成功计算变量相关性、均值和标准差，并输出到 Excel 文件: {output_excel_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\")\n",
    "    except KeyError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 缺少指定列，请检查文件结构。\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 定义文件路径和变量列表\n",
    "input_file_path = \"Merged_Cleaned_InTraFlow.tsv\"  # 修改为你的输入文件路径\n",
    "output_excel_path = \"Correlation_Matrix_Descriptive.xlsx\" # 输出 Excel 文件路径 (修改了输出文件名)\n",
    "variables_to_correlate_descriptive = [\n",
    "    'InTraFlow', 'N_InTraFlow', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'Field_CS', 'Field_Eng', 'Field_Eco'\n",
    "]\n",
    "\n",
    "# 调用函数计算相关性、描述性统计并输出到 Excel\n",
    "calculate_and_export_correlations_descriptive(input_file_path, output_excel_path, variables_to_correlate_descriptive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分析基于 Complete Cases: 符合所有变量均非空值的行数: 3012743\n",
      "已成功计算 Complete Case 变量相关性、均值和标准差，并输出到 Excel 文件: Correlation_Matrix_Descriptive_CompleteCases_2.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def calculate_correlations_descriptive_complete_cases_corrected_excel_sheet_names(input_file_path, output_excel_path, variables):\n",
    "    \"\"\"\n",
    "    计算指定变量的 complete case 相关性、均值和标准差，输出到 Excel 文件，并标记相关性显著性.\n",
    "    Uses only rows where ALL specified variables have non-missing values (complete cases).\n",
    "    Corrected version to handle FutureWarning and Excel sheet name length limit.\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径.\n",
    "        output_excel_path (str): 输出 Excel 文件路径.\n",
    "        variables (list): 需要计算相关性和描述性统计的变量名列表.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "        # 检查变量是否存在于 DataFrame 中\n",
    "        missing_variables = [var for var in variables if var not in df.columns]\n",
    "        if missing_variables:\n",
    "            print(f\"警告: 以下变量未在文件中找到，将跳过这些变量: {missing_variables}\")\n",
    "            variables = [var for var in variables if var in df.columns]\n",
    "            if not variables:\n",
    "                print(\"错误: 指定的变量列表中没有找到任何有效的列名，无法计算相关性和描述性统计。\")\n",
    "                return\n",
    "\n",
    "        # 提取需要计算的变量列\n",
    "        data = df[variables].copy()\n",
    "\n",
    "        # Convert all relevant columns to numeric, coercing errors to NaN\n",
    "        for var in variables:\n",
    "            data[var] = pd.to_numeric(data[var], errors='coerce')\n",
    "\n",
    "        # Filter out rows where ANY of the specified variables are NaN (complete case analysis)\n",
    "        complete_data = data.dropna(subset=variables)\n",
    "\n",
    "        print(f\"分析基于 Complete Cases: 符合所有变量均非空值的行数: {len(complete_data)}\")\n",
    "\n",
    "        if complete_data.empty:\n",
    "            print(\"警告: 没有 Complete Cases (所有指定变量均非空的行)，无法计算相关性和描述性统计。\")\n",
    "            return\n",
    "\n",
    "        # 计算相关性矩阵 (Pearson correlation) on complete cases\n",
    "        correlation_matrix = complete_data.corr(method='pearson')\n",
    "\n",
    "        # 计算 p-value 矩阵 on complete cases\n",
    "        p_value_matrix = pd.DataFrame(index=correlation_matrix.index, columns=correlation_matrix.columns)\n",
    "        for col in correlation_matrix.columns:\n",
    "            for row in correlation_matrix.index:\n",
    "                if row != col: # Avoid calculating p-value for correlation of variable with itself\n",
    "                    corr_val = correlation_matrix.loc[row, col]\n",
    "                    if pd.notna(corr_val): # Check for NaN correlation values\n",
    "                        series_x = complete_data[row].dropna() # dropna here is redundant as complete_data is already dropna, but kept for consistency\n",
    "                        series_y = complete_data[col].dropna() # dropna here is redundant as complete_data is already dropna, but kept for consistency\n",
    "\n",
    "                        if len(series_x) == len(series_y) and len(series_x) > 0:\n",
    "                            try:\n",
    "                                p_value = stats.pearsonr(series_x, series_y)[1]\n",
    "                                p_value_matrix.loc[row, col] = p_value\n",
    "                            except ValueError as ve:\n",
    "                                print(f\"警告: ValueError in pearsonr for '{row}' and '{col}': {ve}. Setting p-value to NaN.\")\n",
    "                                p_value_matrix.loc[row, col] = np.nan\n",
    "                            except Exception as e:\n",
    "                                print(f\"警告: Unexpected error in pearsonr for '{row}' and '{col}': {e}. Setting p-value to NaN.\")\n",
    "                                p_value_matrix.loc[row, col] = np.nan\n",
    "                        else:\n",
    "                            print(f\"警告: 变量 '{row}' 和 '{col}' 在Complete Cases中去除 NaN 值后长度不一致 或 为空，跳过 p-value 计算。\")\n",
    "                            p_value_matrix.loc[row, col] = np.nan\n",
    "                    else:\n",
    "                        p_value_matrix.loc[row, col] = np.nan\n",
    "                else:\n",
    "                    p_value_matrix.loc[row, col] = np.nan # No p-value for self-correlation\n",
    "\n",
    "        # 定义显著性标记函数 (no change needed)\n",
    "        def get_significance_stars(p_value):\n",
    "            if pd.isna(p_value): # Handle NaN p-values\n",
    "                return \"\"\n",
    "            if p_value < 0.001:\n",
    "                return \"***\"\n",
    "            elif p_value < 0.01:\n",
    "                return \"**\"\n",
    "            elif p_value < 0.05:\n",
    "                return \"*\"\n",
    "            else:\n",
    "                return \"\"\n",
    "\n",
    "        # 应用显著性标记到相关性矩阵\n",
    "        correlation_matrix_with_stars = correlation_matrix.copy().astype(str) # Explicitly cast to string type HERE\n",
    "        for col in correlation_matrix.columns:\n",
    "            for row in correlation_matrix.index:\n",
    "                if row != col:\n",
    "                    p_val = p_value_matrix.loc[row, col]\n",
    "                    stars = get_significance_stars(p_val)\n",
    "                    correlation_matrix_with_stars.loc[row, col] = f\"{correlation_matrix.loc[row, col]:.2f}{stars}\" # Format to 2 decimal places\n",
    "\n",
    "        # 计算均值和标准差 on complete cases (no change needed)\n",
    "        descriptive_stats = pd.DataFrame({\n",
    "            'Mean': complete_data.mean(),\n",
    "            'Standard Deviation': complete_data.std()\n",
    "        })\n",
    "\n",
    "        # 将结果输出到 Excel 文件 (Sheet names shortened to be <= 31 chars)\n",
    "        with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "            correlation_matrix_with_stars.to_excel(writer, sheet_name='Corr Matrix (Complete)', index=True) # Shortened sheet name\n",
    "            correlation_matrix.to_excel(writer, sheet_name='Corr Values (Complete)', index=True) # Shortened sheet name\n",
    "            p_value_matrix.to_excel(writer, sheet_name='P-Values (Complete)', index=True) # Shortened sheet name\n",
    "            descriptive_stats.to_excel(writer, sheet_name='Descriptive Stats (Complete)', index=True) # Shortened sheet name\n",
    "\n",
    "        print(f\"已成功计算 Complete Case 变量相关性、均值和标准差，并输出到 Excel 文件: {output_excel_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\")\n",
    "    except KeyError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 缺少指定列，请检查文件结构。\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 定义文件路径和变量列表 (no change needed)\n",
    "input_file_path = \"Merged_Cleaned_InTraFlow.tsv\"  # 修改为你的输入文件路径\n",
    "output_excel_path = \"Correlation_Matrix_Descriptive_CompleteCases_2.xlsx\" # 输出 Excel 文件路径 (修改了输出文件名)\n",
    "variables_to_correlate_descriptive_complete_cases = [\n",
    "    'InTraFlow', 'N_InTraFlow', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'Field_CS', 'Field_Eng', 'Field_Eco'\n",
    "]\n",
    "\n",
    "# 调用函数计算相关性、描述性统计并输出到 Excel (no change needed)\n",
    "calculate_correlations_descriptive_complete_cases_corrected_excel_sheet_names(input_file_path, output_excel_path, variables_to_correlate_descriptive_complete_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "执行 Model 1 回归时发生错误: exog contains inf or nans\n",
      "执行 Model 2 回归时发生错误: exog contains inf or nans\n",
      "执行 Model 3 回归时发生错误: exog contains inf or nans\n",
      "执行 Model 4 回归时发生错误: exog contains inf or nans\n",
      "执行 Model 5 回归时发生错误: exog contains inf or nans\n",
      "OLS 回归结果已成功输出到 Excel 文件: OLS_Regression_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def perform_ols_regressions_and_export(input_file_path, output_excel_path):\n",
    "    \"\"\"\n",
    "    执行 5 个 OLS 回归模型，并将结果输出到 Excel 文件。\n",
    "\n",
    "    Model1：Disruption ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "    Model2：Atyp_Median_Z ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "    Model3：SB_B ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "    Model4：SB_T ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "    Model5：Log_C5 ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径.\n",
    "        output_excel_path (str): 输出 Excel 文件路径.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "        # 定义因变量和自变量\n",
    "        dependent_variables = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "        independent_variables = ['InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', 'Field_CS', 'Field_Eng', 'Field_Eco']\n",
    "\n",
    "        results_dict = {} # 用于存储每个模型的回归结果\n",
    "\n",
    "        for model_num, dep_var in enumerate(dependent_variables, 1):\n",
    "            model_name = f'Model {model_num}'\n",
    "            formula = f\"{dep_var} ~ {' + '.join(independent_variables)}\"\n",
    "\n",
    "            try:\n",
    "                model = smf.ols(formula, data=df).fit(robust='HC1') # 使用稳健标准误 (HC1)\n",
    "                results_summary = model.summary()\n",
    "                params = model.params\n",
    "                bse = model.bse\n",
    "                pvalues = model.pvalues\n",
    "                nobs = model.nobs\n",
    "                rsquared_adj = model.rsquared_adj\n",
    "\n",
    "                model_results = {}\n",
    "                for var in independent_variables + ['Intercept']: # Include Intercept for constant term\n",
    "                    if var == 'Intercept':\n",
    "                        var_name = 'Constant' # Rename Intercept to Constant for output\n",
    "                    else:\n",
    "                        var_name = var\n",
    "\n",
    "                    if var_name in params: # Check if variable exists in model results\n",
    "                        coef = params[var_name]\n",
    "                        se = bse[var_name]\n",
    "                        p_val = pvalues[var_name]\n",
    "\n",
    "                        stars = ''\n",
    "                        if p_val < 0.001:\n",
    "                            stars = '***'\n",
    "                        elif p_val < 0.01:\n",
    "                            stars = '**'\n",
    "                        elif p_val < 0.05:\n",
    "                            stars = '*'\n",
    "\n",
    "                        model_results[var_name] = {\n",
    "                            'Coefficient': f'{coef:.4f}{stars}',\n",
    "                            'Std. Error': f'({se:.4f})',\n",
    "                            'P-value': f'{p_val:.4f}' # Keep p-value for potential further use if needed\n",
    "                        }\n",
    "                    else: # Handle cases where a variable might be dropped due to collinearity etc.\n",
    "                        model_results[var_name] = {\n",
    "                            'Coefficient': 'NA',\n",
    "                            'Std. Error': 'NA',\n",
    "                            'P-value': 'NA'\n",
    "                        }\n",
    "\n",
    "\n",
    "                model_output = pd.DataFrame(model_results).T # Transpose to have variables as rows\n",
    "                model_output.insert(0, 'Variables', model_output.index) # Add Variables column\n",
    "                model_output = model_output.reset_index(drop=True) # Reset index\n",
    "\n",
    "                # 添加 N 和 Adjusted R-squared\n",
    "                n_row = pd.DataFrame([{'Variables': 'N', 'Coefficient': f'{int(nobs):,}', 'Std. Error': '', 'P-value': ''}]) # Format N with comma separator\n",
    "                r2_adj_row = pd.DataFrame([{'Variables': 'Adjusted R²', 'Coefficient': f'{rsquared_adj:.3f}', 'Std. Error': '', 'P-value': ''}])\n",
    "\n",
    "                model_output = pd.concat([model_output, n_row, r2_adj_row], ignore_index=True)\n",
    "\n",
    "                results_dict[model_name] = model_output\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"执行 {model_name} 回归时发生错误: {e}\")\n",
    "                results_dict[model_name] = pd.DataFrame([{'Variables': 'Error', 'Coefficient': str(e), 'Std. Error': '', 'P-value': ''}], index=[0]) # Output error message\n",
    "\n",
    "\n",
    "        # 输出到 Excel\n",
    "        with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "            for model_name, result_df in results_dict.items():\n",
    "                result_df.to_excel(writer, sheet_name=model_name, index=False) # 每个模型一个 sheet\n",
    "\n",
    "        print(f\"OLS 回归结果已成功输出到 Excel 文件: {output_excel_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\")\n",
    "    except KeyError as e:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 缺少列: {e}, 请检查文件结构。\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 定义文件路径\n",
    "input_file_path = \"Merged_Cleaned_InTraFlow.tsv\"  # 修改为你的输入文件路径\n",
    "output_excel_path = \"OLS_Regression_Results.xlsx\" # 输出 Excel 文件路径\n",
    "\n",
    "# 调用函数执行 OLS 回归并输出结果\n",
    "perform_ols_regressions_and_export(input_file_path, output_excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 1: 移除 NaN/Inf 值后，分析 6881165 行数据。\n",
      "模型 2: 移除 NaN/Inf 值后，分析 3790718 行数据。\n",
      "模型 3: 移除 NaN/Inf 值后，分析 4179612 行数据。\n",
      "模型 4: 移除 NaN/Inf 值后，分析 4179612 行数据。\n",
      "模型 5: 移除 NaN/Inf 值后，分析 11569428 行数据。\n",
      "OLS 回归结果已成功输出到 Excel 文件: OLS_Regression_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np  # 导入 numpy 用于处理 NaN/inf 检查\n",
    "\n",
    "def perform_ols_regressions_and_export_corrected_nan_inf_zh(input_file_path, output_excel_path):\n",
    "    \"\"\"\n",
    "    执行 5 个 OLS 回归模型，并将结果输出到 Excel 文件。\n",
    "    **修改说明：** 修正版本，通过移除相关变量中包含 NaN 或 inf 值的行来处理 \"exog contains inf or nans\" 错误。\n",
    "\n",
    "    Model1：Disruption ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "    Model2：Atyp_Median_Z ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "    Model3：SB_B ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "    Model4：SB_T ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "    Model5：Log_C5 ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径.\n",
    "        output_excel_path (str): 输出 Excel 文件路径.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "        # 定义因变量和自变量\n",
    "        dependent_variables = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "        independent_variables = ['InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', 'Field_CS', 'Field_Eng', 'Field_Eco']\n",
    "\n",
    "        results_dict = {} # 用于存储每个模型的回归结果\n",
    "\n",
    "        for model_num, dep_var in enumerate(dependent_variables, 1):\n",
    "            model_name = f'模型 {model_num}' # 修改为中文模型名\n",
    "            formula = f\"{dep_var} ~ {' + '.join(independent_variables)}\"\n",
    "\n",
    "            # 准备模型数据，去除 NaN 和 inf 行\n",
    "            model_vars = [dep_var] + independent_variables\n",
    "            model_data = df[model_vars].replace([np.inf, -np.inf], np.nan).dropna() # 先用 NaN 替换 inf，然后删除 NaN 行\n",
    "\n",
    "            print(f\"模型 {model_num}: 移除 NaN/Inf 值后，分析 {len(model_data)} 行数据。\") # 修改为中文输出\n",
    "\n",
    "            try:\n",
    "                model = smf.ols(formula, data=model_data).fit(robust='HC1') # 使用稳健标准误 (HC1)\n",
    "                results_summary = model.summary()\n",
    "                params = model.params\n",
    "                bse = model.bse\n",
    "                pvalues = model.pvalues\n",
    "                nobs = model.nobs\n",
    "                rsquared_adj = model.rsquared_adj\n",
    "\n",
    "                model_results = {}\n",
    "                for var in independent_variables + ['Intercept']: # 包括截距项作为常数项\n",
    "                    if var == 'Intercept':\n",
    "                        var_name = 'Constant' # 将 Intercept 重命名为 Constant 以便输出\n",
    "                    else:\n",
    "                        var_name = var\n",
    "\n",
    "                    if var_name in params: # 检查模型结果中是否存在变量\n",
    "                        coef = params[var_name]\n",
    "                        se = bse[var_name]\n",
    "                        p_val = pvalues[var_name]\n",
    "\n",
    "                        stars = ''\n",
    "                        if p_val < 0.001:\n",
    "                            stars = '***'\n",
    "                        elif p_val < 0.01:\n",
    "                            stars = '**'\n",
    "                        elif p_val < 0.05:\n",
    "                            stars = '*'\n",
    "\n",
    "                        model_results[var_name] = {\n",
    "                            'Coefficient': f'{coef:.4f}{stars}',\n",
    "                            'Std. Error': f'({se:.4f})',\n",
    "                            'P-value': f'{p_val:.4f}' # 保留 p-value 以便后续可能使用\n",
    "                        }\n",
    "                    else: # 处理由于共线性等原因变量可能被删除的情况\n",
    "                        model_results[var_name] = {\n",
    "                            'Coefficient': 'NA',\n",
    "                            'Std. Error': 'NA',\n",
    "                            'P-value': 'NA'\n",
    "                        }\n",
    "\n",
    "\n",
    "                model_output = pd.DataFrame(model_results).T # 转置以使变量作为行\n",
    "                model_output.insert(0, 'Variables', model_output.index) # 添加 Variables 列\n",
    "                model_output = model_output.reset_index(drop=True) # 重置索引\n",
    "\n",
    "                # 添加 N 和 Adjusted R-squared\n",
    "                n_row = pd.DataFrame([{'Variables': 'N', 'Coefficient': f'{int(nobs):,}', 'Std. Error': '', 'P-value': ''}]) # 格式化 N，使用逗号分隔符\n",
    "                r2_adj_row = pd.DataFrame([{'Variables': 'Adjusted R²', 'Coefficient': f'{rsquared_adj:.3f}', 'Std. Error': '', 'P-value': ''}])\n",
    "\n",
    "                model_output = pd.concat([model_output, n_row, r2_adj_row], ignore_index=True)\n",
    "\n",
    "                results_dict[model_name] = model_output\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"执行 {model_name} 回归时发生错误: {e}\") # 修改为中文输出\n",
    "                results_dict[model_name] = pd.DataFrame([{'Variables': 'Error', 'Coefficient': str(e), 'Std. Error': '', 'P-value': ''}], index=[0]) # 输出错误信息\n",
    "\n",
    "\n",
    "        # 输出到 Excel\n",
    "        with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "            for model_name, result_df in results_dict.items():\n",
    "                result_df.to_excel(writer, sheet_name=model_name, index=False) # 每个模型一个 sheet，sheet 名为模型名\n",
    "\n",
    "        print(f\"OLS 回归结果已成功输出到 Excel 文件: {output_excel_path}\") # 修改为中文输出\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\") # 修改为中文输出\n",
    "    except KeyError as e:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 缺少列: {e}, 请检查文件结构。\") # 修改为中文输出\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\") # 修改为中文输出\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 定义文件路径\n",
    "input_file_path = \"Merged_Cleaned_InTraFlow.tsv\"  # 修改为你的输入文件路径\n",
    "output_excel_path = \"OLS_Regression_Results.xlsx\" # 输出 Excel 文件路径\n",
    "\n",
    "# 调用函数执行 OLS 回归并输出结果\n",
    "perform_ols_regressions_and_export_corrected_nan_inf_zh(input_file_path, output_excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 1: 移除 NaN/Inf 值后，分析 6881165 行数据。\n",
      "模型 2: 移除 NaN/Inf 值后，分析 3790718 行数据。\n",
      "模型 3: 移除 NaN/Inf 值后，分析 4179612 行数据。\n",
      "模型 4: 移除 NaN/Inf 值后，分析 4179612 行数据。\n",
      "模型 5: 移除 NaN/Inf 值后，分析 11569428 行数据。\n",
      "OLS 回归结果已成功输出到 Excel 文件: OLS_Regression_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np  # 导入 numpy 用于处理 NaN/inf 检查\n",
    "\n",
    "def perform_ols_regressions_and_export_corrected_nan_inf_zh(input_file_path, output_excel_path):\n",
    "    \"\"\"\n",
    "    执行 5 个 OLS 回归模型，并将结果输出到 Excel 文件。\n",
    "    **修改说明：** 修正版本，通过移除相关变量中包含 NaN 或 inf 值的行来处理 \"exog contains inf or nans\" 错误，并**解决多重共线性问题**。\n",
    "    **中文输出版本。**\n",
    "\n",
    "    Model1：Disruption ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng  (**移除 Field_Eco**)\n",
    "    Model2：Atyp_Median_Z ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "    Model3：SB_B ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "    Model4：SB_T ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "    Model5：Log_C5 ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng + Field_Eco\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径.\n",
    "        output_excel_path (str): 输出 Excel 文件路径.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "        # 定义因变量和自变量\n",
    "        dependent_variables = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "        independent_variables_common = ['InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', 'Field_CS', 'Field_Eng'] # 移除 Field_Eco，作为基准类别\n",
    "        independent_variables_all_fields = independent_variables_common + ['Field_Eco'] # 包含所有学科哑变量的列表，用于 Model 2-5 (如果需要)\n",
    "\n",
    "        results_dict = {} # 用于存储每个模型的回归结果\n",
    "\n",
    "        for model_num, dep_var in enumerate(dependent_variables, 1):\n",
    "            model_name = f'模型 {model_num}' # 修改为中文模型名\n",
    "            if model_num == 1: # Model 1 公式 - 移除 Field_Eco 以解决多重共线性\n",
    "                formula = f\"{dep_var} ~ {' + '.join(independent_variables_common)}\" # 使用移除 Field_Eco 的自变量列表\n",
    "            else: # Models 2-5 - 保留所有学科哑变量 (如果需要与其他模型保持一致，但通常所有模型都应采用相同基准类别)\n",
    "                formula = f\"{dep_var} ~ {' + '.join(independent_variables_all_fields)}\" # 使用包含所有学科哑变量的列表\n",
    "\n",
    "            # 准备模型数据，去除 NaN 和 inf 行\n",
    "            model_vars = [dep_var]\n",
    "            if model_num == 1:\n",
    "                model_vars.extend(independent_variables_common)\n",
    "            else:\n",
    "                model_vars.extend(independent_variables_all_fields)\n",
    "\n",
    "            model_data = df[model_vars].replace([np.inf, -np.inf], np.nan).dropna() # 先用 NaN 替换 inf，然后删除 NaN 行\n",
    "\n",
    "            print(f\"模型 {model_num}: 移除 NaN/Inf 值后，分析 {len(model_data)} 行数据。\") # 修改为中文输出\n",
    "\n",
    "            try:\n",
    "                model = smf.ols(formula, data=model_data).fit(robust='HC1') # 使用稳健标准误 (HC1)\n",
    "                results_summary = model.summary()\n",
    "                params = model.params\n",
    "                bse = model.bse\n",
    "                pvalues = model.pvalues\n",
    "                nobs = model.nobs\n",
    "                rsquared_adj = model.rsquared_adj\n",
    "\n",
    "                model_results = {}\n",
    "                independent_vars_for_output = independent_variables_common if model_num == 1 else independent_variables_all_fields # 根据模型选择自变量列表用于输出\n",
    "                for var in independent_vars_for_output + ['Intercept']: # 包括截距项作为常数项\n",
    "                    if var == 'Intercept':\n",
    "                        var_name = 'Constant' # 将 Intercept 重命名为 Constant 以便输出\n",
    "                    else:\n",
    "                        var_name = var\n",
    "\n",
    "                    if var_name in params: # 检查模型结果中是否存在变量\n",
    "                        coef = params[var_name]\n",
    "                        se = bse[var_name]\n",
    "                        p_val = pvalues[var_name]\n",
    "\n",
    "                        stars = ''\n",
    "                        if p_val < 0.001:\n",
    "                            stars = '***'\n",
    "                        elif p_val < 0.01:\n",
    "                            stars = '**'\n",
    "                        elif p_val < 0.05:\n",
    "                            stars = '*'\n",
    "\n",
    "                        model_results[var_name] = {\n",
    "                            'Coefficient': f'{coef:.4f}{stars}',\n",
    "                            'Std. Error': f'({se:.4f})',\n",
    "                            'P-value': f'{p_val:.4f}' # 保留 p-value 以便后续可能使用\n",
    "                        }\n",
    "                    else: # 处理由于共线性等原因变量可能被删除的情况\n",
    "                        model_results[var_name] = {\n",
    "                            'Coefficient': 'NA',\n",
    "                            'Std. Error': 'NA',\n",
    "                            'P-value': 'NA'\n",
    "                        }\n",
    "\n",
    "\n",
    "                model_output = pd.DataFrame(model_results).T # 转置以使变量作为行\n",
    "                model_output.insert(0, 'Variables', model_output.index) # 添加 Variables 列\n",
    "                model_output = model_output.reset_index(drop=True) # 重置索引\n",
    "\n",
    "                # 添加 N 和 Adjusted R-squared\n",
    "                n_row = pd.DataFrame([{'Variables': 'N', 'Coefficient': f'{int(nobs):,}', 'Std. Error': '', 'P-value': ''}]) # 格式化 N，使用逗号分隔符\n",
    "                r2_adj_row = pd.DataFrame([{'Variables': 'Adjusted R²', 'Coefficient': f'{rsquared_adj:.3f}', 'Std. Error': '', 'P-value': ''}])\n",
    "\n",
    "                model_output = pd.concat([model_output, n_row, r2_adj_row], ignore_index=True)\n",
    "\n",
    "                results_dict[model_name] = model_output\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"执行 {model_name} 回归时发生错误: {e}\") # 修改为中文输出\n",
    "                results_dict[model_name] = pd.DataFrame([{'Variables': 'Error', 'Coefficient': str(e), 'Std. Error': '', 'P-value': ''}], index=[0]) # 输出错误信息\n",
    "\n",
    "\n",
    "        # 输出到 Excel\n",
    "        with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "            for model_name, result_df in results_dict.items():\n",
    "                result_df.to_excel(writer, sheet_name=model_name, index=False) # 每个模型一个 sheet，sheet 名为模型名\n",
    "\n",
    "        print(f\"OLS 回归结果已成功输出到 Excel 文件: {output_excel_path}\") # 修改为中文输出\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\") # 修改为中文输出\n",
    "    except KeyError as e:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 缺少列: {e}, 请检查文件结构。\") # 修改为中文输出\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\") # 修改为中文输出\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 定义文件路径\n",
    "input_file_path = \"Merged_Cleaned_InTraFlow.tsv\"  # 修改为你的输入文件路径\n",
    "output_excel_path = \"OLS_Regression_Results.xlsx\" # 输出 Excel 文件路径\n",
    "\n",
    "# 调用函数执行 OLS 回归并输出结果\n",
    "perform_ols_regressions_and_export_corrected_nan_inf_zh(input_file_path, output_excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 1: 移除 NaN/Inf 值后，分析 6881165 行数据。\n",
      "模型 2: 移除 NaN/Inf 值后，分析 3790718 行数据。\n",
      "模型 3: 移除 NaN/Inf 值后，分析 4179612 行数据。\n",
      "模型 4: 移除 NaN/Inf 值后，分析 4179612 行数据。\n",
      "模型 5: 移除 NaN/Inf 值后，分析 11569428 行数据。\n",
      "OLS 回归结果已成功输出到 Excel 文件: OLS_Regression_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np  # 导入 numpy 用于处理 NaN/inf 检查\n",
    "\n",
    "def perform_ols_regressions_and_export_corrected_nan_inf_zh(input_file_path, output_excel_path):\n",
    "    \"\"\"\n",
    "    执行 5 个 OLS 回归模型，并将结果输出到 Excel 文件。\n",
    "    **修改说明：** 修正版本，通过移除相关变量中包含 NaN 或 inf 值的行来处理 \"exog contains inf or nans\" 错误，并**解决所有模型的多重共线性问题**。\n",
    "    **所有模型均移除基准类别哑变量 Field_Eco，保持基准类别一致性。**\n",
    "    **中文输出版本。**\n",
    "\n",
    "    Model1：Disruption ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng  (**移除 Field_Eco**)\n",
    "    Model2：Atyp_Median_Z ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng  (**移除 Field_Eco**)\n",
    "    Model3：SB_B ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng  (**移除 Field_Eco**)\n",
    "    Model4：SB_T ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng  (**移除 Field_Eco**)\n",
    "    Model5：Log_C5 ~ InTraFlow + Log_Team_size + Log_Patent_Count + Log_Fund + Field_CS + Field_Eng  (**移除 Field_Eco**)\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径.\n",
    "        output_excel_path (str): 输出 Excel 文件路径.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "        # 定义因变量和自变量\n",
    "        dependent_variables = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "        independent_variables_common = ['InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', 'Field_CS', 'Field_Eng'] # 移除 Field_Eco，作为基准类别\n",
    "\n",
    "        results_dict = {} # 用于存储每个模型的回归结果\n",
    "\n",
    "        for model_num, dep_var in enumerate(dependent_variables, 1):\n",
    "            model_name = f'模型 {model_num}' # 修改为中文模型名\n",
    "            # **所有模型公式均移除 Field_Eco，解决多重共线性并保持基准类别一致**\n",
    "            formula = f\"{dep_var} ~ {' + '.join(independent_variables_common)}\" # 所有模型都使用移除 Field_Eco 的自变量列表\n",
    "\n",
    "            # 准备模型数据，去除 NaN 和 inf 行\n",
    "            model_vars = [dep_var] + independent_variables_common # 所有模型都使用相同的自变量列表\n",
    "            model_data = df[model_vars].replace([np.inf, -np.inf], np.nan).dropna() # 先用 NaN 替换 inf，然后删除 NaN 行\n",
    "\n",
    "            print(f\"模型 {model_num}: 移除 NaN/Inf 值后，分析 {len(model_data)} 行数据。\") # 修改为中文输出\n",
    "\n",
    "            try:\n",
    "                model = smf.ols(formula, data=model_data).fit(robust='HC1') # 使用稳健标准误 (HC1)\n",
    "                results_summary = model.summary()\n",
    "                params = model.params\n",
    "                bse = model.bse\n",
    "                pvalues = model.pvalues\n",
    "                nobs = model.nobs\n",
    "                rsquared_adj = model.rsquared_adj\n",
    "\n",
    "                model_results = {}\n",
    "                for var in independent_variables_common + ['Intercept']: # 包括截距项作为常数项 (自变量列表已统一)\n",
    "                    if var == 'Intercept':\n",
    "                        var_name = 'Constant' # 将 Intercept 重命名为 Constant 以便输出\n",
    "                    else:\n",
    "                        var_name = var\n",
    "\n",
    "                    if var_name in params: # 检查模型结果中是否存在变量\n",
    "                        coef = params[var_name]\n",
    "                        se = bse[var_name]\n",
    "                        p_val = pvalues[var_name]\n",
    "\n",
    "                        stars = ''\n",
    "                        if p_val < 0.001:\n",
    "                            stars = '***'\n",
    "                        elif p_val < 0.01:\n",
    "                            stars = '**'\n",
    "                        elif p_val < 0.05:\n",
    "                            stars = '*'\n",
    "\n",
    "                        model_results[var_name] = {\n",
    "                            'Coefficient': f'{coef:.4f}{stars}',\n",
    "                            'Std. Error': f'({se:.4f})',\n",
    "                            'P-value': f'{p_val:.4f}' # 保留 p-value 以便后续可能使用\n",
    "                        }\n",
    "                    else: # 处理由于共线性等原因变量可能被删除的情况\n",
    "                        model_results[var_name] = {\n",
    "                            'Coefficient': 'NA',\n",
    "                            'Std. Error': 'NA',\n",
    "                            'P-value': 'NA'\n",
    "                        }\n",
    "\n",
    "\n",
    "                model_output = pd.DataFrame(model_results).T # 转置以使变量作为行\n",
    "                model_output.insert(0, 'Variables', model_output.index) # 添加 Variables 列\n",
    "                model_output = model_output.reset_index(drop=True) # 重置索引\n",
    "\n",
    "                # 添加 N 和 Adjusted R-squared\n",
    "                n_row = pd.DataFrame([{'Variables': 'N', 'Coefficient': f'{int(nobs):,}', 'Std. Error': '', 'P-value': ''}]) # 格式化 N，使用逗号分隔符\n",
    "                r2_adj_row = pd.DataFrame([{'Variables': 'Adjusted R²', 'Coefficient': f'{rsquared_adj:.3f}', 'Std. Error': '', 'P-value': ''}])\n",
    "\n",
    "                model_output = pd.concat([model_output, n_row, r2_adj_row], ignore_index=True)\n",
    "\n",
    "                results_dict[model_name] = model_output\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"执行 {model_name} 回归时发生错误: {e}\") # 修改为中文输出\n",
    "                results_dict[model_name] = pd.DataFrame([{'Variables': 'Error', 'Coefficient': str(e), 'Std. Error': '', 'P-value': ''}], index=[0]) # 输出错误信息\n",
    "\n",
    "\n",
    "        # 输出到 Excel\n",
    "        with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "            for model_name, result_df in results_dict.items():\n",
    "                result_df.to_excel(writer, sheet_name=model_name, index=False) # 每个模型一个 sheet，sheet 名为模型名\n",
    "\n",
    "        print(f\"OLS 回归结果已成功输出到 Excel 文件: {output_excel_path}\") # 修改为中文输出\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\") # 修改为中文输出\n",
    "    except KeyError as e:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 缺少列: {e}, 请检查文件结构。\") # 修改为中文输出\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\") # 修改为中文输出\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 定义文件路径\n",
    "input_file_path = \"Merged_Cleaned_InTraFlow.tsv\"  # 修改为你的输入文件路径\n",
    "output_excel_path = \"OLS_Regression_Results.xlsx\" # 输出 Excel 文件路径\n",
    "\n",
    "# 调用函数执行 OLS 回归并输出结果\n",
    "perform_ols_regressions_and_export_corrected_nan_inf_zh(input_file_path, output_excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据集大小: (11613323, 24)\n",
      "\n",
      "各变量缺失值情况:\n",
      "Disruption: 缺失值=4711622, 无穷值=0\n",
      "Atyp_Median_Z: 缺失值=7816176, 无穷值=0\n",
      "SB_B: 缺失值=7423844, 无穷值=0\n",
      "SB_T: 缺失值=7423844, 无穷值=0\n",
      "Log_C5: 缺失值=0, 无穷值=0\n",
      "InTraFlow: 缺失值=0, 无穷值=43895\n",
      "Log_Team_size: 缺失值=0, 无穷值=0\n",
      "Log_Patent_Count: 缺失值=0, 无穷值=0\n",
      "Log_Fund: 缺失值=0, 无穷值=0\n",
      "Field_CS: 缺失值=0, 无穷值=0\n",
      "Field_Eng: 缺失值=0, 无穷值=0\n",
      "\n",
      "自变量相关性矩阵:\n",
      "                  InTraFlow  Log_Team_size  Log_Patent_Count  Log_Fund  \\\n",
      "InTraFlow          1.000000      -0.127807         -0.100689 -0.039634   \n",
      "Log_Team_size     -0.127807       1.000000          0.036887  0.090651   \n",
      "Log_Patent_Count  -0.100689       0.036887          1.000000  0.031096   \n",
      "Log_Fund          -0.039634       0.090651          0.031096  1.000000   \n",
      "Field_CS          -0.307229       0.182514          0.052576  0.066168   \n",
      "Field_Eng          0.307117      -0.023063          0.001021 -0.045859   \n",
      "\n",
      "                  Field_CS  Field_Eng  \n",
      "InTraFlow        -0.307229   0.307117  \n",
      "Log_Team_size     0.182514  -0.023063  \n",
      "Log_Patent_Count  0.052576   0.001021  \n",
      "Log_Fund          0.066168  -0.045859  \n",
      "Field_CS          1.000000  -0.742547  \n",
      "Field_Eng        -0.742547   1.000000  \n",
      "\n",
      "==================================================\n",
      "处理 Model 1: Disruption\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 6881165\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  15.472618\n",
      "1         InTraFlow   1.189404\n",
      "2     Log_Team_size   1.089108\n",
      "3  Log_Patent_Count   1.024196\n",
      "4          Log_Fund   1.013345\n",
      "5          Field_CS   2.445881\n",
      "6         Field_Eng   2.409421\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0116\n",
      "  Adj R-squared: 0.0116\n",
      "  F-statistic: 13452.7996 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 2: Atyp_Median_Z\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3790718\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  12.883314\n",
      "1         InTraFlow   1.113956\n",
      "2     Log_Team_size   1.110640\n",
      "3  Log_Patent_Count   1.016083\n",
      "4          Log_Fund   1.017868\n",
      "5          Field_CS   1.970113\n",
      "6         Field_Eng   1.920270\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0126\n",
      "  Adj R-squared: 0.0126\n",
      "  F-statistic: 8042.7519 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 3: SB_B\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 4179612\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  11.959916\n",
      "1         InTraFlow   1.112543\n",
      "2     Log_Team_size   1.104694\n",
      "3  Log_Patent_Count   1.018947\n",
      "4          Log_Fund   1.021063\n",
      "5          Field_CS   1.970042\n",
      "6         Field_Eng   1.927768\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0170\n",
      "  Adj R-squared: 0.0170\n",
      "  F-statistic: 12037.5274 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 4: SB_T\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 4179612\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  11.959916\n",
      "1         InTraFlow   1.112543\n",
      "2     Log_Team_size   1.104694\n",
      "3  Log_Patent_Count   1.018947\n",
      "4          Log_Fund   1.021063\n",
      "5          Field_CS   1.970042\n",
      "6         Field_Eng   1.927768\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0566\n",
      "  Adj R-squared: 0.0566\n",
      "  F-statistic: 41781.4459 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 5: Log_C5\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 11569428\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  14.304861\n",
      "1         InTraFlow   1.143476\n",
      "2     Log_Team_size   1.083049\n",
      "3  Log_Patent_Count   1.016711\n",
      "4          Log_Fund   1.011762\n",
      "5          Field_CS   2.409504\n",
      "6         Field_Eng   2.355395\n",
      "回归结果摘要:\n",
      "  R-squared: 0.1011\n",
      "  Adj R-squared: 0.1011\n",
      "  F-statistic: 216776.8676 (p-value: 0.0000)\n",
      "\n",
      "回归结果已保存到 Regression_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略一些警告信息\n",
    "\n",
    "# 读取TSV文件\n",
    "file_path = 'Merged_Cleaned_InTraFlow.tsv'\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "print(f\"原始数据集大小: {data.shape}\")\n",
    "\n",
    "# 定义因变量和自变量 (移除Field_Eco)\n",
    "dependent_vars = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "independent_vars = ['InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', \n",
    "                    'Field_CS', 'Field_Eng']  # 移除了Field_Eco\n",
    "\n",
    "# 检查列是否存在\n",
    "missing_cols = [col for col in dependent_vars + independent_vars if col not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\"错误: 以下列不存在于数据中: {missing_cols}\")\n",
    "    exit(1)\n",
    "\n",
    "# 打印每个变量的基本信息\n",
    "print(\"\\n各变量缺失值情况:\")\n",
    "for col in dependent_vars + independent_vars:\n",
    "    na_count = data[col].isna().sum()\n",
    "    inf_count = np.isinf(data[col]).sum() if pd.api.types.is_numeric_dtype(data[col]) else 0\n",
    "    print(f\"{col}: 缺失值={na_count}, 无穷值={inf_count}\")\n",
    "\n",
    "# 检查自变量之间的相关性\n",
    "corr_matrix = data[independent_vars].corr()\n",
    "print(\"\\n自变量相关性矩阵:\")\n",
    "print(corr_matrix)\n",
    "\n",
    "# 执行回归分析并存储结果\n",
    "results = []\n",
    "\n",
    "for i, dv in enumerate(dependent_vars):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理 Model {i+1}: {dv}\")\n",
    "    \n",
    "    # 为每个模型单独提取数据并处理缺失值\n",
    "    model_vars = [dv] + independent_vars\n",
    "    model_data = data[model_vars].copy()\n",
    "    \n",
    "    # 打印处理前的样本量\n",
    "    print(f\"处理前样本量: {len(model_data)}\")\n",
    "    \n",
    "    # 替换无穷值为NaN并删除缺失值\n",
    "    model_data = model_data.replace([np.inf, -np.inf], np.nan)\n",
    "    model_data = model_data.dropna()\n",
    "    print(f\"处理后有效样本量: {len(model_data)}\")\n",
    "    \n",
    "    if len(model_data) == 0:\n",
    "        print(f\"错误: Model {i+1} ({dv}) 没有有效数据!\")\n",
    "        continue\n",
    "    \n",
    "    # 检查多重共线性\n",
    "    X_check = sm.add_constant(model_data[independent_vars])\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X_check.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_check.values, j) \n",
    "                       for j in range(X_check.shape[1])]\n",
    "    print(\"VIF值 (多重共线性检测):\")\n",
    "    print(vif_data)\n",
    "    \n",
    "    # 执行OLS回归\n",
    "    y = model_data[dv]\n",
    "    X = sm.add_constant(model_data[independent_vars])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # 输出基本回归结果\n",
    "    print(f\"回归结果摘要:\")\n",
    "    print(f\"  R-squared: {model.rsquared:.4f}\")\n",
    "    print(f\"  Adj R-squared: {model.rsquared_adj:.4f}\")\n",
    "    print(f\"  F-statistic: {model.fvalue:.4f} (p-value: {model.f_pvalue:.4f})\")\n",
    "    \n",
    "    # 提取结果\n",
    "    result = {\n",
    "        'Model': f\"Model {i+1}\",\n",
    "        'DV': dv,\n",
    "        'Coefficients': model.params,\n",
    "        'P_values': model.pvalues,\n",
    "        'Std_Errors': model.bse,\n",
    "        'R_squared': model.rsquared,\n",
    "        'Adj_R_squared': model.rsquared_adj,\n",
    "        'F_statistic': model.fvalue,\n",
    "        'F_pvalue': model.f_pvalue,\n",
    "        'N': model.nobs\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# 创建结果DataFrame\n",
    "output_file = 'Regression_Results.xlsx'\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 添加变量名\n",
    "var_names = ['Constant'] + independent_vars\n",
    "result_df['Variable'] = var_names + ['', 'Observations', 'R-squared', 'Adjusted R-squared', 'F-statistic', 'Prob > F']\n",
    "\n",
    "# 添加每个模型的结果\n",
    "for i, result in enumerate(results):\n",
    "    model_col = []\n",
    "    \n",
    "    # 添加系数和标准误\n",
    "    for var in ['const'] + independent_vars:\n",
    "        coef = result['Coefficients'][var]\n",
    "        stderr = result['Std_Errors'][var]\n",
    "        pval = result['P_values'][var]\n",
    "        \n",
    "        # 添加显著性星号\n",
    "        stars = ''\n",
    "        if pval < 0.01:\n",
    "            stars = '***'\n",
    "        elif pval < 0.05:\n",
    "            stars = '**'\n",
    "        elif pval < 0.1:\n",
    "            stars = '*'\n",
    "        \n",
    "        # 格式化系数和标准误\n",
    "        model_col.append(f\"{coef:.3f}{stars}\\n({stderr:.3f})\")\n",
    "    \n",
    "    # 添加空行和统计量\n",
    "    model_col.append('')\n",
    "    model_col.append(f\"{int(result['N'])}\")\n",
    "    model_col.append(f\"{result['R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['Adj_R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['F_statistic']:.3f}\")\n",
    "    model_col.append(f\"{result['F_pvalue']:.6f}\")\n",
    "    \n",
    "    # 添加到结果DataFrame\n",
    "    result_df[f\"Model {i+1}\\n{result['DV']}\"] = model_col\n",
    "\n",
    "# 保存到Excel\n",
    "result_df.to_excel(output_file, sheet_name='Regression Results', index=False)\n",
    "\n",
    "# 格式化Excel文件\n",
    "wb = load_workbook(output_file)\n",
    "ws = wb['Regression Results']\n",
    "\n",
    "# 设置列宽和样式\n",
    "for col in ws.columns:\n",
    "    column = col[0].column_letter\n",
    "    max_length = max(len(str(cell.value or '')) for cell in col)\n",
    "    adjusted_width = max(max_length + 2, 15)  # 最小宽度15\n",
    "    ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "# 设置样式\n",
    "header_font = Font(bold=True)\n",
    "align_center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "align_left = Alignment(horizontal='left', vertical='center', wrap_text=True)\n",
    "border = Border(left=Side(style='thin'), right=Side(style='thin'), \n",
    "                top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "# 应用样式\n",
    "for row_idx, row in enumerate(ws.rows, 1):\n",
    "    for col_idx, cell in enumerate(row, 1):\n",
    "        cell.border = border\n",
    "        \n",
    "        if row_idx == 1:  # 标题行\n",
    "            cell.font = header_font\n",
    "            cell.alignment = align_center\n",
    "        else:\n",
    "            if col_idx == 1:  # 变量名列\n",
    "                cell.alignment = align_left\n",
    "            else:\n",
    "                cell.alignment = align_center\n",
    "\n",
    "# 添加注释说明星号的含义\n",
    "footnote_row = ws.max_row + 2\n",
    "ws.cell(row=footnote_row, column=1, value=\"注: *** p<0.01, ** p<0.05, * p<0.1，括号内为标准误\")\n",
    "\n",
    "# 保存格式化后的Excel\n",
    "wb.save(output_file)\n",
    "\n",
    "print(f\"\\n回归结果已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据集大小: (11613323, 24)\n",
      "\n",
      "各变量缺失值情况:\n",
      "Field_Eng: 缺失值=0, 无穷值=0\n",
      "Field_CS: 缺失值=0, 无穷值=0\n",
      "Log_Team_size: 缺失值=0, 无穷值=0\n",
      "InTraFlow: 缺失值=0, 无穷值=43895\n",
      "SB_T: 缺失值=7423844, 无穷值=0\n",
      "SB_B: 缺失值=7423844, 无穷值=0\n",
      "N_InTraFlow: 缺失值=43895, 无穷值=0\n",
      "Atyp_Median_Z: 缺失值=7816176, 无穷值=0\n",
      "Log_Patent_Count: 缺失值=0, 无穷值=0\n",
      "Log_C5: 缺失值=0, 无穷值=0\n",
      "Disruption: 缺失值=4711622, 无穷值=0\n",
      "Log_Fund: 缺失值=0, 无穷值=0\n",
      "\n",
      "==================================================\n",
      "处理 Model 1: Disruption (使用InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 6881165\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  15.472618\n",
      "1         InTraFlow   1.189404\n",
      "2     Log_Team_size   1.089108\n",
      "3  Log_Patent_Count   1.024196\n",
      "4          Log_Fund   1.013345\n",
      "5          Field_CS   2.445881\n",
      "6         Field_Eng   2.409421\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0116\n",
      "  Adj R-squared: 0.0116\n",
      "  F-statistic: 13452.7996 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 2: Atyp_Median_Z (使用InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3790718\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  12.883314\n",
      "1         InTraFlow   1.113956\n",
      "2     Log_Team_size   1.110640\n",
      "3  Log_Patent_Count   1.016083\n",
      "4          Log_Fund   1.017868\n",
      "5          Field_CS   1.970113\n",
      "6         Field_Eng   1.920270\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0126\n",
      "  Adj R-squared: 0.0126\n",
      "  F-statistic: 8042.7519 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 3: SB_B (使用InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 4179612\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  11.959916\n",
      "1         InTraFlow   1.112543\n",
      "2     Log_Team_size   1.104694\n",
      "3  Log_Patent_Count   1.018947\n",
      "4          Log_Fund   1.021063\n",
      "5          Field_CS   1.970042\n",
      "6         Field_Eng   1.927768\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0170\n",
      "  Adj R-squared: 0.0170\n",
      "  F-statistic: 12037.5274 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 4: SB_T (使用InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 4179612\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  11.959916\n",
      "1         InTraFlow   1.112543\n",
      "2     Log_Team_size   1.104694\n",
      "3  Log_Patent_Count   1.018947\n",
      "4          Log_Fund   1.021063\n",
      "5          Field_CS   1.970042\n",
      "6         Field_Eng   1.927768\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0566\n",
      "  Adj R-squared: 0.0566\n",
      "  F-statistic: 41781.4459 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 5: Log_C5 (使用InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 11569428\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  14.304861\n",
      "1         InTraFlow   1.143476\n",
      "2     Log_Team_size   1.083049\n",
      "3  Log_Patent_Count   1.016711\n",
      "4          Log_Fund   1.011762\n",
      "5          Field_CS   2.409504\n",
      "6         Field_Eng   2.355395\n",
      "回归结果摘要:\n",
      "  R-squared: 0.1011\n",
      "  Adj R-squared: 0.1011\n",
      "  F-statistic: 216776.8676 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 6: Disruption (使用N_InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 6881165\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  15.123040\n",
      "1       N_InTraFlow   1.010256\n",
      "2     Log_Team_size   1.084045\n",
      "3  Log_Patent_Count   1.014205\n",
      "4          Log_Fund   1.013326\n",
      "5          Field_CS   2.415079\n",
      "6         Field_Eng   2.347748\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0114\n",
      "  Adj R-squared: 0.0114\n",
      "  F-statistic: 13272.9975 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 7: Atyp_Median_Z (使用N_InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3790718\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  12.614212\n",
      "1       N_InTraFlow   1.006960\n",
      "2     Log_Team_size   1.108322\n",
      "3  Log_Patent_Count   1.010311\n",
      "4          Log_Fund   1.018043\n",
      "5          Field_CS   1.953308\n",
      "6         Field_Eng   1.875888\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0127\n",
      "  Adj R-squared: 0.0127\n",
      "  F-statistic: 8133.3947 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 8: SB_B (使用N_InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 4179612\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  11.390913\n",
      "1       N_InTraFlow   1.004874\n",
      "2     Log_Team_size   1.090338\n",
      "3  Log_Patent_Count   1.011639\n",
      "4          Log_Fund   1.021274\n",
      "5          Field_CS   1.964000\n",
      "6         Field_Eng   1.876748\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0194\n",
      "  Adj R-squared: 0.0194\n",
      "  F-statistic: 13817.5615 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 9: SB_T (使用N_InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 4179612\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  11.390913\n",
      "1       N_InTraFlow   1.004874\n",
      "2     Log_Team_size   1.090338\n",
      "3  Log_Patent_Count   1.011639\n",
      "4          Log_Fund   1.021274\n",
      "5          Field_CS   1.964000\n",
      "6         Field_Eng   1.876748\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0564\n",
      "  Adj R-squared: 0.0564\n",
      "  F-statistic: 41606.3227 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 10: Log_C5 (使用N_InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 11569428\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.843966\n",
      "1       N_InTraFlow   1.005463\n",
      "2     Log_Team_size   1.072809\n",
      "3  Log_Patent_Count   1.009265\n",
      "4          Log_Fund   1.011655\n",
      "5          Field_CS   2.390513\n",
      "6         Field_Eng   2.307746\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0927\n",
      "  Adj R-squared: 0.0927\n",
      "  F-statistic: 197027.3185 (p-value: 0.0000)\n",
      "\n",
      "回归结果已保存到 Regression_Results_2.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略警告信息\n",
    "\n",
    "# 读取TSV文件\n",
    "file_path = 'Merged_Cleaned_InTraFlow.tsv'\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "print(f\"原始数据集大小: {data.shape}\")\n",
    "\n",
    "# 定义因变量\n",
    "dependent_vars = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "\n",
    "# 定义两组自变量（移除Field_Eco）\n",
    "independent_vars_1 = ['InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', \n",
    "                     'Field_CS', 'Field_Eng']  # 第一组模型的自变量\n",
    "                     \n",
    "independent_vars_2 = ['N_InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', \n",
    "                     'Field_CS', 'Field_Eng']  # 第二组模型的自变量\n",
    "\n",
    "# 检查列是否存在\n",
    "all_vars = list(set(dependent_vars + independent_vars_1 + independent_vars_2))\n",
    "missing_cols = [col for col in all_vars if col not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\"错误: 以下列不存在于数据中: {missing_cols}\")\n",
    "    print(f\"可用的列: {data.columns.tolist()}\")\n",
    "    exit(1)\n",
    "\n",
    "# 打印每个变量的基本信息\n",
    "print(\"\\n各变量缺失值情况:\")\n",
    "for col in all_vars:\n",
    "    na_count = data[col].isna().sum()\n",
    "    inf_count = np.isinf(data[col]).sum() if pd.api.types.is_numeric_dtype(data[col]) else 0\n",
    "    print(f\"{col}: 缺失值={na_count}, 无穷值={inf_count}\")\n",
    "\n",
    "# 执行回归分析并存储结果\n",
    "results = []\n",
    "\n",
    "# 模型1-5: 使用InTraFlow\n",
    "for i, dv in enumerate(dependent_vars):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理 Model {i+1}: {dv} (使用InTraFlow)\")\n",
    "    \n",
    "    # 为每个模型单独提取数据并处理缺失值\n",
    "    model_vars = [dv] + independent_vars_1\n",
    "    model_data = data[model_vars].copy()\n",
    "    \n",
    "    # 打印处理前的样本量\n",
    "    print(f\"处理前样本量: {len(model_data)}\")\n",
    "    \n",
    "    # 替换无穷值为NaN并删除缺失值\n",
    "    model_data = model_data.replace([np.inf, -np.inf], np.nan)\n",
    "    model_data = model_data.dropna()\n",
    "    print(f\"处理后有效样本量: {len(model_data)}\")\n",
    "    \n",
    "    if len(model_data) == 0:\n",
    "        print(f\"错误: Model {i+1} ({dv}) 没有有效数据!\")\n",
    "        continue\n",
    "    \n",
    "    # 检查多重共线性\n",
    "    X_check = sm.add_constant(model_data[independent_vars_1])\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X_check.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_check.values, j) \n",
    "                       for j in range(X_check.shape[1])]\n",
    "    print(\"VIF值 (多重共线性检测):\")\n",
    "    print(vif_data)\n",
    "    \n",
    "    # 执行OLS回归\n",
    "    y = model_data[dv]\n",
    "    X = sm.add_constant(model_data[independent_vars_1])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # 输出基本回归结果\n",
    "    print(f\"回归结果摘要:\")\n",
    "    print(f\"  R-squared: {model.rsquared:.4f}\")\n",
    "    print(f\"  Adj R-squared: {model.rsquared_adj:.4f}\")\n",
    "    print(f\"  F-statistic: {model.fvalue:.4f} (p-value: {model.f_pvalue:.4f})\")\n",
    "    \n",
    "    # 提取结果\n",
    "    result = {\n",
    "        'Model': f\"Model {i+1}\",\n",
    "        'DV': dv,\n",
    "        'IV': 'InTraFlow',\n",
    "        'Coefficients': model.params,\n",
    "        'P_values': model.pvalues,\n",
    "        'Std_Errors': model.bse,\n",
    "        'R_squared': model.rsquared,\n",
    "        'Adj_R_squared': model.rsquared_adj,\n",
    "        'F_statistic': model.fvalue,\n",
    "        'F_pvalue': model.f_pvalue,\n",
    "        'N': model.nobs\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# 模型6-10: 使用N_InTraFlow\n",
    "for i, dv in enumerate(dependent_vars):\n",
    "    model_number = i + 6  # 模型编号从6开始\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理 Model {model_number}: {dv} (使用N_InTraFlow)\")\n",
    "    \n",
    "    # 为每个模型单独提取数据并处理缺失值\n",
    "    model_vars = [dv] + independent_vars_2\n",
    "    model_data = data[model_vars].copy()\n",
    "    \n",
    "    # 打印处理前的样本量\n",
    "    print(f\"处理前样本量: {len(model_data)}\")\n",
    "    \n",
    "    # 替换无穷值为NaN并删除缺失值\n",
    "    model_data = model_data.replace([np.inf, -np.inf], np.nan)\n",
    "    model_data = model_data.dropna()\n",
    "    print(f\"处理后有效样本量: {len(model_data)}\")\n",
    "    \n",
    "    if len(model_data) == 0:\n",
    "        print(f\"错误: Model {model_number} ({dv}) 没有有效数据!\")\n",
    "        continue\n",
    "    \n",
    "    # 检查多重共线性\n",
    "    X_check = sm.add_constant(model_data[independent_vars_2])\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X_check.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_check.values, j) \n",
    "                       for j in range(X_check.shape[1])]\n",
    "    print(\"VIF值 (多重共线性检测):\")\n",
    "    print(vif_data)\n",
    "    \n",
    "    # 执行OLS回归\n",
    "    y = model_data[dv]\n",
    "    X = sm.add_constant(model_data[independent_vars_2])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # 输出基本回归结果\n",
    "    print(f\"回归结果摘要:\")\n",
    "    print(f\"  R-squared: {model.rsquared:.4f}\")\n",
    "    print(f\"  Adj R-squared: {model.rsquared_adj:.4f}\")\n",
    "    print(f\"  F-statistic: {model.fvalue:.4f} (p-value: {model.f_pvalue:.4f})\")\n",
    "    \n",
    "    # 提取结果\n",
    "    result = {\n",
    "        'Model': f\"Model {model_number}\",\n",
    "        'DV': dv,\n",
    "        'IV': 'N_InTraFlow',\n",
    "        'Coefficients': model.params,\n",
    "        'P_values': model.pvalues,\n",
    "        'Std_Errors': model.bse,\n",
    "        'R_squared': model.rsquared,\n",
    "        'Adj_R_squared': model.rsquared_adj,\n",
    "        'F_statistic': model.fvalue,\n",
    "        'F_pvalue': model.f_pvalue,\n",
    "        'N': model.nobs\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# 创建结果DataFrame\n",
    "output_file = 'Regression_Results_2.xlsx'\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 添加变量名 (使用第一组变量的名称，但在展示时会区分)\n",
    "var_names = ['Constant'] + independent_vars_1[1:]  # 除了第一个变量外的所有变量\n",
    "result_df['Variable'] = ['InTraFlow/N_InTraFlow'] + var_names + ['', 'Observations', 'R-squared', 'Adjusted R-squared', 'F-statistic', 'Prob > F']\n",
    "\n",
    "# 添加每个模型的结果\n",
    "for result in results:\n",
    "    model_col = []\n",
    "    \n",
    "    # 确定使用哪组变量\n",
    "    if result['IV'] == 'InTraFlow':\n",
    "        iv_vars = ['InTraFlow'] + independent_vars_1[1:]\n",
    "    else:\n",
    "        iv_vars = ['N_InTraFlow'] + independent_vars_2[1:]\n",
    "    \n",
    "    # 添加系数和标准误\n",
    "    for var in ['const'] + iv_vars:\n",
    "        coef = result['Coefficients'][var]\n",
    "        stderr = result['Std_Errors'][var]\n",
    "        pval = result['P_values'][var]\n",
    "        \n",
    "        # 添加显著性星号\n",
    "        stars = ''\n",
    "        if pval < 0.01:\n",
    "            stars = '***'\n",
    "        elif pval < 0.05:\n",
    "            stars = '**'\n",
    "        elif pval < 0.1:\n",
    "            stars = '*'\n",
    "        \n",
    "        # 格式化系数和标准误\n",
    "        model_col.append(f\"{coef:.3f}{stars}\\n({stderr:.3f})\")\n",
    "    \n",
    "    # 添加空行和统计量\n",
    "    model_col.append('')\n",
    "    model_col.append(f\"{int(result['N'])}\")\n",
    "    model_col.append(f\"{result['R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['Adj_R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['F_statistic']:.3f}\")\n",
    "    model_col.append(f\"{result['F_pvalue']:.6f}\")\n",
    "    \n",
    "    # 添加到结果DataFrame\n",
    "    result_df[f\"Model {result['Model'].split()[1]}\\n{result['DV']}\"] = model_col\n",
    "\n",
    "# 保存到Excel\n",
    "result_df.to_excel(output_file, sheet_name='Regression Results', index=False)\n",
    "\n",
    "# 格式化Excel文件\n",
    "wb = load_workbook(output_file)\n",
    "ws = wb['Regression Results']\n",
    "\n",
    "# 设置列宽和样式\n",
    "for col in ws.columns:\n",
    "    column = col[0].column_letter\n",
    "    max_length = max(len(str(cell.value or '')) for cell in col)\n",
    "    adjusted_width = max(max_length + 2, 15)  # 最小宽度15\n",
    "    ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "# 设置样式\n",
    "header_font = Font(bold=True)\n",
    "align_center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "align_left = Alignment(horizontal='left', vertical='center', wrap_text=True)\n",
    "border = Border(left=Side(style='thin'), right=Side(style='thin'), \n",
    "                top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "# 应用样式\n",
    "for row_idx, row in enumerate(ws.rows, 1):\n",
    "    for col_idx, cell in enumerate(row, 1):\n",
    "        cell.border = border\n",
    "        \n",
    "        if row_idx == 1:  # 标题行\n",
    "            cell.font = header_font\n",
    "            cell.alignment = align_center\n",
    "        else:\n",
    "            if col_idx == 1:  # 变量名列\n",
    "                cell.alignment = align_left\n",
    "            else:\n",
    "                cell.alignment = align_center\n",
    "\n",
    "# 添加注释说明星号的含义\n",
    "footnote_row = ws.max_row + 2\n",
    "ws.cell(row=footnote_row, column=1, value=\"注: *** p<0.01, ** p<0.05, * p<0.1，括号内为标准误\")\n",
    "ws.cell(row=footnote_row+1, column=1, value=\"Model 1-5使用InTraFlow作为自变量，Model 6-10使用N_InTraFlow作为自变量\")\n",
    "\n",
    "# 保存格式化后的Excel\n",
    "wb.save(output_file)\n",
    "\n",
    "print(f\"\\n回归结果已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据集大小: (11613323, 24)\n",
      "\n",
      "各变量缺失值情况:\n",
      "Disruption: 缺失值=4711622, 无穷值=0\n",
      "Atyp_Median_Z: 缺失值=7816176, 无穷值=0\n",
      "SB_B: 缺失值=7423844, 无穷值=0\n",
      "SB_T: 缺失值=7423844, 无穷值=0\n",
      "Log_C5: 缺失值=0, 无穷值=0\n",
      "N_InTraFlow: 缺失值=43895, 无穷值=0\n",
      "Log_Team_size: 缺失值=0, 无穷值=0\n",
      "Log_Patent_Count: 缺失值=0, 无穷值=0\n",
      "Log_Fund: 缺失值=0, 无穷值=0\n",
      "Field_CS: 缺失值=0, 无穷值=0\n",
      "Field_Eng: 缺失值=0, 无穷值=0\n",
      "\n",
      "自变量相关性矩阵:\n",
      "                  N_InTraFlow  Log_Team_size  Log_Patent_Count  Log_Fund  \\\n",
      "N_InTraFlow          1.000000      -0.016346         -0.044368 -0.002555   \n",
      "Log_Team_size       -0.016346       1.000000          0.036887  0.090651   \n",
      "Log_Patent_Count    -0.044368       0.036887          1.000000  0.031096   \n",
      "Log_Fund            -0.002555       0.090651          0.031096  1.000000   \n",
      "Field_CS            -0.053466       0.182514          0.052576  0.066168   \n",
      "Field_Eng            0.056079      -0.023063          0.001021 -0.045859   \n",
      "\n",
      "                  Field_CS  Field_Eng  \n",
      "N_InTraFlow      -0.053466   0.056079  \n",
      "Log_Team_size     0.182514  -0.023063  \n",
      "Log_Patent_Count  0.052576   0.001021  \n",
      "Log_Fund          0.066168  -0.045859  \n",
      "Field_CS          1.000000  -0.742547  \n",
      "Field_Eng        -0.742547   1.000000  \n",
      "\n",
      "==================================================\n",
      "处理 Model 1: Disruption\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 6881165\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  15.123040\n",
      "1       N_InTraFlow   1.010256\n",
      "2     Log_Team_size   1.084045\n",
      "3  Log_Patent_Count   1.014205\n",
      "4          Log_Fund   1.013326\n",
      "5          Field_CS   2.415079\n",
      "6         Field_Eng   2.347748\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0114\n",
      "  Adj R-squared: 0.0114\n",
      "  F-statistic: 13272.9975 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 2: Atyp_Median_Z\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3790718\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  12.614212\n",
      "1       N_InTraFlow   1.006960\n",
      "2     Log_Team_size   1.108322\n",
      "3  Log_Patent_Count   1.010311\n",
      "4          Log_Fund   1.018043\n",
      "5          Field_CS   1.953308\n",
      "6         Field_Eng   1.875888\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0127\n",
      "  Adj R-squared: 0.0127\n",
      "  F-statistic: 8133.3947 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 3: SB_B\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 4179612\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  11.390913\n",
      "1       N_InTraFlow   1.004874\n",
      "2     Log_Team_size   1.090338\n",
      "3  Log_Patent_Count   1.011639\n",
      "4          Log_Fund   1.021274\n",
      "5          Field_CS   1.964000\n",
      "6         Field_Eng   1.876748\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0194\n",
      "  Adj R-squared: 0.0194\n",
      "  F-statistic: 13817.5615 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 4: SB_T\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 4179612\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  11.390913\n",
      "1       N_InTraFlow   1.004874\n",
      "2     Log_Team_size   1.090338\n",
      "3  Log_Patent_Count   1.011639\n",
      "4          Log_Fund   1.021274\n",
      "5          Field_CS   1.964000\n",
      "6         Field_Eng   1.876748\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0564\n",
      "  Adj R-squared: 0.0564\n",
      "  F-statistic: 41606.3227 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 5: Log_C5\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 11569428\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.843966\n",
      "1       N_InTraFlow   1.005463\n",
      "2     Log_Team_size   1.072809\n",
      "3  Log_Patent_Count   1.009265\n",
      "4          Log_Fund   1.011655\n",
      "5          Field_CS   2.390513\n",
      "6         Field_Eng   2.307746\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0927\n",
      "  Adj R-squared: 0.0927\n",
      "  F-statistic: 197027.3185 (p-value: 0.0000)\n",
      "\n",
      "回归结果已保存到 Regression_Results_6-10.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略一些警告信息\n",
    "\n",
    "# 读取TSV文件\n",
    "file_path = 'Merged_Cleaned_InTraFlow.tsv'\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "print(f\"原始数据集大小: {data.shape}\")\n",
    "\n",
    "# 定义因变量和自变量 (移除Field_Eco)\n",
    "dependent_vars = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "independent_vars = ['N_InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', \n",
    "                    'Field_CS', 'Field_Eng']  # 移除了Field_Eco\n",
    "\n",
    "# 检查列是否存在\n",
    "missing_cols = [col for col in dependent_vars + independent_vars if col not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\"错误: 以下列不存在于数据中: {missing_cols}\")\n",
    "    exit(1)\n",
    "\n",
    "# 打印每个变量的基本信息\n",
    "print(\"\\n各变量缺失值情况:\")\n",
    "for col in dependent_vars + independent_vars:\n",
    "    na_count = data[col].isna().sum()\n",
    "    inf_count = np.isinf(data[col]).sum() if pd.api.types.is_numeric_dtype(data[col]) else 0\n",
    "    print(f\"{col}: 缺失值={na_count}, 无穷值={inf_count}\")\n",
    "\n",
    "# 检查自变量之间的相关性\n",
    "corr_matrix = data[independent_vars].corr()\n",
    "print(\"\\n自变量相关性矩阵:\")\n",
    "print(corr_matrix)\n",
    "\n",
    "# 执行回归分析并存储结果\n",
    "results = []\n",
    "\n",
    "for i, dv in enumerate(dependent_vars):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理 Model {i+1}: {dv}\")\n",
    "    \n",
    "    # 为每个模型单独提取数据并处理缺失值\n",
    "    model_vars = [dv] + independent_vars\n",
    "    model_data = data[model_vars].copy()\n",
    "    \n",
    "    # 打印处理前的样本量\n",
    "    print(f\"处理前样本量: {len(model_data)}\")\n",
    "    \n",
    "    # 替换无穷值为NaN并删除缺失值\n",
    "    model_data = model_data.replace([np.inf, -np.inf], np.nan)\n",
    "    model_data = model_data.dropna()\n",
    "    print(f\"处理后有效样本量: {len(model_data)}\")\n",
    "    \n",
    "    if len(model_data) == 0:\n",
    "        print(f\"错误: Model {i+1} ({dv}) 没有有效数据!\")\n",
    "        continue\n",
    "    \n",
    "    # 检查多重共线性\n",
    "    X_check = sm.add_constant(model_data[independent_vars])\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X_check.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_check.values, j) \n",
    "                       for j in range(X_check.shape[1])]\n",
    "    print(\"VIF值 (多重共线性检测):\")\n",
    "    print(vif_data)\n",
    "    \n",
    "    # 执行OLS回归\n",
    "    y = model_data[dv]\n",
    "    X = sm.add_constant(model_data[independent_vars])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # 输出基本回归结果\n",
    "    print(f\"回归结果摘要:\")\n",
    "    print(f\"  R-squared: {model.rsquared:.4f}\")\n",
    "    print(f\"  Adj R-squared: {model.rsquared_adj:.4f}\")\n",
    "    print(f\"  F-statistic: {model.fvalue:.4f} (p-value: {model.f_pvalue:.4f})\")\n",
    "    \n",
    "    # 提取结果\n",
    "    result = {\n",
    "        'Model': f\"Model {i+1}\",\n",
    "        'DV': dv,\n",
    "        'Coefficients': model.params,\n",
    "        'P_values': model.pvalues,\n",
    "        'Std_Errors': model.bse,\n",
    "        'R_squared': model.rsquared,\n",
    "        'Adj_R_squared': model.rsquared_adj,\n",
    "        'F_statistic': model.fvalue,\n",
    "        'F_pvalue': model.f_pvalue,\n",
    "        'N': model.nobs\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# 创建结果DataFrame\n",
    "output_file = 'Regression_Results_6-10.xlsx'\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 添加变量名\n",
    "var_names = ['Constant'] + independent_vars\n",
    "result_df['Variable'] = var_names + ['', 'Observations', 'R-squared', 'Adjusted R-squared', 'F-statistic', 'Prob > F']\n",
    "\n",
    "# 添加每个模型的结果\n",
    "for i, result in enumerate(results):\n",
    "    model_col = []\n",
    "    \n",
    "    # 添加系数和标准误\n",
    "    for var in ['const'] + independent_vars:\n",
    "        coef = result['Coefficients'][var]\n",
    "        stderr = result['Std_Errors'][var]\n",
    "        pval = result['P_values'][var]\n",
    "        \n",
    "        # 添加显著性星号\n",
    "        stars = ''\n",
    "        if pval < 0.01:\n",
    "            stars = '***'\n",
    "        elif pval < 0.05:\n",
    "            stars = '**'\n",
    "        elif pval < 0.1:\n",
    "            stars = '*'\n",
    "        \n",
    "        # 格式化系数和标准误\n",
    "        model_col.append(f\"{coef:.3f}{stars}\\n({stderr:.3f})\")\n",
    "    \n",
    "    # 添加空行和统计量\n",
    "    model_col.append('')\n",
    "    model_col.append(f\"{int(result['N'])}\")\n",
    "    model_col.append(f\"{result['R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['Adj_R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['F_statistic']:.3f}\")\n",
    "    model_col.append(f\"{result['F_pvalue']:.6f}\")\n",
    "    \n",
    "    # 添加到结果DataFrame\n",
    "    result_df[f\"Model {i+1}\\n{result['DV']}\"] = model_col\n",
    "\n",
    "# 保存到Excel\n",
    "result_df.to_excel(output_file, sheet_name='Regression Results', index=False)\n",
    "\n",
    "# 格式化Excel文件\n",
    "wb = load_workbook(output_file)\n",
    "ws = wb['Regression Results']\n",
    "\n",
    "# 设置列宽和样式\n",
    "for col in ws.columns:\n",
    "    column = col[0].column_letter\n",
    "    max_length = max(len(str(cell.value or '')) for cell in col)\n",
    "    adjusted_width = max(max_length + 2, 15)  # 最小宽度15\n",
    "    ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "# 设置样式\n",
    "header_font = Font(bold=True)\n",
    "align_center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "align_left = Alignment(horizontal='left', vertical='center', wrap_text=True)\n",
    "border = Border(left=Side(style='thin'), right=Side(style='thin'), \n",
    "                top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "# 应用样式\n",
    "for row_idx, row in enumerate(ws.rows, 1):\n",
    "    for col_idx, cell in enumerate(row, 1):\n",
    "        cell.border = border\n",
    "        \n",
    "        if row_idx == 1:  # 标题行\n",
    "            cell.font = header_font\n",
    "            cell.alignment = align_center\n",
    "        else:\n",
    "            if col_idx == 1:  # 变量名列\n",
    "                cell.alignment = align_left\n",
    "            else:\n",
    "                cell.alignment = align_center\n",
    "\n",
    "# 添加注释说明星号的含义\n",
    "footnote_row = ws.max_row + 2\n",
    "ws.cell(row=footnote_row, column=1, value=\"注: *** p<0.01, ** p<0.05, * p<0.1，括号内为标准误\")\n",
    "\n",
    "# 保存格式化后的Excel\n",
    "wb.save(output_file)\n",
    "\n",
    "print(f\"\\n回归结果已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 'Merged_Cleaned_InTraFlow_CareerYear.tsv' 分析报告:\n",
      "\n",
      "字段: 'FieldID'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'PaperID'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'C_f'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3\n",
      "------------------------------\n",
      "字段: 'Year'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3\n",
      "------------------------------\n",
      "字段: 'Citation_Count'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'C10'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 5924481\n",
      "------------------------------\n",
      "字段: 'C5'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 3085294\n",
      "------------------------------\n",
      "字段: 'Team_size'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 167\n",
      "------------------------------\n",
      "字段: 'Disruption'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 4711622\n",
      "------------------------------\n",
      "字段: 'Atyp_Median_Z'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7816176\n",
      "------------------------------\n",
      "字段: 'SB_B'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7423844\n",
      "------------------------------\n",
      "字段: 'SB_T'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 7423844\n",
      "------------------------------\n",
      "字段: 'InTraFlowf'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 5546180\n",
      "  NaN 值 数量: 0\n",
      "------------------------------\n",
      "字段: 'InTraFlow'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'N_InTraFlow'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 43895\n",
      "------------------------------\n",
      "字段: 'Patent_Count'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'Fund'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'Field_CS'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'Field_Eng'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'Field_Eco'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'Log_Team_size'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'Log_C5'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'Log_Patent_Count'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'Log_Fund'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 0\n",
      "------------------------------\n",
      "字段: 'Career Year'\n",
      "  总行数 (不含 header): 11613323\n",
      "  空值 (空字符串) 数量: 13627\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def analyze_tsv_file(file_path):\n",
    "    \"\"\"\n",
    "    分析 TSV 文件，统计每个字段的行数、空值和 NaN 值。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV 文件的路径。\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as tsvfile:\n",
    "            reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "            header = next(reader, None)  # 读取 header 行\n",
    "\n",
    "            if not header:\n",
    "                print(f\"错误: 文件 '{file_path}' 没有 header 行或为空文件。\")\n",
    "                return\n",
    "\n",
    "            column_data = {field: [] for field in header} # 使用字典存储每列的数据\n",
    "\n",
    "            for row in reader:\n",
    "                for i, value in enumerate(row):\n",
    "                    if i < len(header): # 确保列索引在 header 范围内\n",
    "                        column_data[header[i]].append(value.strip()) # 去除值两端空格\n",
    "\n",
    "            print(f\"文件 '{file_path}' 分析报告:\\n\")\n",
    "\n",
    "            for field in header:\n",
    "                values = column_data[field]\n",
    "                total_rows = len(values)\n",
    "                empty_count = values.count('')\n",
    "                nan_count = values.count('NaN') if field == 'InTraFlowf' else 0 # 只对 InTraFlowf 列统计 NaN\n",
    "\n",
    "                print(f\"字段: '{field}'\")\n",
    "                print(f\"  总行数 (不含 header): {total_rows}\")\n",
    "                print(f\"  空值 (空字符串) 数量: {empty_count}\")\n",
    "                if field == 'InTraFlowf':\n",
    "                    print(f\"  NaN 值 数量: {nan_count}\") # 只在 InTraFlowf 列显示 NaN 计数\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{file_path}' 未找到，请检查文件路径。\")\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件 '{file_path}' 时发生错误: {e}\")\n",
    "\n",
    "\n",
    "# 定义要分析的文件路径\n",
    "file_path_to_analyze = \"Merged_Cleaned_InTraFlow_CareerYear.tsv\" # 替换为您要分析的文件路径\n",
    "analyze_tsv_file(file_path_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将按 Career Year 分组计算的均值结果输出到文件: CareerYear_Grouped_Means.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 定义需要计算均值的列名\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'InTraFlowf', 'InTraFlow', 'N_InTraFlow', 'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng',\n",
    "    'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund'\n",
    "]\n",
    "\n",
    "# 按 'Career Year' 分组并计算均值\n",
    "career_year_group_means = df.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "\n",
    "# 输出到 Excel 文件\n",
    "output_excel_file = 'CareerYear_Grouped_Means.xlsx'\n",
    "career_year_group_means.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"已将按 Career Year 分组计算的均值结果输出到文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功提取 'PaperID' 和 'Year' 列并保存到: PaperID_Year.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def extract_paperid_year(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    从大型 TSV 文件中提取 'PaperID' 和 'Year' 列，并保存到新的 TSV 文件。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件的路径。\n",
    "        output_file_path (str): 输出 TSV 文件的路径。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as infile, \\\n",
    "             open(output_file_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "            reader = csv.reader(infile, delimiter='\\t') # 创建 TSV 读取器\n",
    "            writer = csv.writer(outfile, delimiter='\\t') # 创建 TSV 写入器\n",
    "\n",
    "            header = next(reader) # 读取首行作为 header\n",
    "            paperid_index = -1\n",
    "            year_index = -1\n",
    "\n",
    "            # 查找 'PaperID' 和 'Year' 列的索引\n",
    "            for index, column_name in enumerate(header):\n",
    "                if column_name == 'PaperID':\n",
    "                    paperid_index = index\n",
    "                elif column_name == 'Year':\n",
    "                    year_index = index\n",
    "\n",
    "            # 检查是否找到了需要的列\n",
    "            if paperid_index == -1 or year_index == -1:\n",
    "                raise ValueError(\"Input file does not contain 'PaperID' or 'Year' column.\")\n",
    "\n",
    "            # 写入新的 header 到输出文件\n",
    "            writer.writerow(['PaperID', 'Year'])\n",
    "\n",
    "            # 逐行处理数据并写入到输出文件\n",
    "            for row in reader:\n",
    "                try:\n",
    "                    paper_id = row[paperid_index]\n",
    "                    year = row[year_index]\n",
    "                    writer.writerow([paper_id, year])\n",
    "                except IndexError:\n",
    "                    print(f\"Warning: 行数据不完整，缺少列，已跳过该行: {row}\") # 捕获行数据可能不完整的情况\n",
    "\n",
    "        print(f\"成功提取 'PaperID' 和 'Year' 列并保存到: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 输入文件 '{input_file_path}' 未找到.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"值错误: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误: {e}\")\n",
    "\n",
    "# 设置输入和输出文件路径\n",
    "input_tsv_file = 'SciSciNet_Papers.tsv'\n",
    "output_tsv_file = 'PaperID_Year.tsv'\n",
    "\n",
    "# 执行提取操作\n",
    "extract_paperid_year(input_tsv_file, output_tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已按照 'PaperID' 数值大小升序排序，并保存到: PaperID_Year_sorted.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def sort_paperid_year_file(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    读取 TSV 文件，按照 'PaperID' 列的数值大小升序排序，并将结果保存到新的 TSV 文件。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件的路径 (PaperID_Year.tsv).\n",
    "        output_file_path (str): 输出排序后 TSV 文件的路径 (例如: PaperID_Year_sorted.tsv).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取 TSV 文件到 DataFrame\n",
    "        df = pd.read_csv(input_file_path, sep='\\t')\n",
    "\n",
    "        # 确保 'PaperID' 列是数值类型，如果不是，尝试转换为数值型\n",
    "        # errors='coerce' 会将无法转换为数值的值设置为 NaN\n",
    "        df['PaperID'] = pd.to_numeric(df['PaperID'], errors='coerce')\n",
    "\n",
    "        # 排序前移除 NaN 值，避免排序错误，并记录移除的行数\n",
    "        initial_rows = len(df)\n",
    "        df_cleaned = df.dropna(subset=['PaperID'])\n",
    "        removed_rows = initial_rows - len(df_cleaned)\n",
    "        if removed_rows > 0:\n",
    "            print(f\"Warning: Removed {removed_rows} rows with non-numeric or missing PaperID values before sorting.\")\n",
    "        df = df_cleaned # 使用 cleaned DataFrame 进行后续操作\n",
    "\n",
    "        # 按照 'PaperID' 列升序排序\n",
    "        df_sorted = df.sort_values(by='PaperID', ascending=True)\n",
    "\n",
    "        # 将排序后的 DataFrame 保存为新的 TSV 文件，不包含索引\n",
    "        df_sorted.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"文件已按照 'PaperID' 数值大小升序排序，并保存到: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 输入文件 '{input_file_path}' 未找到.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"错误: 解析文件 '{input_file_path}' 失败，请检查文件格式是否为 TSV.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"键错误: 列名 '{e}' 不存在于文件中.\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误: {e}\")\n",
    "\n",
    "# 设置输入和输出文件路径\n",
    "input_tsv_file = 'PaperID_Year.tsv' # 上一步生成的文件名\n",
    "output_tsv_file = 'PaperID_Year_sorted.tsv' # 排序后的文件名\n",
    "\n",
    "# 执行排序操作\n",
    "sort_paperid_year_file(input_tsv_file, output_tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将包含 'Career Year' 的数据保存到: SciSciNet_MergedData_CareerYear.tsv\n",
      "   PaperID    AuthorID    Year  Atyp_Median_Z  Career_Start_Year  Career Year\n",
      "0       15   199142497  2013.0            NaN             2013.0          1.0\n",
      "1       23  1243978490  2012.0            NaN             2002.0         11.0\n",
      "2       79  2662843304  2009.0            NaN             2009.0          1.0\n",
      "3      108  2126642415  2013.0            NaN             2013.0          1.0\n",
      "4      125  2002579779  1988.0            NaN             1987.0          2.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135827039 entries, 0 to 135827038\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   PaperID            int64  \n",
      " 1   AuthorID           int64  \n",
      " 2   Year               float64\n",
      " 3   Atyp_Median_Z      float64\n",
      " 4   Career_Start_Year  float64\n",
      " 5   Career Year        float64\n",
      "dtypes: float64(4), int64(2)\n",
      "memory usage: 6.1 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'SciSciNet_MergedData_pandas.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 计算每位作者的职业生涯起始年份\n",
    "author_career_start_year = df.groupby('AuthorID')['Year'].min().reset_index()\n",
    "author_career_start_year.rename(columns={'Year': 'Career_Start_Year'}, inplace=True)\n",
    "\n",
    "# 合并 Career Start Year 到原始 DataFrame\n",
    "df_merged = pd.merge(df, author_career_start_year, on='AuthorID', how='left')\n",
    "\n",
    "# 计算 Career Year\n",
    "df_merged['Career Year'] = df_merged['Year'] - df_merged['Career_Start_Year'] + 1\n",
    "\n",
    "# (可选) 保存结果到新的 TSV 文件\n",
    "output_file_path = 'SciSciNet_MergedData_CareerYear.tsv'\n",
    "df_merged.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"已将包含 'Career Year' 的数据保存到: {output_file_path}\")\n",
    "\n",
    "# 打印结果DataFrame的信息，包括新的 'Career Year' 列\n",
    "print(df_merged.head())\n",
    "print(df_merged.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各职业生涯年份的论文数量统计:\n",
      "     Career Year  Paper_Count\n",
      "0            1.0     75151857\n",
      "1            2.0      7537801\n",
      "2            3.0      6268893\n",
      "3            4.0      5121045\n",
      "4            5.0      4330963\n",
      "..           ...          ...\n",
      "217        218.0          242\n",
      "218        219.0          169\n",
      "219        220.0          289\n",
      "220        221.0          126\n",
      "221        222.0           54\n",
      "\n",
      "[222 rows x 2 columns]\n",
      "\n",
      "已将结果保存到: CareerYear_PaperCounts.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_papers_by_career_year(input_file_path, output_file_path=None):\n",
    "    \"\"\"\n",
    "    统计每个职业生涯年份发表的论文数量。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件的路径 (SciSciNet_MergedData_CareerYear.tsv).\n",
    "        output_file_path (str, optional): 输出结果 TSV 文件的路径. 如果为 None，则只打印结果.\n",
    "                                         Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 包含职业生涯年份和论文数量的 DataFrame.\n",
    "                          如果 output_file_path 不为 None, 则返回的 DataFrame 也保存到文件.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取包含 'Career Year' 列的 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t')\n",
    "\n",
    "        # 按照 'Career Year' 分组，并计算每组的大小 (即论文数量)\n",
    "        career_year_counts = df.groupby('Career Year').size().reset_index(name='Paper_Count')\n",
    "\n",
    "        # 对结果按照 'Career Year' 升序排序 (可选，但通常使结果更有序)\n",
    "        career_year_counts_sorted = career_year_counts.sort_values(by='Career Year')\n",
    "\n",
    "        # 打印结果\n",
    "        print(\"各职业生涯年份的论文数量统计:\")\n",
    "        print(career_year_counts_sorted)\n",
    "\n",
    "        # 如果指定了输出文件路径，则保存结果到 TSV 文件\n",
    "        if output_file_path:\n",
    "            career_year_counts_sorted.to_csv(output_file_path, sep='\\t', index=False)\n",
    "            print(f\"\\n已将结果保存到: {output_file_path}\")\n",
    "\n",
    "        return career_year_counts_sorted\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 输入文件 '{input_file_path}' 未找到.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"错误: 解析文件 '{input_file_path}' 失败，请检查文件格式是否为 TSV.\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        print(f\"键错误: 列名 '{e}' 不存在于文件中. 确保文件包含 'Career Year' 列.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误: {e}\")\n",
    "        return None\n",
    "\n",
    "# 设置输入和输出文件路径\n",
    "input_tsv_file = 'SciSciNet_MergedData_CareerYear.tsv' # 上一步生成的文件名\n",
    "output_tsv_file = 'CareerYear_PaperCounts.tsv' # 输出统计结果的文件名 (可选)\n",
    "\n",
    "# 执行统计并保存结果 (如果需要保存文件，则取消注释 output_tsv_file 参数)\n",
    "career_year_paper_counts_df = count_papers_by_career_year(input_tsv_file, output_tsv_file)\n",
    "# 如果只想打印结果，可以这样调用:\n",
    "# career_year_paper_counts_df = count_papers_by_career_year(input_tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Career Year 列的描述性统计:\n",
      "count    1.358265e+08\n",
      "mean     5.736116e+00\n",
      "std      1.017554e+01\n",
      "min      1.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      1.000000e+00\n",
      "75%      6.000000e+00\n",
      "max      2.220000e+02\n",
      "Name: Career Year, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 35770 (\\N{CJK UNIFIED IDEOGRAPH-8BBA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 25991 (\\N{CJK UNIFIED IDEOGRAPH-6587}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30452 (\\N{CJK UNIFIED IDEOGRAPH-76F4}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 26041 (\\N{CJK UNIFIED IDEOGRAPH-65B9}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 22270 (\\N{CJK UNIFIED IDEOGRAPH-56FE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 绘制 Career Year 的箱线图，查看异常值\u001b[39;00m\n\u001b[0;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m---> 24\u001b[0m sns\u001b[38;5;241m.\u001b[39mboxplot(x\u001b[38;5;241m=\u001b[39mdf_career[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCareer Year\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCareer Year 箱线图 (异常值检测)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCareer Year\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\seaborn\\categorical.py:1634\u001b[0m, in \u001b[0;36mboxplot\u001b[1;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, dodge, width, gap, whis, linecolor, linewidth, fliersize, hue_norm, native_scale, log_scale, formatter, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m color \u001b[38;5;241m=\u001b[39m _default_color(\n\u001b[0;32m   1628\u001b[0m     ax\u001b[38;5;241m.\u001b[39mfill_between, hue, color,\n\u001b[0;32m   1629\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m]},\n\u001b[0;32m   1630\u001b[0m     saturation\u001b[38;5;241m=\u001b[39msaturation,\n\u001b[0;32m   1631\u001b[0m )\n\u001b[0;32m   1632\u001b[0m linecolor \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39m_complement_color(linecolor, color, p\u001b[38;5;241m.\u001b[39m_hue_map)\n\u001b[1;32m-> 1634\u001b[0m p\u001b[38;5;241m.\u001b[39mplot_boxes(\n\u001b[0;32m   1635\u001b[0m     width\u001b[38;5;241m=\u001b[39mwidth,\n\u001b[0;32m   1636\u001b[0m     dodge\u001b[38;5;241m=\u001b[39mdodge,\n\u001b[0;32m   1637\u001b[0m     gap\u001b[38;5;241m=\u001b[39mgap,\n\u001b[0;32m   1638\u001b[0m     fill\u001b[38;5;241m=\u001b[39mfill,\n\u001b[0;32m   1639\u001b[0m     whis\u001b[38;5;241m=\u001b[39mwhis,\n\u001b[0;32m   1640\u001b[0m     color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[0;32m   1641\u001b[0m     linecolor\u001b[38;5;241m=\u001b[39mlinecolor,\n\u001b[0;32m   1642\u001b[0m     linewidth\u001b[38;5;241m=\u001b[39mlinewidth,\n\u001b[0;32m   1643\u001b[0m     fliersize\u001b[38;5;241m=\u001b[39mfliersize,\n\u001b[0;32m   1644\u001b[0m     plot_kws\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   1645\u001b[0m )\n\u001b[0;32m   1647\u001b[0m p\u001b[38;5;241m.\u001b[39m_add_axis_labels(ax)\n\u001b[0;32m   1648\u001b[0m p\u001b[38;5;241m.\u001b[39m_adjust_cat_axis(ax, axis\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39morient)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\seaborn\\categorical.py:631\u001b[0m, in \u001b[0;36m_CategoricalPlotter.plot_boxes\u001b[1;34m(self, width, dodge, gap, fill, whis, color, linecolor, linewidth, fliersize, plot_kws)\u001b[0m\n\u001b[0;32m    627\u001b[0m props[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflier\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkersize\u001b[39m\u001b[38;5;124m\"\u001b[39m, fliersize)\n\u001b[0;32m    629\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39max\n\u001b[1;32m--> 631\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_vars, sub_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_data(iter_vars,\n\u001b[0;32m    632\u001b[0m                                          from_comp_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    633\u001b[0m                                          allow_empty\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    635\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axes(sub_vars)\n\u001b[0;32m    637\u001b[0m     grouped \u001b[38;5;241m=\u001b[39m sub_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient)[value_var]\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\seaborn\\_base.py:902\u001b[0m, in \u001b[0;36mVectorPlotter.iter_data\u001b[1;34m(self, grouping_vars, reverse, from_comp_data, by_facet, allow_empty, dropna)\u001b[0m\n\u001b[0;32m    899\u001b[0m grouping_vars \u001b[38;5;241m=\u001b[39m [var \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m grouping_vars \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables]\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_comp_data:\n\u001b[1;32m--> 902\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomp_data\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_data\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\seaborn\\_base.py:992\u001b[0m, in \u001b[0;36mVectorPlotter.comp_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    990\u001b[0m parts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    991\u001b[0m grouped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_data[var]\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverters[var], sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 992\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m converter, orig \u001b[38;5;129;01min\u001b[39;00m grouped:\n\u001b[0;32m    993\u001b[0m     orig \u001b[38;5;241m=\u001b[39m orig\u001b[38;5;241m.\u001b[39mmask(orig\u001b[38;5;241m.\u001b[39misin([np\u001b[38;5;241m.\u001b[39minf, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf]), np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m    994\u001b[0m     orig \u001b[38;5;241m=\u001b[39m orig\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\groupby\\ops.py:620\u001b[0m, in \u001b[0;36mBaseGrouper.get_iterator\u001b[1;34m(self, data, axis)\u001b[0m\n\u001b[0;32m    618\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(data, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    619\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_keys_seq\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, splitter)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\groupby\\ops.py:1150\u001b[0m, in \u001b[0;36mDataSplitter.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator:\n\u001b[1;32m-> 1150\u001b[0m     sdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sorted_data\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1153\u001b[0m         \u001b[38;5;66;03m# we are inside a generator, rather than raise StopIteration\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;66;03m# we merely return signal the end\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\groupby\\ops.py:1164\u001b[0m, in \u001b[0;36mDataSplitter._sorted_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sorted_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m-> 1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4131\u001b[0m     )\n\u001b[1;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[0;32m   4134\u001b[0m     indices,\n\u001b[0;32m   4135\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[0;32m   4136\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4137\u001b[0m )\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4140\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    895\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[0;32m    896\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[0;32m    897\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    898\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    899\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    900\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    689\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:773\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m             bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, sllen))\n\u001b[0;32m    772\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 773\u001b[0m                 blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    774\u001b[0m                     slobj,\n\u001b[0;32m    775\u001b[0m                     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    776\u001b[0m                     new_mgr_locs\u001b[38;5;241m=\u001b[39mbp,\n\u001b[0;32m    777\u001b[0m                     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    778\u001b[0m                 )\n\u001b[0;32m    779\u001b[0m             ]\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sl_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    782\u001b[0m     blknos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos[slobj]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m   1308\u001b[0m     values, indexer, axis\u001b[38;5;241m=\u001b[39maxis, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m   1309\u001b[0m )\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m func(arr, indexer, out, fill_value)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[0;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'SciSciNet_MergedData_CareerYear.tsv'\n",
    "df_career = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 描述性统计\n",
    "print(\"Career Year 列的描述性统计:\")\n",
    "print(df_career['Career Year'].describe())\n",
    "\n",
    "# 绘制 Career Year 的分布直方图\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_career['Career Year'], bins=100, kde=True) # bins 可以调整直方图的柱子数量\n",
    "plt.title('Career Year histogram')\n",
    "plt.xlabel('Career Year')\n",
    "plt.ylabel('Number of Papers')\n",
    "plt.xlim(0, 250) # 可以根据描述性统计的结果调整 x 轴范围，更清晰地展示分布\n",
    "plt.show()\n",
    "\n",
    "# 绘制 Career Year 的箱线图，查看异常值\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x=df_career['Career Year'])\n",
    "plt.title('Career Year 箱线图 (异常值检测)')\n",
    "plt.xlabel('Career Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各年份的论文数量统计:\n",
      "       Year  Paper_Count\n",
      "196  1800.0         1476\n",
      "203  1801.0          895\n",
      "209  1802.0          815\n",
      "206  1803.0          827\n",
      "218  1804.0          725\n",
      "..      ...          ...\n",
      "4    2018.0      5967295\n",
      "1    2019.0      6308169\n",
      "0    2020.0      6606804\n",
      "2    2021.0      6262356\n",
      "75   2022.0       105852\n",
      "\n",
      "[223 rows x 2 columns]\n",
      "\n",
      "已将结果保存到: Year_PaperCounts.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_papers_by_year(input_file_path, output_file_path=None):\n",
    "    \"\"\"\n",
    "    统计 SciSciNet_MergedData_CareerYear.tsv 文件中，每个年份发表的论文数量。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件的路径 (SciSciNet_MergedData_CareerYear.tsv).\n",
    "        output_file_path (str, optional): 输出结果 TSV 文件的路径. 如果为 None，则只打印结果.\n",
    "                                         Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 包含年份和论文数量的 DataFrame.\n",
    "                          如果 output_file_path 不为 None, 则返回的 DataFrame 也保存到文件.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t')\n",
    "\n",
    "        # 统计 'Year' 列中每个年份的出现次数\n",
    "        year_counts = df['Year'].value_counts().reset_index()\n",
    "        year_counts.columns = ['Year', 'Paper_Count'] # 设置列名\n",
    "\n",
    "        # 按照年份升序排序 (可选，但通常使结果更有序)\n",
    "        year_counts_sorted = year_counts.sort_values(by='Year')\n",
    "\n",
    "        # 打印结果\n",
    "        print(\"各年份的论文数量统计:\")\n",
    "        print(year_counts_sorted)\n",
    "\n",
    "        # 如果指定了输出文件路径，则保存结果到 TSV 文件\n",
    "        if output_file_path:\n",
    "            year_counts_sorted.to_csv(output_file_path, sep='\\t', index=False)\n",
    "            print(f\"\\n已将结果保存到: {output_file_path}\")\n",
    "\n",
    "        return year_counts_sorted\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 输入文件 '{input_file_path}' 未找到.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"错误: 解析文件 '{input_file_path}' 失败，请检查文件格式是否为 TSV.\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        print(f\"键错误: 列名 '{e}' 不存在于文件中. 确保文件包含 'Year' 列.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误: {e}\")\n",
    "        return None\n",
    "\n",
    "# 设置输入和输出文件路径\n",
    "input_tsv_file = 'SciSciNet_MergedData_CareerYear.tsv' # 你的输入文件名\n",
    "output_tsv_file = 'Year_PaperCounts.tsv' # 输出统计结果的文件名 (可选)\n",
    "\n",
    "# 执行统计并保存结果 (如果需要保存文件，则取消注释 output_tsv_file 参数)\n",
    "year_paper_counts_df = count_papers_by_year(input_tsv_file, output_tsv_file)\n",
    "# 如果只想打印结果，可以这样调用:\n",
    "# year_paper_counts_df = count_papers_by_year(input_tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将职业生涯年份大于等于 200 年的论文记录保存到: Long_Career_Years_Papers.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_long_career_years(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    从 SciSciNet_MergedData_CareerYear.tsv 文件中提取职业生涯年份超过或等于 200 年的论文记录，\n",
    "    并将这些记录保存到新的 TSV 文件。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件的路径 (SciSciNet_MergedData_CareerYear.tsv).\n",
    "        output_file_path (str): 输出 TSV 文件的路径，用于保存职业生涯年份过长的记录.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t')\n",
    "\n",
    "        # 筛选 'Career Year' 大于等于 200 的行\n",
    "        long_career_year_df = df[df['Career Year'] >= 200]\n",
    "\n",
    "        # 检查是否找到符合条件的记录\n",
    "        if long_career_year_df.empty:\n",
    "            print(\"没有找到职业生涯年份大于等于 200 年的论文记录。\")\n",
    "        else:\n",
    "            # 保存筛选结果到新的 TSV 文件，不包含索引\n",
    "            long_career_year_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "            print(f\"已将职业生涯年份大于等于 200 年的论文记录保存到: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 输入文件 '{input_file_path}' 未找到.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"错误: 解析文件 '{input_file_path}' 失败，请检查文件格式是否为 TSV.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"键错误: 列名 '{e}' 不存在于文件中. 确保文件包含 'Career Year' 列.\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误: {e}\")\n",
    "\n",
    "# 设置输入和输出文件路径\n",
    "input_tsv_file = 'SciSciNet_MergedData_CareerYear.tsv' # 你的输入文件名\n",
    "output_tsv_file = 'Long_Career_Years_Papers.tsv' # 输出文件名，用于保存职业生涯年份过长的论文记录\n",
    "\n",
    "# 执行提取操作\n",
    "extract_long_career_years(input_tsv_file, output_tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将职业生涯年份大于等于 200 年的论文记录保存到: Long_Career_Years_Papers_intraflow.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_long_career_years(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    从 SciSciNet_MergedData_CareerYear.tsv 文件中提取职业生涯年份超过或等于 200 年的论文记录，\n",
    "    并将这些记录保存到新的 TSV 文件。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件的路径 (SciSciNet_MergedData_CareerYear.tsv).\n",
    "        output_file_path (str): 输出 TSV 文件的路径，用于保存职业生涯年份过长的记录.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t')\n",
    "\n",
    "        # 筛选 'Career Year' 大于等于 200 的行\n",
    "        long_career_year_df = df[df['Career Year'] >= 200]\n",
    "\n",
    "        # 检查是否找到符合条件的记录\n",
    "        if long_career_year_df.empty:\n",
    "            print(\"没有找到职业生涯年份大于等于 200 年的论文记录。\")\n",
    "        else:\n",
    "            # 保存筛选结果到新的 TSV 文件，不包含索引\n",
    "            long_career_year_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "            print(f\"已将职业生涯年份大于等于 200 年的论文记录保存到: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 输入文件 '{input_file_path}' 未找到.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"错误: 解析文件 '{input_file_path}' 失败，请检查文件格式是否为 TSV.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"键错误: 列名 '{e}' 不存在于文件中. 确保文件包含 'Career Year' 列.\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误: {e}\")\n",
    "\n",
    "# 设置输入和输出文件路径\n",
    "input_tsv_file = 'Merged_Cleaned_InTraFlow_CareerYear.tsv' # 你的输入文件名\n",
    "output_tsv_file = 'Long_Career_Years_Papers_intraflow.tsv' # 输出文件名，用于保存职业生涯年份过长的论文记录\n",
    "\n",
    "# 执行提取操作\n",
    "extract_long_career_years(input_tsv_file, output_tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将合并后的文件保存到: Merged_Cleaned_InTraFlow_CareerYear.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_career_year_by_paperid(intraflow_file_path, career_year_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    根据 PaperID 将 Merged_Cleaned_InTraFlow.tsv 文件与 SciSciNet_MergedData_CareerYear.tsv 文件合并，\n",
    "    添加 Career Year 信息到 Merged_Cleaned_InTraFlow.tsv。\n",
    "\n",
    "    Args:\n",
    "        intraflow_file_path (str): Merged_Cleaned_InTraFlow.tsv 文件的路径.\n",
    "        career_year_file_path (str): SciSciNet_MergedData_CareerYear.tsv 文件的路径.\n",
    "        output_file_path (str): 输出合并后 TSV 文件的路径.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取 Merged_Cleaned_InTraFlow.tsv 文件\n",
    "        df_intraflow = pd.read_csv(intraflow_file_path, sep='\\t')\n",
    "\n",
    "        # 读取 SciSciNet_MergedData_CareerYear.tsv 文件，只读取 PaperID 和 Career Year 列\n",
    "        df_career_year = pd.read_csv(career_year_file_path, sep='\\t', usecols=['PaperID', 'Career Year'])\n",
    "\n",
    "        # 确保两个 DataFrame 中用于合并的列名都是 'PaperID'\n",
    "        # Merged_Cleaned_InTraFlow.tsv 的 PaperID 列在索引为 1 的位置，假设没有 header，或者header是第一行\n",
    "        # 假设 Merged_Cleaned_InTraFlow.tsv 的 header 是在第一行，并且第二列的列名可以自动识别或者不需要指定列名\n",
    "        # 如果 Merged_Cleaned_InTraFlow.tsv 没有 header 并且第二列没有列名，需要手动设置列名或者使用 header=None 并指定 names\n",
    "\n",
    "        # 假设 Merged_Cleaned_InTraFlow.tsv 的第二列就是 PaperID，且列名正确或可以访问，例如 \"PaperID\" 或 默认索引访问\n",
    "        # 如果列名不是 \"PaperID\"，或者需要根据位置访问，可能需要先检查或重命名列\n",
    "        # 为了通用性，假设 Merged_Cleaned_InTraFlow.tsv 的第二列（索引 1）是我们需要的 PaperID 列\n",
    "        # 并且假设它已经有一个合适的列名或者我们稍后可以通过索引来操作\n",
    "\n",
    "        # 合并两个 DataFrame，基于 'PaperID' 列\n",
    "        df_merged = pd.merge(df_intraflow, df_career_year, on='PaperID', how='left')\n",
    "\n",
    "        # 保存合并后的 DataFrame 到新的 TSV 文件\n",
    "        df_merged.to_csv(output_file_path, sep='\\t', index=False)\n",
    "        print(f\"已将合并后的文件保存到: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到，请检查文件路径是否正确.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"错误: 解析文件失败，请检查文件格式是否为 TSV.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"键错误: 列名 '{e}' 不存在于文件中. 确保文件包含 'PaperID' 和 'Career Year' 列.\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误: {e}\")\n",
    "\n",
    "# 设置文件路径\n",
    "intraflow_file = 'Merged_Cleaned_InTraFlow.tsv'\n",
    "career_year_file = 'SciSciNet_MergedData_CareerYear.tsv'\n",
    "output_file = 'Merged_Cleaned_InTraFlow_CareerYear.tsv' # 输出文件，将包含 Career Year\n",
    "\n",
    "# 执行合并操作\n",
    "merge_career_year_by_paperid(intraflow_file, career_year_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各年份的论文数量统计:\n",
      "       Year  Paper_Count\n",
      "196  1800.0         1510\n",
      "203  1801.0          905\n",
      "209  1802.0          825\n",
      "207  1803.0          833\n",
      "218  1804.0          729\n",
      "..      ...          ...\n",
      "4    2018.0      5845847\n",
      "1    2019.0      6148831\n",
      "0    2020.0      6415292\n",
      "2    2021.0      6058310\n",
      "75   2022.0       100990\n",
      "\n",
      "[223 rows x 2 columns]\n",
      "\n",
      "已将结果保存到: Year_PaperCounts_all.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_papers_by_year(input_file_path, output_file_path=None):\n",
    "    \"\"\"\n",
    "    统计 SciSciNet_MergedData_CareerYear.tsv 文件中，每个年份发表的论文数量。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件的路径 (SciSciNet_MergedData_CareerYear.tsv).\n",
    "        output_file_path (str, optional): 输出结果 TSV 文件的路径. 如果为 None，则只打印结果.\n",
    "                                         Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 包含年份和论文数量的 DataFrame.\n",
    "                          如果 output_file_path 不为 None, 则返回的 DataFrame 也保存到文件.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t')\n",
    "\n",
    "        # 统计 'Year' 列中每个年份的出现次数\n",
    "        year_counts = df['Year'].value_counts().reset_index()\n",
    "        year_counts.columns = ['Year', 'Paper_Count'] # 设置列名\n",
    "\n",
    "        # 按照年份升序排序 (可选，但通常使结果更有序)\n",
    "        year_counts_sorted = year_counts.sort_values(by='Year')\n",
    "\n",
    "        # 打印结果\n",
    "        print(\"各年份的论文数量统计:\")\n",
    "        print(year_counts_sorted)\n",
    "\n",
    "        # 如果指定了输出文件路径，则保存结果到 TSV 文件\n",
    "        if output_file_path:\n",
    "            year_counts_sorted.to_csv(output_file_path, sep='\\t', index=False)\n",
    "            print(f\"\\n已将结果保存到: {output_file_path}\")\n",
    "\n",
    "        return year_counts_sorted\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 输入文件 '{input_file_path}' 未找到.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"错误: 解析文件 '{input_file_path}' 失败，请检查文件格式是否为 TSV.\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        print(f\"键错误: 列名 '{e}' 不存在于文件中. 确保文件包含 'Year' 列.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误: {e}\")\n",
    "        return None\n",
    "\n",
    "# 设置输入和输出文件路径\n",
    "input_tsv_file = 'PaperID_Year_sorted.tsv' # 你的输入文件名\n",
    "output_tsv_file = 'Year_PaperCounts_all.tsv' # 输出统计结果的文件名 (可选)\n",
    "\n",
    "# 执行统计并保存结果 (如果需要保存文件，则取消注释 output_tsv_file 参数)\n",
    "year_paper_counts_df = count_papers_by_year(input_tsv_file, output_tsv_file)\n",
    "# 如果只想打印结果，可以这样调用:\n",
    "# year_paper_counts_df = count_papers_by_year(input_tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将职业生涯年份大于等于 200 年的论文记录保存到: Long_Career_Years_Papers_intraflow.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_long_career_years(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    从 SciSciNet_MergedData_CareerYear.tsv 文件中提取职业生涯年份超过或等于 200 年的论文记录，\n",
    "    并将这些记录保存到新的 TSV 文件。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件的路径 (SciSciNet_MergedData_CareerYear.tsv).\n",
    "        output_file_path (str): 输出 TSV 文件的路径，用于保存职业生涯年份过长的记录.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t')\n",
    "\n",
    "        # 筛选 'Career Year' 大于等于 200 的行\n",
    "        long_career_year_df = df[df['Career Year'] >= 200]\n",
    "\n",
    "        # 检查是否找到符合条件的记录\n",
    "        if long_career_year_df.empty:\n",
    "            print(\"没有找到职业生涯年份大于等于 200 年的论文记录。\")\n",
    "        else:\n",
    "            # 保存筛选结果到新的 TSV 文件，不包含索引\n",
    "            long_career_year_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "            print(f\"已将职业生涯年份大于等于 200 年的论文记录保存到: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 输入文件 '{input_file_path}' 未找到.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"错误: 解析文件 '{input_file_path}' 失败，请检查文件格式是否为 TSV.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"键错误: 列名 '{e}' 不存在于文件中. 确保文件包含 'Career Year' 列.\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误: {e}\")\n",
    "\n",
    "# 设置输入和输出文件路径\n",
    "input_tsv_file = 'Merged_Cleaned_InTraFlow_CareerYear.tsv' # 你的输入文件名\n",
    "output_tsv_file = 'Long_Career_Years_Papers_intraflow.tsv' # 输出文件名，用于保存职业生涯年份过长的论文记录\n",
    "\n",
    "# 执行提取操作\n",
    "extract_long_career_years(input_tsv_file, output_tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各年份的论文数量统计:\n",
      "       Year  Paper_Count\n",
      "183  1800.0           30\n",
      "219  1801.0            8\n",
      "222  1802.0            5\n",
      "199  1803.0           15\n",
      "216  1804.0            9\n",
      "..      ...          ...\n",
      "6    2018.0       593809\n",
      "1    2019.0       640476\n",
      "0    2020.0       652036\n",
      "2    2021.0       635015\n",
      "48   2022.0        18547\n",
      "\n",
      "[223 rows x 2 columns]\n",
      "\n",
      "已将结果保存到: Year_PaperCounts_intraflow.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_papers_by_year(input_file_path, output_file_path=None):\n",
    "    \"\"\"\n",
    "    统计 SciSciNet_MergedData_CareerYear.tsv 文件中，每个年份发表的论文数量。\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件的路径 (SciSciNet_MergedData_CareerYear.tsv).\n",
    "        output_file_path (str, optional): 输出结果 TSV 文件的路径. 如果为 None，则只打印结果.\n",
    "                                         Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 包含年份和论文数量的 DataFrame.\n",
    "                          如果 output_file_path 不为 None, 则返回的 DataFrame 也保存到文件.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t')\n",
    "\n",
    "        # 统计 'Year' 列中每个年份的出现次数\n",
    "        year_counts = df['Year'].value_counts().reset_index()\n",
    "        year_counts.columns = ['Year', 'Paper_Count'] # 设置列名\n",
    "\n",
    "        # 按照年份升序排序 (可选，但通常使结果更有序)\n",
    "        year_counts_sorted = year_counts.sort_values(by='Year')\n",
    "\n",
    "        # 打印结果\n",
    "        print(\"各年份的论文数量统计:\")\n",
    "        print(year_counts_sorted)\n",
    "\n",
    "        # 如果指定了输出文件路径，则保存结果到 TSV 文件\n",
    "        if output_file_path:\n",
    "            year_counts_sorted.to_csv(output_file_path, sep='\\t', index=False)\n",
    "            print(f\"\\n已将结果保存到: {output_file_path}\")\n",
    "\n",
    "        return year_counts_sorted\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 输入文件 '{input_file_path}' 未找到.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"错误: 解析文件 '{input_file_path}' 失败，请检查文件格式是否为 TSV.\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        print(f\"键错误: 列名 '{e}' 不存在于文件中. 确保文件包含 'Year' 列.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误: {e}\")\n",
    "        return None\n",
    "\n",
    "# 设置输入和输出文件路径\n",
    "input_tsv_file = 'Merged_Cleaned_InTraFlow_CareerYear.tsv' # 你的输入文件名\n",
    "output_tsv_file = 'Year_PaperCounts_intraflow.tsv' # 输出统计结果的文件名 (可选)\n",
    "\n",
    "# 执行统计并保存结果 (如果需要保存文件，则取消注释 output_tsv_file 参数)\n",
    "year_paper_counts_df = count_papers_by_year(input_tsv_file, output_tsv_file)\n",
    "# 如果只想打印结果，可以这样调用:\n",
    "# year_paper_counts_df = count_papers_by_year(input_tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将 Career Year 在80年以内的数据，并处理inf值的按 Career Year 分组计算的均值结果输出到文件: CareerYear_Grouped_Means_CareerYearFiltered_NaNInf.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (包括原始的 InTraFlow 列)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'InTraFlowf', 'InTraFlow', 'N_InTraFlow', 'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng',\n",
    "    'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN\n",
    "for col in columns_to_mean:\n",
    "    if df[col].dtype in ['float64', 'int64']: # 仅对数值型列进行 inf 值处理\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 按 'Career Year' 分组并计算均值\n",
    "career_year_group_means = df.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "\n",
    "# 输出到 Excel 文件\n",
    "output_excel_file = 'CareerYear_Grouped_Means_CareerYearFiltered_NaNInf.xlsx' # 修改输出文件名以反映修改\n",
    "career_year_group_means.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"已将 Career Year 在80年以内的数据，并处理inf值的按 Career Year 分组计算的均值结果输出到文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将高低 InTraFlow 组按 Career Year 分组计算的均值结果输出到文件: CareerYear_Grouped_Means_HighLowInTraFlow.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (排除 InTraFlow 本身，以及其他不需要的列，和之前的保持一致)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng',\n",
    "    'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN (在计算百分位数之前处理)\n",
    "for col in columns_to_mean + ['InTraFlow', 'N_InTraFlow']: # 包括 InTraFlow 和 N_InTraFlow 列\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 划分 InTraFlow 高低组\n",
    "q1_intraflow = df['InTraFlow'].quantile(0.25)\n",
    "q3_intraflow = df['InTraFlow'].quantile(0.75)\n",
    "\n",
    "df_low_intraflow = df[df['InTraFlow'] <= q1_intraflow]\n",
    "df_high_intraflow = df[df['InTraFlow'] >= q3_intraflow]\n",
    "\n",
    "# 步骤 4: 分别计算高低 InTraFlow 组在每个 Career Year 的平均值\n",
    "mean_low_intraflow = df_low_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "mean_high_intraflow = df_high_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "\n",
    "# 步骤 5: 输出到 Excel 文件，不同 sheet 存放高低组数据\n",
    "output_excel_file = 'CareerYear_Grouped_Means_HighLowInTraFlow.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(output_excel_file) as writer:\n",
    "    mean_low_intraflow.to_excel(writer, sheet_name='Low_InTraFlow', index=False)\n",
    "    mean_high_intraflow.to_excel(writer, sheet_name='High_InTraFlow', index=False)\n",
    "\n",
    "print(f\"已将高低 InTraFlow 组按 Career Year 分组计算的均值结果输出到文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将高低 InTraFlow 组按 Career Year 分组计算的均值结果合并输出到文件: CareerYear_Grouped_Means_Combined_HighLowInTraFlow.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (排除 InTraFlow 本身，以及其他不需要的列，和之前的保持一致)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng',\n",
    "    'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN (在计算百分位数之前处理)\n",
    "for col in columns_to_mean + ['InTraFlow', 'N_InTraFlow']: # 包括 InTraFlow 和 N_InTraFlow 列\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 划分 InTraFlow 高低组\n",
    "q1_intraflow = df['InTraFlow'].quantile(0.25)\n",
    "q3_intraflow = df['InTraFlow'].quantile(0.75)\n",
    "\n",
    "df_low_intraflow = df[df['InTraFlow'] <= q1_intraflow]\n",
    "df_high_intraflow = df[df['InTraFlow'] >= q3_intraflow]\n",
    "\n",
    "# 步骤 4: 分别计算高低 InTraFlow 组在每个 Career Year 的平均值\n",
    "mean_low_intraflow = df_low_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "mean_high_intraflow = df_high_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "\n",
    "# 步骤 5: 添加 'InTraFlow Group' 列，用于区分高低组\n",
    "mean_low_intraflow['InTraFlow Group'] = 'Low'\n",
    "mean_high_intraflow['InTraFlow Group'] = 'High'\n",
    "\n",
    "# 步骤 6: 合并高低 InTraFlow 组的数据到一个 DataFrame\n",
    "combined_means = pd.concat([mean_low_intraflow, mean_high_intraflow], ignore_index=True)\n",
    "\n",
    "# 步骤 7: 输出到 Excel 文件，所有数据在同一个 sheet\n",
    "output_excel_file = 'CareerYear_Grouped_Means_Combined_HighLowInTraFlow.xlsx'\n",
    "combined_means.to_excel(output_excel_file, sheet_name='Combined_Means', index=False)\n",
    "\n",
    "print(f\"已将高低 InTraFlow 组按 Career Year 分组计算的均值结果合并输出到文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将高低 InTraFlow 组按 Career Year 分组计算的均值结果横向合并输出到文件: CareerYear_Grouped_Means_Horizontal_HighLowInTraFlow.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (排除 InTraFlow 本身，以及其他不需要的列，和之前的保持一致)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng',\n",
    "    'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN (在计算百分位数之前处理)\n",
    "for col in columns_to_mean + ['InTraFlow', 'N_InTraFlow']: # 包括 InTraFlow 和 N_InTraFlow 列\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 划分 InTraFlow 高低组\n",
    "q1_intraflow = df['InTraFlow'].quantile(0.25)\n",
    "q3_intraflow = df['InTraFlow'].quantile(0.75)\n",
    "\n",
    "df_low_intraflow = df[df['InTraFlow'] <= q1_intraflow]\n",
    "df_high_intraflow = df[df['InTraFlow'] >= q3_intraflow]\n",
    "\n",
    "# 步骤 4: 分别计算高低 InTraFlow 组在每个 Career Year 的平均值\n",
    "mean_low_intraflow = df_low_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "mean_high_intraflow = df_high_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "\n",
    "# 步骤 5: 重命名列名，添加 \"_Low\" 和 \"_High\" 后缀\n",
    "mean_low_intraflow.columns = ['Career Year'] + [col + '_Low' for col in columns_to_mean]\n",
    "mean_high_intraflow.columns = ['Career Year'] + [col + '_High' for col in columns_to_mean]\n",
    "\n",
    "# 步骤 6: 横向合并高低 InTraFlow 组的数据，基于 'Career Year'\n",
    "combined_means_horizontal = pd.merge(mean_low_intraflow, mean_high_intraflow, on='Career Year', how='outer')\n",
    "\n",
    "# 步骤 7: 输出到 Excel 文件，所有数据在同一个 sheet，横向排列\n",
    "output_excel_file = 'CareerYear_Grouped_Means_Horizontal_HighLowInTraFlow.xlsx'\n",
    "combined_means_horizontal.to_excel(output_excel_file, sheet_name='Horizontal_Combined_Means', index=False)\n",
    "\n",
    "print(f\"已将高低 InTraFlow 组按 Career Year 分组计算的均值结果横向合并输出到文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将高低 N_InTraFlow 组按 Career Year 分组计算的均值结果横向合并输出到文件: CareerYear_Grouped_Means_Horizontal_HighLowN_InTraFlow.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (排除 InTraFlow 本身，以及其他不需要的列，和之前的保持一致)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng',\n",
    "    'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN (在计算百分位数之前处理)\n",
    "for col in columns_to_mean + ['InTraFlow', 'N_InTraFlow']: # 包括 InTraFlow 和 N_InTraFlow 列\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 划分 N_InTraFlow 高低组 (修改为 N_InTraFlow)\n",
    "q1_n_intraflow = df['N_InTraFlow'].quantile(0.25) # 修改为 N_InTraFlow\n",
    "q3_n_intraflow = df['N_InTraFlow'].quantile(0.75) # 修改为 N_InTraFlow\n",
    "\n",
    "df_low_n_intraflow = df[df['N_InTraFlow'] <= q1_n_intraflow] # 修改为 N_InTraFlow 和 q1_n_intraflow\n",
    "df_high_n_intraflow = df[df['N_InTraFlow'] >= q3_n_intraflow] # 修改为 N_InTraFlow 和 q3_n_intraflow\n",
    "\n",
    "# 步骤 4: 分别计算高低 N_InTraFlow 组在每个 Career Year 的平均值 (修改为 N_InTraFlow)\n",
    "mean_low_n_intraflow = df_low_n_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index() # 修改为 df_low_n_intraflow\n",
    "mean_high_n_intraflow = df_high_n_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index() # 修改为 df_high_n_intraflow\n",
    "\n",
    "# 步骤 5: 重命名列名，添加 \"_Low_N\" 和 \"_High_N\" 后缀 (修改为 N_InTraFlow)\n",
    "mean_low_n_intraflow.columns = ['Career Year'] + [col + '_Low_N' for col in columns_to_mean] # 修改后缀为 _Low_N\n",
    "mean_high_n_intraflow.columns = ['Career Year'] + [col + '_High_N' for col in columns_to_mean] # 修改后缀为 _High_N\n",
    "\n",
    "# 步骤 6: 横向合并高低 N_InTraFlow 组的数据，基于 'Career Year' (修改为 N_InTraFlow)\n",
    "combined_means_horizontal = pd.merge(mean_low_n_intraflow, mean_high_n_intraflow, on='Career Year', how='outer') # 修改为 mean_low_n_intraflow 和 mean_high_n_intraflow\n",
    "\n",
    "# 步骤 7: 输出到 Excel 文件，所有数据在同一个 sheet，横向排列 (修改为 N_InTraFlow 文件名)\n",
    "output_excel_file = 'CareerYear_Grouped_Means_Horizontal_HighLowN_InTraFlow.xlsx' # 修改输出文件名为 N_InTraFlow\n",
    "combined_means_horizontal.to_excel(output_excel_file, sheet_name='Horizontal_Combined_Means_N', index=False) # 修改 sheet 名为 N_InTraFlow\n",
    "\n",
    "print(f\"已将高低 N_InTraFlow 组按 Career Year 分组计算的均值结果横向合并输出到文件: {output_excel_file}\") # 修改输出信息为 N_InTraFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将高低 N_InTraFlow 组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)横向合并输出到文件: CareerYear_Grouped_Means_Horizontal_HighLowN_InTraFlow_IncN.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (现在包括 'N_InTraFlow' 以及其他指标)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng',\n",
    "    'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'N_InTraFlow' # 添加 'N_InTraFlow'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN (在计算百分位数之前处理)\n",
    "for col in columns_to_mean: #  现在只需要 columns_to_mean\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 划分 N_InTraFlow 高低组\n",
    "q1_n_intraflow = df['N_InTraFlow'].quantile(0.25)\n",
    "q3_n_intraflow = df['N_InTraFlow'].quantile(0.75)\n",
    "\n",
    "df_low_n_intraflow = df[df['N_InTraFlow'] <= q1_n_intraflow]\n",
    "df_high_n_intraflow = df[df['N_InTraFlow'] >= q3_n_intraflow]\n",
    "\n",
    "# 步骤 4: 分别计算高低 N_InTraFlow 组在每个 Career Year 的平均值\n",
    "mean_low_n_intraflow = df_low_n_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "mean_high_n_intraflow = df_high_n_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "\n",
    "# 步骤 5: 重命名列名，添加 \"_Low_N\" 和 \"_High_N\" 后缀\n",
    "mean_low_n_intraflow.columns = ['Career Year'] + [col + '_Low_N' for col in columns_to_mean]\n",
    "mean_high_n_intraflow.columns = ['Career Year'] + [col + '_High_N' for col in columns_to_mean]\n",
    "\n",
    "# 步骤 6: 横向合并高低 N_InTraFlow 组的数据，基于 'Career Year'\n",
    "combined_means_horizontal = pd.merge(mean_low_n_intraflow, mean_high_n_intraflow, on='Career Year', how='outer')\n",
    "\n",
    "# 步骤 7: 输出到 Excel 文件，所有数据在同一个 sheet，横向排列\n",
    "output_excel_file = 'CareerYear_Grouped_Means_Horizontal_HighLowN_InTraFlow_IncN.xlsx' # 修改文件名，缩短\n",
    "combined_means_horizontal.to_excel(output_excel_file, sheet_name='Horizontal_N', index=False) # 修改 sheet 名为 Horizontal_N (shorter)\n",
    "\n",
    "print(f\"已将高低 N_InTraFlow 组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)横向合并输出到文件: {output_excel_file}\") # 修改输出信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将高低 N_InTraFlow 组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)横向合并输出到文件: CareerYear_Grouped_Means_Horizontal_HighLowN_InTraFlow_Inc.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (现在包括 'N_InTraFlow' 以及其他指标)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng',\n",
    "    'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'N_InTraFlow' # 添加 'N_InTraFlow'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN (在计算百分位数之前处理)\n",
    "for col in columns_to_mean: #  现在只需要 columns_to_mean\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 划分 N_InTraFlow 高低组\n",
    "q1_n_intraflow = df['InTraFlow'].quantile(0.25)\n",
    "q3_n_intraflow = df['InTraFlow'].quantile(0.75)\n",
    "\n",
    "df_low_n_intraflow = df[df['InTraFlow'] <= q1_n_intraflow]\n",
    "df_high_n_intraflow = df[df['InTraFlow'] >= q3_n_intraflow]\n",
    "\n",
    "# 步骤 4: 分别计算高低 N_InTraFlow 组在每个 Career Year 的平均值\n",
    "mean_low_n_intraflow = df_low_n_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "mean_high_n_intraflow = df_high_n_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "\n",
    "# 步骤 5: 重命名列名，添加 \"_Low_N\" 和 \"_High_N\" 后缀\n",
    "mean_low_n_intraflow.columns = ['Career Year'] + [col + '_Low' for col in columns_to_mean]\n",
    "mean_high_n_intraflow.columns = ['Career Year'] + [col + '_High' for col in columns_to_mean]\n",
    "\n",
    "# 步骤 6: 横向合并高低 N_InTraFlow 组的数据，基于 'Career Year'\n",
    "combined_means_horizontal = pd.merge(mean_low_n_intraflow, mean_high_n_intraflow, on='Career Year', how='outer')\n",
    "\n",
    "# 步骤 7: 输出到 Excel 文件，所有数据在同一个 sheet，横向排列\n",
    "output_excel_file = 'CareerYear_Grouped_Means_Horizontal_HighLowN_InTraFlow_Inc.xlsx' # 修改文件名，缩短\n",
    "combined_means_horizontal.to_excel(output_excel_file, sheet_name='Horizontal_N', index=False) # 修改 sheet 名为 Horizontal_N (shorter)\n",
    "\n",
    "print(f\"已将高低 N_InTraFlow 组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)横向合并输出到文件: {output_excel_file}\") # 修改输出信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将 InTraFlow 排序后，前25% (Bottom 25%) 和后25% (Top 25%) 组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)横向合并输出到文件: CareerYear_Grouped_Means_Horizontal_TopBottom25N_InTraFlow_Inc.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (现在包括 'N_InTraFlow' 以及其他指标)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng',\n",
    "    'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'N_InTraFlow' # 添加 'N_InTraFlow'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN (在计算百分位数之前处理)\n",
    "for col in columns_to_mean: #  现在只需要 columns_to_mean\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 严格筛选 InTraFlow 列的前 25% 和后 25%\n",
    "\n",
    "# 3.1: 按照 'InTraFlow' 列排序 DataFrame\n",
    "df_sorted_intraflow = df.sort_values(by='InTraFlow', ascending=True)\n",
    "\n",
    "# 3.2: 计算 25% 和 75% 的索引位置\n",
    "n_rows = len(df_sorted_intraflow)\n",
    "index_25 = int(0.25 * n_rows)\n",
    "index_75 = int(0.75 * n_rows) # 75% 索引用于确定 top 25% 的起始位置\n",
    "\n",
    "# 3.3: 提取前 25% (bottom 25% based on InTraFlow value) 和 后 25% (top 25% based on InTraFlow value)\n",
    "df_bottom_25_intraflow = df_sorted_intraflow.iloc[:index_25] #  严格取前 index_25 行作为 bottom 25%\n",
    "df_top_25_intraflow = df_sorted_intraflow.iloc[index_75:]   #  严格取 index_75 行之后的所有行作为 top 25%\n",
    "\n",
    "\n",
    "# 步骤 4: 分别计算 前 25% 和 后 25% InTraFlow 组在每个 Career Year 的平均值\n",
    "mean_bottom_25_intraflow = df_bottom_25_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "mean_top_25_intraflow = df_top_25_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "\n",
    "# 步骤 5: 重命名列名，添加 \"_Bottom25_N\" 和 \"_Top25_N\" 后缀\n",
    "mean_bottom_25_intraflow.columns = ['Career Year'] + [col + '_Bottom25' for col in columns_to_mean]\n",
    "mean_top_25_intraflow.columns = ['Career Year'] + [col + '_Top25' for col in columns_to_mean]\n",
    "\n",
    "# 步骤 6: 横向合并 前 25% 和 后 25% InTraFlow 组的数据，基于 'Career Year'\n",
    "combined_means_horizontal = pd.merge(mean_bottom_25_intraflow, mean_top_25_intraflow, on='Career Year', how='outer')\n",
    "\n",
    "# 步骤 7: 输出到 Excel 文件，所有数据在同一个 sheet，横向排列\n",
    "output_excel_file = 'CareerYear_Grouped_Means_Horizontal_TopBottom25N_InTraFlow_Inc.xlsx' # 修改文件名，更清晰\n",
    "combined_means_horizontal.to_excel(output_excel_file, sheet_name='Horizontal_TopBottom25N', index=False) # 修改 sheet 名\n",
    "\n",
    "print(f\"已将 InTraFlow 排序后，前25% (Bottom 25%) 和后25% (Top 25%) 组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)横向合并输出到文件: {output_excel_file}\") # 修改输出信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将 N_InTraFlow 排序后，前25% (Bottom 25%) 和后25% (Top 25%) 组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)横向合并输出到文件: CareerYear_Grouped_Means_Horizontal_TopBottom25N_N_InTraFlow_Inc.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (现在包括 'N_InTraFlow' 以及其他指标)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng',\n",
    "    'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'N_InTraFlow' # 添加 'N_InTraFlow'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN (在计算百分位数之前处理)\n",
    "for col in columns_to_mean: #  现在只需要 columns_to_mean\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 严格筛选 N_InTraFlow 列的前 25% 和后 25%\n",
    "\n",
    "# 3.1: 按照 'N_InTraFlow' 列排序 DataFrame\n",
    "df_sorted_n_intraflow = df.sort_values(by='N_InTraFlow', ascending=True) # 修改为 'N_InTraFlow'\n",
    "\n",
    "# 3.2: 计算 25% 和 75% 的索引位置\n",
    "n_rows = len(df_sorted_n_intraflow)\n",
    "index_25 = int(0.25 * n_rows)\n",
    "index_75 = int(0.75 * n_rows) # 75% 索引用于确定 top 25% 的起始位置\n",
    "\n",
    "# 3.3: 提取前 25% (bottom 25% based on N_InTraFlow value) 和 后 25% (top 25% based on N_InTraFlow value)\n",
    "df_bottom_25_n_intraflow = df_sorted_n_intraflow.iloc[:index_25] #  严格取前 index_25 行作为 bottom 25%\n",
    "df_top_25_n_intraflow = df_sorted_n_intraflow.iloc[index_75:]   #  严格取 index_75 行之后的所有行作为 top 25%\n",
    "\n",
    "\n",
    "# 步骤 4: 分别计算 前 25% 和 后 25% N_InTraFlow 组在每个 Career Year 的平均值\n",
    "mean_bottom_25_n_intraflow = df_bottom_25_n_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "mean_top_25_n_intraflow = df_top_25_n_intraflow.groupby('Career Year')[columns_to_mean].mean().reset_index()\n",
    "\n",
    "# 步骤 5: 重命名列名，添加 \"_Bottom25_N\" 和 \"_Top25_N\" 后缀 (保持不变，因为后缀已经体现 N)\n",
    "mean_bottom_25_n_intraflow.columns = ['Career Year'] + [col + '_Bottom25' for col in columns_to_mean]\n",
    "mean_top_25_n_intraflow.columns = ['Career Year'] + [col + '_Top25' for col in columns_to_mean]\n",
    "\n",
    "# 步骤 6: 横向合并 前 25% 和 后 25% N_InTraFlow 组的数据，基于 'Career Year'\n",
    "combined_means_horizontal = pd.merge(mean_bottom_25_n_intraflow, mean_top_25_n_intraflow, on='Career Year', how='outer')\n",
    "\n",
    "# 步骤 7: 输出到 Excel 文件，所有数据在同一个 sheet，横向排列\n",
    "output_excel_file = 'CareerYear_Grouped_Means_Horizontal_TopBottom25N_N_InTraFlow_Inc.xlsx' # 修改文件名，更清晰，更明确 N_InTraFlow\n",
    "combined_means_horizontal.to_excel(output_excel_file, sheet_name='Horizontal_TopBottom25N', index=False) # 修改 sheet 名 (保持不变)\n",
    "\n",
    "print(f\"已将 N_InTraFlow 排序后，前25% (Bottom 25%) 和后25% (Top 25%) 组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)横向合并输出到文件: {output_excel_file}\") # 修改输出信息，更明确 N_InTraFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将基于 N_InTraFlow 总体平均值分组的高低组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)输出到文件: Avg N_InTraFlow.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (现在包括 'N_InTraFlow' 以及其他指标)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'N_InTraFlow'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN\n",
    "for col in columns_to_mean:\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 计算 N_InTraFlow 的总体平均值\n",
    "overall_mean_n_intraflow = df['N_InTraFlow'].mean()\n",
    "\n",
    "# 步骤 4: 基于总体平均值划分 N_InTraFlow 高低组\n",
    "df['N_InTraFlow_Group'] = np.where(df['N_InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 5: 分别计算高低 N_InTraFlow 组在每个 Career Year 的平均值\n",
    "mean_grouped_n_intraflow = df.groupby(['Career Year', 'N_InTraFlow_Group'])[columns_to_mean].mean().reset_index()\n",
    "\n",
    "# 步骤 6:  数据透视，将 'N_InTraFlow_Group' 的 'Low_N_Avg' 和 'High_N_Avg' 变为列\n",
    "pivot_df = mean_grouped_n_intraflow.pivot(index='Career Year', columns='N_InTraFlow_Group', values=columns_to_mean)\n",
    "\n",
    "# 步骤 7: 展平多级列索引，并重命名列名\n",
    "pivot_df.columns = [f'{col}_{group}' for group, col in pivot_df.columns]\n",
    "pivot_df = pivot_df.reset_index() # 将 Career Year 变回列\n",
    "\n",
    "# 步骤 8: 输出到 Excel 文件\n",
    "output_excel_file = 'Avg N_InTraFlow.xlsx' # 修改文件名\n",
    "pivot_df.to_excel(output_excel_file, sheet_name='Horizontal_AvgN', index=False) # 修改 sheet 名\n",
    "\n",
    "print(f\"已将基于 N_InTraFlow 总体平均值分组的高低组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)输出到文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将基于 N_InTraFlow 总体平均值分组的高低组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)输出到文件: Avg InTraFlow.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (现在包括 'InTraFlow' 以及其他指标)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'InTraFlow'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN\n",
    "for col in columns_to_mean:\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 计算 N_InTraFlow 的总体平均值\n",
    "overall_mean_n_intraflow = df['InTraFlow'].mean()\n",
    "\n",
    "# 步骤 4: 基于总体平均值划分 N_InTraFlow 高低组\n",
    "df['InTraFlow_Group'] = np.where(df['InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 5: 分别计算高低 N_InTraFlow 组在每个 Career Year 的平均值\n",
    "mean_grouped_n_intraflow = df.groupby(['Career Year', 'InTraFlow_Group'])[columns_to_mean].mean().reset_index()\n",
    "\n",
    "# 步骤 6:  数据透视，将 'InTraFlow_Group' 的 'Low_N_Avg' 和 'High_N_Avg' 变为列\n",
    "pivot_df = mean_grouped_n_intraflow.pivot(index='Career Year', columns='InTraFlow_Group', values=columns_to_mean)\n",
    "\n",
    "# 步骤 7: 展平多级列索引，并重命名列名\n",
    "pivot_df.columns = [f'{col}_{group}' for group, col in pivot_df.columns]\n",
    "pivot_df = pivot_df.reset_index() # 将 Career Year 变回列\n",
    "\n",
    "# 步骤 8: 输出到 Excel 文件\n",
    "output_excel_file = 'Avg InTraFlow.xlsx' # 修改文件名\n",
    "pivot_df.to_excel(output_excel_file, sheet_name='Horizontal_AvgN', index=False) # 修改 sheet 名\n",
    "\n",
    "print(f\"已将基于 N_InTraFlow 总体平均值分组的高低组按 Career Year 分组计算的均值结果(包括 N_InTraFlow 均值)输出到文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将不同 N_InTraFlow 组各项指标的变异系数 (CV) 计算结果输出到文件: N_InTraFlow_Grouped_CVs.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 60]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (现在包括 'N_InTraFlow' 以及其他指标)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'N_InTraFlow'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN\n",
    "for col in columns_to_mean:\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 计算 N_InTraFlow 的总体平均值 (与之前的代码相同)\n",
    "overall_mean_n_intraflow = df['N_InTraFlow'].mean()\n",
    "\n",
    "# 步骤 4: 基于总体平均值划分 N_InTraFlow 高低组 (与之前的代码相同)\n",
    "df['N_InTraFlow_Group'] = np.where(df['N_InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 5: 计算不同 N_InTraFlow 组各项指标的变异系数 (CV)\n",
    "def coefficient_of_variation(series):\n",
    "    \"\"\"计算变异系数 (Coefficient of Variation, CV)\"\"\"\n",
    "    return series.std() / series.mean()\n",
    "\n",
    "cv_n_intraflow_group = df.groupby('N_InTraFlow_Group')[columns_to_mean].agg(coefficient_of_variation).reset_index()\n",
    "\n",
    "# 步骤 6: 重命名列名，添加 \"_CV\" 后缀，并调整列顺序\n",
    "new_columns = ['N_InTraFlow_Group'] + [col + '_CV' for col in columns_to_mean]\n",
    "cv_n_intraflow_group.columns = new_columns\n",
    "\n",
    "# 步骤 7: 输出到 Excel 文件\n",
    "output_excel_file = 'N_InTraFlow_Grouped_CVs.xlsx' # 修改文件名，更简洁\n",
    "cv_n_intraflow_group.to_excel(output_excel_file, sheet_name='CV_by_N_Group', index=False) # 修改 sheet 名\n",
    "\n",
    "print(f\"已将不同 N_InTraFlow 组各项指标的变异系数 (CV) 计算结果输出到文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将按 Career Year 分组计算的各项指标变异系数 (CV) 结果输出到文件: CareerYear_Grouped_CVs.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 60]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (现在包括 'N_InTraFlow' 以及其他指标)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'N_InTraFlow'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN\n",
    "for col in columns_to_mean:\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 定义计算变异系数 (CV) 的函数 (如果之前没有定义过)\n",
    "def coefficient_of_variation(series):\n",
    "    \"\"\"计算变异系数 (Coefficient of Variation, CV)\"\"\"\n",
    "    return series.std() / series.mean()\n",
    "\n",
    "# 步骤 4: 按照 Career Year 分组，并计算各项指标的变异系数 (CV)\n",
    "cv_career_year = df.groupby('Career Year')[columns_to_mean].agg(coefficient_of_variation).reset_index()\n",
    "\n",
    "# 步骤 5: 重命名列名，添加 \"_CV\" 后缀\n",
    "new_columns = ['Career Year'] + [col + '_CV' for col in columns_to_mean]\n",
    "cv_career_year.columns = new_columns\n",
    "\n",
    "# 步骤 6: 输出到 Excel 文件\n",
    "output_excel_file = 'CareerYear_Grouped_CVs.xlsx' # 修改文件名，更简洁\n",
    "cv_career_year.to_excel(output_excel_file, sheet_name='CV_by_CareerYear', index=False) # 修改 sheet 名\n",
    "\n",
    "print(f\"已将按 Career Year 分组计算的各项指标变异系数 (CV) 结果输出到文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_22896\\73924790.py:32: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return series.std() / series.mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将按 Career Year 和 N_InTraFlow 组分组计算的各项指标变异系数 (CV) 结果输出到文件: CareerYearCVs_N_InTraFlow.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 60]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (现在包括 'N_InTraFlow' 以及其他指标)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'N_InTraFlow'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN\n",
    "for col in columns_to_mean:\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 计算 N_InTraFlow 的总体平均值 (与之前的代码相同)\n",
    "overall_mean_n_intraflow = df['N_InTraFlow'].mean()\n",
    "\n",
    "# 步骤 4: 基于总体平均值划分 N_InTraFlow 高低组 (与之前的代码相同)\n",
    "df['N_InTraFlow_Group'] = np.where(df['N_InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 5: 定义计算变异系数 (CV) 的函数 (如果之前没有定义过)\n",
    "def coefficient_of_variation(series):\n",
    "    \"\"\"计算变异系数 (Coefficient of Variation, CV)\"\"\"\n",
    "    return series.std() / series.mean()\n",
    "\n",
    "# 步骤 6: 按照 Career Year 和 N_InTraFlow_Group 分组，并计算各项指标的变异系数 (CV)\n",
    "cv_career_year_n_group = df.groupby(['Career Year', 'N_InTraFlow_Group'])[columns_to_mean].agg(coefficient_of_variation).reset_index()\n",
    "\n",
    "# 步骤 7:  数据透视，将 'N_InTraFlow_Group' 的 'Low_N_Avg' 和 'High_N_Avg' 变为列\n",
    "pivot_cv_df = cv_career_year_n_group.pivot(index='Career Year', columns='N_InTraFlow_Group', values=columns_to_mean)\n",
    "\n",
    "# 步骤 8: 展平多级列索引，并重命名列名\n",
    "pivot_cv_df.columns = [f'{col}_CV_{group}' for group, col in pivot_cv_df.columns]\n",
    "pivot_cv_df = pivot_cv_df.reset_index() # 将 Career Year 变回列\n",
    "\n",
    "# 步骤 9: 输出到 Excel 文件\n",
    "output_excel_file = 'CareerYearCVs_N_InTraFlow.xlsx' # 修改文件名，更详细\n",
    "pivot_cv_df.to_excel(output_excel_file, sheet_name='CV_by_CareerYear_NGroup', index=False) # 修改 sheet 名\n",
    "\n",
    "print(f\"已将按 Career Year 和 N_InTraFlow 组分组计算的各项指标变异系数 (CV) 结果输出到文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将按 Career Year 和 N_InTraFlow 组分组计算的各项指标变异系数 (CV) 结果输出到文件: CareerYearCVs_N_InTraFlow.xlsx\n",
      "输出文件路径: CareerYearCVs_N_InTraFlow.xlsx\n",
      "警告信息 (如果存在): 运行时可能会出现关于除以零的警告，已在代码中处理。\n",
      "请检查输出的 Excel 文件，名为： CareerYearCVs_N_InTraFlow.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 60]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要计算均值的列名 (现在包括 'N_InTraFlow' 以及其他指标)\n",
    "columns_to_mean = [\n",
    "    'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Patent_Count', 'Fund','Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'N_InTraFlow'\n",
    "]\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN\n",
    "for col in columns_to_mean:\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 计算 N_InTraFlow 的总体平均值 (与之前的代码相同)\n",
    "overall_mean_n_intraflow = df['N_InTraFlow'].mean()\n",
    "\n",
    "# 步骤 4: 基于总体平均值划分 N_InTraFlow 高低组 (与之前的代码相同)\n",
    "df['N_InTraFlow_Group'] = np.where(df['N_InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 5: 定义计算变异系数 (CV) 的函数 (如果之前没有定义过)\n",
    "def coefficient_of_variation(series):\n",
    "    \"\"\"计算变异系数 (Coefficient of Variation, CV)，处理均值为 0 的情况\"\"\"\n",
    "    mean_val = series.mean()\n",
    "    if mean_val == 0:\n",
    "        return np.nan  # 或者你可以返回 0，或者其他你认为合适的表示\n",
    "                      # NaN (Not a Number) 通常更合适，因为它表示 CV 未定义\n",
    "    else:\n",
    "        return series.std() / mean_val\n",
    "\n",
    "# 步骤 6: 按照 Career Year 和 N_InTraFlow_Group 分组，并计算各项指标的变异系数 (CV)\n",
    "cv_career_year_n_group = df.groupby(['Career Year', 'N_InTraFlow_Group'])[columns_to_mean].agg(coefficient_of_variation).reset_index()\n",
    "\n",
    "# 步骤 7:  数据透视，将 'N_InTraFlow_Group' 的 'Low_N_Avg' 和 'High_N_Avg' 变为列\n",
    "pivot_cv_df = cv_career_year_n_group.pivot(index='Career Year', columns='N_InTraFlow_Group', values=columns_to_mean)\n",
    "\n",
    "# 步骤 8: 展平多级列索引，并重命名列名\n",
    "pivot_cv_df.columns = [f'{col}_CV_{group}' for group, col in pivot_cv_df.columns]\n",
    "pivot_cv_df = pivot_cv_df.reset_index() # 将 Career Year 变回列\n",
    "\n",
    "# 步骤 9: 输出到 Excel 文件\n",
    "output_excel_file = 'CareerYearCVs_N_InTraFlow.xlsx' # 修改文件名，更详细\n",
    "pivot_cv_df.to_excel(output_excel_file, sheet_name='CV_by_CareerYear_NGroup', index=False) # 修改 sheet 名\n",
    "\n",
    "print(f\"已将按 Career Year 和 N_InTraFlow 组分组计算的各项指标变异系数 (CV) 结果输出到文件: {output_excel_file}\")\n",
    "print(f\"输出文件路径: {output_excel_file}\") # 添加输出文件路径的中文输出\n",
    "print(\"警告信息 (如果存在): 运行时可能会出现关于除以零的警告，已在代码中处理。\") # 添加警告信息说明 (中文)\n",
    "print(\"请检查输出的 Excel 文件，名为：\", output_excel_file) #  更友好的提示，并使用中文文件名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "高 N_InTraFlow 组 (High_N_Avg) Atyp_Median_Z 平均值最高的 Career Year:\n",
      "  Career Year: 62.0\n",
      "  最高平均值: 375.8459\n",
      "--------------------------------------------------\n",
      "低 N_InTraFlow 组 (Low_N_Avg) Atyp_Median_Z 平均值最高的 Career Year:\n",
      "  Career Year: 76.0\n",
      "  最高平均值: 341.8383\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要分析的列名，这里只关注 'Atyp_Median_Z'\n",
    "columns_to_analyze = ['Atyp_Median_Z']\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN\n",
    "for col in columns_to_analyze:\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 计算 N_InTraFlow 的总体平均值 (与之前的代码相同)\n",
    "overall_mean_n_intraflow = df['N_InTraFlow'].mean()\n",
    "\n",
    "# 步骤 4: 基于总体平均值划分 N_InTraFlow 高低组 (与之前的代码相同)\n",
    "df['N_InTraFlow_Group'] = np.where(df['N_InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 5: 按照 Career Year 和 N_InTraFlow_Group 分组，计算 'Atyp_Median_Z' 的平均值\n",
    "mean_atyp_median_z_by_group_year = df.groupby(['Career Year', 'N_InTraFlow_Group'])[columns_to_analyze].mean().reset_index()\n",
    "\n",
    "# 步骤 6: 分别找到高低组中 'Atyp_Median_Z' 平均值最高的 Career Year\n",
    "max_atyp_year_high_n = mean_atyp_median_z_by_group_year[mean_atyp_median_z_by_group_year['N_InTraFlow_Group'] == 'High_N_Avg'].sort_values(\n",
    "    by='Atyp_Median_Z', ascending=False\n",
    ").iloc[0]\n",
    "\n",
    "max_atyp_year_low_n = mean_atyp_median_z_by_group_year[mean_atyp_median_z_by_group_year['N_InTraFlow_Group'] == 'Low_N_Avg'].sort_values(\n",
    "    by='Atyp_Median_Z', ascending=False\n",
    ").iloc[0]\n",
    "\n",
    "# 步骤 7: 提取结果 Career Year 和 最大平均值\n",
    "career_year_high_n = max_atyp_year_high_n['Career Year']\n",
    "max_atyp_value_high_n = max_atyp_year_high_n['Atyp_Median_Z']\n",
    "\n",
    "career_year_low_n = max_atyp_year_low_n['Career Year']\n",
    "max_atyp_value_low_n = max_atyp_year_low_n['Atyp_Median_Z']\n",
    "\n",
    "# 步骤 8: 输出结果\n",
    "print(\"=\" * 50)\n",
    "print(\"高 N_InTraFlow 组 (High_N_Avg) Atyp_Median_Z 平均值最高的 Career Year:\")\n",
    "print(f\"  Career Year: {career_year_high_n}\")\n",
    "print(f\"  最高平均值: {max_atyp_value_high_n:.4f}\") # 格式化输出，保留4位小数\n",
    "\n",
    "print(\"-\" * 50) # 分隔线\n",
    "\n",
    "print(\"低 N_InTraFlow 组 (Low_N_Avg) Atyp_Median_Z 平均值最高的 Career Year:\")\n",
    "print(f\"  Career Year: {career_year_low_n}\")\n",
    "print(f\"  最高平均值: {max_atyp_value_low_n:.4f}\") # 格式化输出，保留4位小数\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "不同 N_InTraFlow 组在不同 Career Year 的平均论文数量 (Citation_Count)\n",
      "============================================================\n",
      "\n",
      "N_InTraFlow 组: High_N_Avg\n",
      "  Career Year 1: 平均论文数量 (Citation_Count): 12.79\n",
      "  Career Year 2: 平均论文数量 (Citation_Count): 17.43\n",
      "  Career Year 3: 平均论文数量 (Citation_Count): 20.13\n",
      "  Career Year 4: 平均论文数量 (Citation_Count): 22.15\n",
      "  Career Year 5: 平均论文数量 (Citation_Count): 23.93\n",
      "  Career Year 6: 平均论文数量 (Citation_Count): 24.82\n",
      "  Career Year 7: 平均论文数量 (Citation_Count): 25.80\n",
      "  Career Year 8: 平均论文数量 (Citation_Count): 26.11\n",
      "  Career Year 9: 平均论文数量 (Citation_Count): 27.57\n",
      "  Career Year 10: 平均论文数量 (Citation_Count): 28.08\n",
      "  Career Year 11: 平均论文数量 (Citation_Count): 27.86\n",
      "  Career Year 12: 平均论文数量 (Citation_Count): 28.46\n",
      "  Career Year 13: 平均论文数量 (Citation_Count): 28.69\n",
      "  Career Year 14: 平均论文数量 (Citation_Count): 29.98\n",
      "  Career Year 15: 平均论文数量 (Citation_Count): 29.61\n",
      "  Career Year 16: 平均论文数量 (Citation_Count): 31.76\n",
      "  Career Year 17: 平均论文数量 (Citation_Count): 33.41\n",
      "  Career Year 18: 平均论文数量 (Citation_Count): 33.97\n",
      "  Career Year 19: 平均论文数量 (Citation_Count): 32.54\n",
      "  Career Year 20: 平均论文数量 (Citation_Count): 33.21\n",
      "  Career Year 21: 平均论文数量 (Citation_Count): 34.06\n",
      "  Career Year 22: 平均论文数量 (Citation_Count): 35.94\n",
      "  Career Year 23: 平均论文数量 (Citation_Count): 36.89\n",
      "  Career Year 24: 平均论文数量 (Citation_Count): 35.80\n",
      "  Career Year 25: 平均论文数量 (Citation_Count): 36.02\n",
      "  Career Year 26: 平均论文数量 (Citation_Count): 34.16\n",
      "  Career Year 27: 平均论文数量 (Citation_Count): 37.21\n",
      "  Career Year 28: 平均论文数量 (Citation_Count): 34.39\n",
      "  Career Year 29: 平均论文数量 (Citation_Count): 35.67\n",
      "  Career Year 30: 平均论文数量 (Citation_Count): 39.95\n",
      "  Career Year 31: 平均论文数量 (Citation_Count): 32.90\n",
      "  Career Year 32: 平均论文数量 (Citation_Count): 38.68\n",
      "  Career Year 33: 平均论文数量 (Citation_Count): 36.44\n",
      "  Career Year 34: 平均论文数量 (Citation_Count): 39.39\n",
      "  Career Year 35: 平均论文数量 (Citation_Count): 41.03\n",
      "  Career Year 36: 平均论文数量 (Citation_Count): 39.50\n",
      "  Career Year 37: 平均论文数量 (Citation_Count): 36.96\n",
      "  Career Year 38: 平均论文数量 (Citation_Count): 37.91\n",
      "  Career Year 39: 平均论文数量 (Citation_Count): 33.79\n",
      "  Career Year 40: 平均论文数量 (Citation_Count): 33.79\n",
      "  Career Year 41: 平均论文数量 (Citation_Count): 32.55\n",
      "  Career Year 42: 平均论文数量 (Citation_Count): 32.01\n",
      "  Career Year 43: 平均论文数量 (Citation_Count): 36.05\n",
      "  Career Year 44: 平均论文数量 (Citation_Count): 28.58\n",
      "  Career Year 45: 平均论文数量 (Citation_Count): 30.11\n",
      "  Career Year 46: 平均论文数量 (Citation_Count): 30.30\n",
      "  Career Year 47: 平均论文数量 (Citation_Count): 48.19\n",
      "  Career Year 48: 平均论文数量 (Citation_Count): 32.72\n",
      "  Career Year 49: 平均论文数量 (Citation_Count): 40.27\n",
      "  Career Year 50: 平均论文数量 (Citation_Count): 33.57\n",
      "  Career Year 51: 平均论文数量 (Citation_Count): 31.66\n",
      "  Career Year 52: 平均论文数量 (Citation_Count): 29.19\n",
      "  Career Year 53: 平均论文数量 (Citation_Count): 44.78\n",
      "  Career Year 54: 平均论文数量 (Citation_Count): 27.89\n",
      "  Career Year 55: 平均论文数量 (Citation_Count): 58.81\n",
      "  Career Year 56: 平均论文数量 (Citation_Count): 58.40\n",
      "  Career Year 57: 平均论文数量 (Citation_Count): 35.71\n",
      "  Career Year 58: 平均论文数量 (Citation_Count): 55.07\n",
      "  Career Year 59: 平均论文数量 (Citation_Count): 43.31\n",
      "  Career Year 60: 平均论文数量 (Citation_Count): 44.25\n",
      "  Career Year 61: 平均论文数量 (Citation_Count): 128.22\n",
      "  Career Year 62: 平均论文数量 (Citation_Count): 62.23\n",
      "  Career Year 63: 平均论文数量 (Citation_Count): 38.41\n",
      "  Career Year 64: 平均论文数量 (Citation_Count): 41.44\n",
      "  Career Year 65: 平均论文数量 (Citation_Count): 48.29\n",
      "  Career Year 66: 平均论文数量 (Citation_Count): 61.02\n",
      "  Career Year 67: 平均论文数量 (Citation_Count): 32.25\n",
      "  Career Year 68: 平均论文数量 (Citation_Count): 28.43\n",
      "  Career Year 69: 平均论文数量 (Citation_Count): 19.53\n",
      "  Career Year 70: 平均论文数量 (Citation_Count): 58.75\n",
      "  Career Year 71: 平均论文数量 (Citation_Count): 95.40\n",
      "  Career Year 72: 平均论文数量 (Citation_Count): 156.85\n",
      "  Career Year 73: 平均论文数量 (Citation_Count): 20.47\n",
      "  Career Year 74: 平均论文数量 (Citation_Count): 153.39\n",
      "  Career Year 75: 平均论文数量 (Citation_Count): 38.35\n",
      "  Career Year 76: 平均论文数量 (Citation_Count): 44.44\n",
      "  Career Year 77: 平均论文数量 (Citation_Count): 39.75\n",
      "  Career Year 78: 平均论文数量 (Citation_Count): 43.44\n",
      "  Career Year 79: 平均论文数量 (Citation_Count): 98.42\n",
      "  Career Year 80: 平均论文数量 (Citation_Count): 37.57\n",
      "\n",
      "N_InTraFlow 组: Low_N_Avg\n",
      "  Career Year 1: 平均论文数量 (Citation_Count): 6.55\n",
      "  Career Year 2: 平均论文数量 (Citation_Count): 11.86\n",
      "  Career Year 3: 平均论文数量 (Citation_Count): 13.96\n",
      "  Career Year 4: 平均论文数量 (Citation_Count): 15.90\n",
      "  Career Year 5: 平均论文数量 (Citation_Count): 16.20\n",
      "  Career Year 6: 平均论文数量 (Citation_Count): 17.25\n",
      "  Career Year 7: 平均论文数量 (Citation_Count): 17.44\n",
      "  Career Year 8: 平均论文数量 (Citation_Count): 17.77\n",
      "  Career Year 9: 平均论文数量 (Citation_Count): 17.35\n",
      "  Career Year 10: 平均论文数量 (Citation_Count): 17.40\n",
      "  Career Year 11: 平均论文数量 (Citation_Count): 17.78\n",
      "  Career Year 12: 平均论文数量 (Citation_Count): 17.30\n",
      "  Career Year 13: 平均论文数量 (Citation_Count): 18.62\n",
      "  Career Year 14: 平均论文数量 (Citation_Count): 18.32\n",
      "  Career Year 15: 平均论文数量 (Citation_Count): 18.88\n",
      "  Career Year 16: 平均论文数量 (Citation_Count): 19.03\n",
      "  Career Year 17: 平均论文数量 (Citation_Count): 19.26\n",
      "  Career Year 18: 平均论文数量 (Citation_Count): 19.36\n",
      "  Career Year 19: 平均论文数量 (Citation_Count): 19.84\n",
      "  Career Year 20: 平均论文数量 (Citation_Count): 18.21\n",
      "  Career Year 21: 平均论文数量 (Citation_Count): 19.57\n",
      "  Career Year 22: 平均论文数量 (Citation_Count): 18.91\n",
      "  Career Year 23: 平均论文数量 (Citation_Count): 19.30\n",
      "  Career Year 24: 平均论文数量 (Citation_Count): 21.39\n",
      "  Career Year 25: 平均论文数量 (Citation_Count): 19.03\n",
      "  Career Year 26: 平均论文数量 (Citation_Count): 19.83\n",
      "  Career Year 27: 平均论文数量 (Citation_Count): 21.01\n",
      "  Career Year 28: 平均论文数量 (Citation_Count): 18.80\n",
      "  Career Year 29: 平均论文数量 (Citation_Count): 18.17\n",
      "  Career Year 30: 平均论文数量 (Citation_Count): 22.49\n",
      "  Career Year 31: 平均论文数量 (Citation_Count): 19.25\n",
      "  Career Year 32: 平均论文数量 (Citation_Count): 18.83\n",
      "  Career Year 33: 平均论文数量 (Citation_Count): 19.31\n",
      "  Career Year 34: 平均论文数量 (Citation_Count): 19.22\n",
      "  Career Year 35: 平均论文数量 (Citation_Count): 21.70\n",
      "  Career Year 36: 平均论文数量 (Citation_Count): 20.98\n",
      "  Career Year 37: 平均论文数量 (Citation_Count): 21.77\n",
      "  Career Year 38: 平均论文数量 (Citation_Count): 16.70\n",
      "  Career Year 39: 平均论文数量 (Citation_Count): 17.09\n",
      "  Career Year 40: 平均论文数量 (Citation_Count): 20.64\n",
      "  Career Year 41: 平均论文数量 (Citation_Count): 15.74\n",
      "  Career Year 42: 平均论文数量 (Citation_Count): 16.62\n",
      "  Career Year 43: 平均论文数量 (Citation_Count): 12.69\n",
      "  Career Year 44: 平均论文数量 (Citation_Count): 18.22\n",
      "  Career Year 45: 平均论文数量 (Citation_Count): 13.95\n",
      "  Career Year 46: 平均论文数量 (Citation_Count): 12.82\n",
      "  Career Year 47: 平均论文数量 (Citation_Count): 17.59\n",
      "  Career Year 48: 平均论文数量 (Citation_Count): 20.09\n",
      "  Career Year 49: 平均论文数量 (Citation_Count): 13.33\n",
      "  Career Year 50: 平均论文数量 (Citation_Count): 26.85\n",
      "  Career Year 51: 平均论文数量 (Citation_Count): 9.82\n",
      "  Career Year 52: 平均论文数量 (Citation_Count): 16.15\n",
      "  Career Year 53: 平均论文数量 (Citation_Count): 15.33\n",
      "  Career Year 54: 平均论文数量 (Citation_Count): 18.28\n",
      "  Career Year 55: 平均论文数量 (Citation_Count): 22.42\n",
      "  Career Year 56: 平均论文数量 (Citation_Count): 14.63\n",
      "  Career Year 57: 平均论文数量 (Citation_Count): 19.12\n",
      "  Career Year 58: 平均论文数量 (Citation_Count): 28.03\n",
      "  Career Year 59: 平均论文数量 (Citation_Count): 18.31\n",
      "  Career Year 60: 平均论文数量 (Citation_Count): 30.04\n",
      "  Career Year 61: 平均论文数量 (Citation_Count): 32.11\n",
      "  Career Year 62: 平均论文数量 (Citation_Count): 42.74\n",
      "  Career Year 63: 平均论文数量 (Citation_Count): 69.02\n",
      "  Career Year 64: 平均论文数量 (Citation_Count): 28.62\n",
      "  Career Year 65: 平均论文数量 (Citation_Count): 49.55\n",
      "  Career Year 66: 平均论文数量 (Citation_Count): 17.92\n",
      "  Career Year 67: 平均论文数量 (Citation_Count): 42.74\n",
      "  Career Year 68: 平均论文数量 (Citation_Count): 46.97\n",
      "  Career Year 69: 平均论文数量 (Citation_Count): 27.24\n",
      "  Career Year 70: 平均论文数量 (Citation_Count): 34.19\n",
      "  Career Year 71: 平均论文数量 (Citation_Count): 23.64\n",
      "  Career Year 72: 平均论文数量 (Citation_Count): 53.34\n",
      "  Career Year 73: 平均论文数量 (Citation_Count): 43.24\n",
      "  Career Year 74: 平均论文数量 (Citation_Count): 53.17\n",
      "  Career Year 75: 平均论文数量 (Citation_Count): 30.19\n",
      "  Career Year 76: 平均论文数量 (Citation_Count): 18.93\n",
      "  Career Year 77: 平均论文数量 (Citation_Count): 35.69\n",
      "  Career Year 78: 平均论文数量 (Citation_Count): 120.01\n",
      "  Career Year 79: 平均论文数量 (Citation_Count): 209.46\n",
      "  Career Year 80: 平均论文数量 (Citation_Count): 45.03\n",
      "============================================================\n",
      "\n",
      "结果已输出到 Excel 文件: CareerYear_Grouped_Mean_CitationCount_by_NGroup.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要分析的列名，这里关注 'Citation_Count' (作为论文数量的代表)\n",
    "columns_to_analyze = ['Citation_Count']\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN\n",
    "for col in columns_to_analyze:\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 计算 N_InTraFlow 的总体平均值 (与之前的代码相同)\n",
    "overall_mean_n_intraflow = df['N_InTraFlow'].mean()\n",
    "\n",
    "# 步骤 4: 基于总体平均值划分 N_InTraFlow 高低组 (与之前的代码相同)\n",
    "df['N_InTraFlow_Group'] = np.where(df['N_InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 5: 按照 Career Year 和 N_InTraFlow_Group 分组，计算 'Citation_Count' 的平均值\n",
    "mean_citation_count_by_group_year = df.groupby(['Career Year', 'N_InTraFlow_Group'])[columns_to_analyze].mean().reset_index()\n",
    "\n",
    "# 步骤 6: 输出结果到控制台 (表格形式)\n",
    "print(\"=\" * 60)\n",
    "print(\"不同 N_InTraFlow 组在不同 Career Year 的平均论文数量 (Citation_Count)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for group in ['High_N_Avg', 'Low_N_Avg']:\n",
    "    print(f\"\\nN_InTraFlow 组: {group}\")\n",
    "    group_data = mean_citation_count_by_group_year[mean_citation_count_by_group_year['N_InTraFlow_Group'] == group]\n",
    "    for index, row in group_data.iterrows():\n",
    "        career_year = int(row['Career Year']) # 转换为整数，使输出更整洁\n",
    "        avg_citation_count = row['Citation_Count']\n",
    "        print(f\"  Career Year {career_year}: 平均论文数量 (Citation_Count): {avg_citation_count:.2f}\") # 格式化输出\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 步骤 7:  (可选) 输出结果到 Excel 文件\n",
    "output_excel_file = 'CareerYear_Grouped_Mean_CitationCount_by_NGroup.xlsx'\n",
    "mean_citation_count_by_group_year.to_excel(output_excel_file, sheet_name='Mean_CitationCount', index=False)\n",
    "print(f\"\\n结果已输出到 Excel 文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "不同 N_InTraFlow 组在不同 Career Year 的论文数量 (数据条数)\n",
      "============================================================\n",
      "\n",
      "N_InTraFlow 组: High_N_Avg\n",
      "  Career Year 1: 论文数量 (数据条数): 1735903\n",
      "  Career Year 2: 论文数量 (数据条数): 262044\n",
      "  Career Year 3: 论文数量 (数据条数): 232990\n",
      "  Career Year 4: 论文数量 (数据条数): 194449\n",
      "  Career Year 5: 论文数量 (数据条数): 165345\n",
      "  Career Year 6: 论文数量 (数据条数): 141549\n",
      "  Career Year 7: 论文数量 (数据条数): 123242\n",
      "  Career Year 8: 论文数量 (数据条数): 107152\n",
      "  Career Year 9: 论文数量 (数据条数): 93934\n",
      "  Career Year 10: 论文数量 (数据条数): 83285\n",
      "  Career Year 11: 论文数量 (数据条数): 73834\n",
      "  Career Year 12: 论文数量 (数据条数): 65570\n",
      "  Career Year 13: 论文数量 (数据条数): 59002\n",
      "  Career Year 14: 论文数量 (数据条数): 53008\n",
      "  Career Year 15: 论文数量 (数据条数): 48193\n",
      "  Career Year 16: 论文数量 (数据条数): 43002\n",
      "  Career Year 17: 论文数量 (数据条数): 39517\n",
      "  Career Year 18: 论文数量 (数据条数): 36187\n",
      "  Career Year 19: 论文数量 (数据条数): 32974\n",
      "  Career Year 20: 论文数量 (数据条数): 30378\n",
      "  Career Year 21: 论文数量 (数据条数): 27966\n",
      "  Career Year 22: 论文数量 (数据条数): 25803\n",
      "  Career Year 23: 论文数量 (数据条数): 23403\n",
      "  Career Year 24: 论文数量 (数据条数): 21525\n",
      "  Career Year 25: 论文数量 (数据条数): 19900\n",
      "  Career Year 26: 论文数量 (数据条数): 18027\n",
      "  Career Year 27: 论文数量 (数据条数): 16478\n",
      "  Career Year 28: 论文数量 (数据条数): 15104\n",
      "  Career Year 29: 论文数量 (数据条数): 13602\n",
      "  Career Year 30: 论文数量 (数据条数): 12690\n",
      "  Career Year 31: 论文数量 (数据条数): 11827\n",
      "  Career Year 32: 论文数量 (数据条数): 10758\n",
      "  Career Year 33: 论文数量 (数据条数): 9649\n",
      "  Career Year 34: 论文数量 (数据条数): 8717\n",
      "  Career Year 35: 论文数量 (数据条数): 8024\n",
      "  Career Year 36: 论文数量 (数据条数): 7253\n",
      "  Career Year 37: 论文数量 (数据条数): 6701\n",
      "  Career Year 38: 论文数量 (数据条数): 6078\n",
      "  Career Year 39: 论文数量 (数据条数): 5561\n",
      "  Career Year 40: 论文数量 (数据条数): 4937\n",
      "  Career Year 41: 论文数量 (数据条数): 4507\n",
      "  Career Year 42: 论文数量 (数据条数): 4084\n",
      "  Career Year 43: 论文数量 (数据条数): 3645\n",
      "  Career Year 44: 论文数量 (数据条数): 3371\n",
      "  Career Year 45: 论文数量 (数据条数): 2885\n",
      "  Career Year 46: 论文数量 (数据条数): 2596\n",
      "  Career Year 47: 论文数量 (数据条数): 2321\n",
      "  Career Year 48: 论文数量 (数据条数): 1975\n",
      "  Career Year 49: 论文数量 (数据条数): 1577\n",
      "  Career Year 50: 论文数量 (数据条数): 1338\n",
      "  Career Year 51: 论文数量 (数据条数): 1169\n",
      "  Career Year 52: 论文数量 (数据条数): 1025\n",
      "  Career Year 53: 论文数量 (数据条数): 766\n",
      "  Career Year 54: 论文数量 (数据条数): 661\n",
      "  Career Year 55: 论文数量 (数据条数): 543\n",
      "  Career Year 56: 论文数量 (数据条数): 460\n",
      "  Career Year 57: 论文数量 (数据条数): 403\n",
      "  Career Year 58: 论文数量 (数据条数): 329\n",
      "  Career Year 59: 论文数量 (数据条数): 354\n",
      "  Career Year 60: 论文数量 (数据条数): 308\n",
      "\n",
      "N_InTraFlow 组: Low_N_Avg\n",
      "  Career Year 1: 论文数量 (数据条数): 3640430\n",
      "  Career Year 2: 论文数量 (数据条数): 605288\n",
      "  Career Year 3: 论文数量 (数据条数): 517639\n",
      "  Career Year 4: 论文数量 (数据条数): 415947\n",
      "  Career Year 5: 论文数量 (数据条数): 344833\n",
      "  Career Year 6: 论文数量 (数据条数): 285220\n",
      "  Career Year 7: 论文数量 (数据条数): 241189\n",
      "  Career Year 8: 论文数量 (数据条数): 204281\n",
      "  Career Year 9: 论文数量 (数据条数): 174888\n",
      "  Career Year 10: 论文数量 (数据条数): 151460\n",
      "  Career Year 11: 论文数量 (数据条数): 132050\n",
      "  Career Year 12: 论文数量 (数据条数): 114589\n",
      "  Career Year 13: 论文数量 (数据条数): 100912\n",
      "  Career Year 14: 论文数量 (数据条数): 88077\n",
      "  Career Year 15: 论文数量 (数据条数): 78033\n",
      "  Career Year 16: 论文数量 (数据条数): 70106\n",
      "  Career Year 17: 论文数量 (数据条数): 61657\n",
      "  Career Year 18: 论文数量 (数据条数): 55803\n",
      "  Career Year 19: 论文数量 (数据条数): 50254\n",
      "  Career Year 20: 论文数量 (数据条数): 45533\n",
      "  Career Year 21: 论文数量 (数据条数): 41237\n",
      "  Career Year 22: 论文数量 (数据条数): 36923\n",
      "  Career Year 23: 论文数量 (数据条数): 33870\n",
      "  Career Year 24: 论文数量 (数据条数): 31023\n",
      "  Career Year 25: 论文数量 (数据条数): 27938\n",
      "  Career Year 26: 论文数量 (数据条数): 25410\n",
      "  Career Year 27: 论文数量 (数据条数): 23491\n",
      "  Career Year 28: 论文数量 (数据条数): 21103\n",
      "  Career Year 29: 论文数量 (数据条数): 19399\n",
      "  Career Year 30: 论文数量 (数据条数): 17246\n",
      "  Career Year 31: 论文数量 (数据条数): 15793\n",
      "  Career Year 32: 论文数量 (数据条数): 14017\n",
      "  Career Year 33: 论文数量 (数据条数): 12353\n",
      "  Career Year 34: 论文数量 (数据条数): 11335\n",
      "  Career Year 35: 论文数量 (数据条数): 9943\n",
      "  Career Year 36: 论文数量 (数据条数): 9142\n",
      "  Career Year 37: 论文数量 (数据条数): 8208\n",
      "  Career Year 38: 论文数量 (数据条数): 7324\n",
      "  Career Year 39: 论文数量 (数据条数): 6707\n",
      "  Career Year 40: 论文数量 (数据条数): 5905\n",
      "  Career Year 41: 论文数量 (数据条数): 5453\n",
      "  Career Year 42: 论文数量 (数据条数): 4952\n",
      "  Career Year 43: 论文数量 (数据条数): 4357\n",
      "  Career Year 44: 论文数量 (数据条数): 3929\n",
      "  Career Year 45: 论文数量 (数据条数): 3407\n",
      "  Career Year 46: 论文数量 (数据条数): 3076\n",
      "  Career Year 47: 论文数量 (数据条数): 2707\n",
      "  Career Year 48: 论文数量 (数据条数): 2377\n",
      "  Career Year 49: 论文数量 (数据条数): 2167\n",
      "  Career Year 50: 论文数量 (数据条数): 1888\n",
      "  Career Year 51: 论文数量 (数据条数): 1646\n",
      "  Career Year 52: 论文数量 (数据条数): 1449\n",
      "  Career Year 53: 论文数量 (数据条数): 1008\n",
      "  Career Year 54: 论文数量 (数据条数): 807\n",
      "  Career Year 55: 论文数量 (数据条数): 699\n",
      "  Career Year 56: 论文数量 (数据条数): 594\n",
      "  Career Year 57: 论文数量 (数据条数): 478\n",
      "  Career Year 58: 论文数量 (数据条数): 460\n",
      "  Career Year 59: 论文数量 (数据条数): 386\n",
      "  Career Year 60: 论文数量 (数据条数): 304\n",
      "============================================================\n",
      "\n",
      "结果已输出到 Excel 文件: CareerYear_Grouped_PaperCount_by_NGroup.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 60]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 步骤 2: 计算 N_InTraFlow 的总体平均值 (与之前的代码相同)\n",
    "overall_mean_n_intraflow = df['N_InTraFlow'].mean()\n",
    "\n",
    "# 步骤 3: 基于总体平均值划分 N_InTraFlow 高低组 (与之前的代码相同)\n",
    "df['N_InTraFlow_Group'] = np.where(df['N_InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 4: 按照 Career Year 和 N_InTraFlow_Group 分组，计算数据条数 (论文数量)\n",
    "paper_count_by_group_year = df.groupby(['Career Year', 'N_InTraFlow_Group'])['Citation_Count'].count().reset_index() # 使用 count() 而不是 mean()\n",
    "\n",
    "# 步骤 5: 输出结果到控制台 (表格形式)\n",
    "print(\"=\" * 60)\n",
    "print(\"不同 N_InTraFlow 组在不同 Career Year 的论文数量 (数据条数)\") # 修改标题\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for group in ['High_N_Avg', 'Low_N_Avg']:\n",
    "    print(f\"\\nN_InTraFlow 组: {group}\")\n",
    "    group_data = paper_count_by_group_year[paper_count_by_group_year['N_InTraFlow_Group'] == group]\n",
    "    for index, row in group_data.iterrows():\n",
    "        career_year = int(row['Career Year']) # 转换为整数，使输出更整洁\n",
    "        paper_count = row['Citation_Count'] # 列名仍然是 'Citation_Count'，但现在是计数\n",
    "        print(f\"  Career Year {career_year}: 论文数量 (数据条数): {paper_count}\") # 修改输出文字\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 步骤 6:  (可选) 输出结果到 Excel 文件\n",
    "output_excel_file = 'CareerYear_Grouped_PaperCount_by_NGroup.xlsx' # 修改文件名\n",
    "paper_count_by_group_year.to_excel(output_excel_file, sheet_name='PaperCount', index=False) # 修改 sheet 名\n",
    "print(f\"\\n结果已输出到 Excel 文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "不同 N_InTraFlow 组在不同 Career Year 的平均 Citation Count\n",
      "============================================================\n",
      "N_InTraFlow_Group  Career Year  High_N_Avg  Low_N_Avg\n",
      "0                          1.0   12.773926   6.547727\n",
      "1                          2.0   17.419605  11.863303\n",
      "2                          3.0   20.107279  13.964987\n",
      "3                          4.0   22.128337  15.901754\n",
      "4                          5.0   23.905936  16.206506\n",
      "5                          6.0   24.798494  17.257924\n",
      "6                          7.0   25.778168  17.443652\n",
      "7                          8.0   26.083844  17.780371\n",
      "8                          9.0   27.548364  17.356177\n",
      "9                         10.0   28.055688  17.402245\n",
      "10                        11.0   27.836281  17.791208\n",
      "11                        12.0   28.435336  17.309157\n",
      "12                        13.0   28.669689  18.630916\n",
      "13                        14.0   29.962515  18.330960\n",
      "14                        15.0   29.576163  18.889790\n",
      "15                        16.0   31.734524  19.040253\n",
      "16                        17.0   33.383860  19.273237\n",
      "17                        18.0   33.938569  19.371163\n",
      "18                        19.0   32.510493  19.848589\n",
      "19                        20.0   33.180394  18.224518\n",
      "20                        21.0   34.038690  19.578607\n",
      "21                        22.0   35.910088  18.919914\n",
      "22                        23.0   36.852070  19.309094\n",
      "23                        24.0   35.761208  21.410792\n",
      "24                        25.0   36.010151  19.033431\n",
      "25                        26.0   34.114218  19.851633\n",
      "26                        27.0   37.164826  21.020561\n",
      "27                        28.0   34.351695  18.808416\n",
      "28                        29.0   35.648581  18.175215\n",
      "29                        30.0   39.909693  22.501624\n",
      "30                        31.0   32.884417  19.253087\n",
      "31                        32.0   38.627626  18.846258\n",
      "32                        33.0   36.404705  19.324941\n",
      "33                        34.0   39.357921  19.229907\n",
      "34                        35.0   40.992398  21.712662\n",
      "35                        36.0   39.479939  20.988186\n",
      "36                        37.0   36.948664  21.770468\n",
      "37                        38.0   37.896018  16.708083\n",
      "38                        39.0   33.749146  17.109140\n",
      "39                        40.0   33.769496  20.644369\n",
      "40                        41.0   32.518749  15.748212\n",
      "41                        42.0   31.994613  16.620153\n",
      "42                        43.0   36.024966  12.697498\n",
      "43                        44.0   28.556215  18.231102\n",
      "44                        45.0   30.097747  13.949222\n",
      "45                        46.0   30.251541  12.834200\n",
      "46                        47.0   48.153813  17.598818\n",
      "47                        48.0   32.688101  20.109382\n",
      "48                        49.0   40.177552  13.333180\n",
      "49                        50.0   33.568759  26.848517\n",
      "50                        51.0   31.661249   9.815917\n",
      "51                        52.0   29.163902  16.146308\n",
      "52                        53.0   44.720627  15.345238\n",
      "53                        54.0   27.892587  18.276332\n",
      "54                        55.0   58.808471  22.417740\n",
      "55                        56.0   58.397826  14.631313\n",
      "56                        57.0   35.712159  19.121339\n",
      "57                        58.0   54.902736  28.086957\n",
      "58                        59.0   43.214689  18.329016\n",
      "59                        60.0   44.113636  30.134868\n",
      "============================================================\n",
      "\n",
      "结果已输出到 Excel 文件: CareerYear_Grouped_AvgCitation_by_NGroup.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 60]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 步骤 2: 计算 N_InTraFlow 的总体平均值 (与之前的代码相同)\n",
    "overall_mean_n_intraflow = df['N_InTraFlow'].mean()\n",
    "\n",
    "# 步骤 3: 基于总体平均值划分 N_InTraFlow 高低组 (与之前的代码相同)\n",
    "df['N_InTraFlow_Group'] = np.where(df['N_InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 4: 按照 Career Year 和 N_InTraFlow_Group 分组，计算 Citation_Count 的平均值\n",
    "average_citation_by_group_year = df.groupby(['Career Year', 'N_InTraFlow_Group'])['Citation_Count'].mean().reset_index()\n",
    "\n",
    "# 步骤 5: 将结果转换为横向表格 (使用 pivot_table)\n",
    "pivot_df = average_citation_by_group_year.pivot_table(index='Career Year', columns='N_InTraFlow_Group', values='Citation_Count').reset_index()\n",
    "\n",
    "# 为了美观，填充 NaN 值为 0 (如果需要)\n",
    "pivot_df = pivot_df.fillna(0)\n",
    "\n",
    "# 步骤 6: 输出结果到控制台 (表格形式)\n",
    "print(\"=\" * 60)\n",
    "print(\"不同 N_InTraFlow 组在不同 Career Year 的平均 Citation Count\")\n",
    "print(\"=\" * 60)\n",
    "print(pivot_df) # 直接打印 DataFrame\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 步骤 7: (可选) 输出结果到 Excel 文件\n",
    "output_excel_file = 'CareerYear_Grouped_AvgCitation_by_NGroup.xlsx' # 修改文件名\n",
    "pivot_df.to_excel(output_excel_file, sheet_name='AvgCitation', index=False) # 修改 sheet 名\n",
    "print(f\"\\n结果已输出到 Excel 文件: {output_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件字段数: 6\n",
      "数据行数: 135827039\n",
      "各字段空值数量:\n",
      "字段 PaperID: 0 个空值\n",
      "字段 AuthorID: 0 个空值\n",
      "字段 Year: 3 个空值\n",
      "字段 Atyp_Median_Z: 90073430 个空值\n",
      "字段 Career_Start_Year: 0 个空值\n",
      "字段 Career Year: 0 个空值\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def analyze_tsv(file_path):\n",
    "    \"\"\"\n",
    "    分析大型TSV文件，输出字段数、行数和空值数量。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV文件路径。\n",
    "    \"\"\"\n",
    "    field_count = 0\n",
    "    row_count = 0\n",
    "    null_counts = None  # 用于存储每个字段的空值计数\n",
    "    field_names = None # 用于存储字段名\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_number, line in enumerate(f, start=1):\n",
    "                line = line.strip()  # 移除行尾空白\n",
    "                if not line:  # 跳过空行\n",
    "                    continue\n",
    "\n",
    "                fields = line.split('\\t')\n",
    "\n",
    "                if line_number == 1:\n",
    "                    # 第一行作为字段名行\n",
    "                    field_count = len(fields)\n",
    "                    null_counts = [0] * field_count  # 初始化空值计数列表\n",
    "                    print(f\"文件字段数: {field_count}\")\n",
    "                    field_names = fields # 保存字段名\n",
    "                else:\n",
    "                    row_count += 1\n",
    "                    # 统计空值\n",
    "                    for i, field in enumerate(fields):\n",
    "                        if i < field_count and not field:  # 检查是否为空值 (针对空字符串)\n",
    "                            null_counts[i] += 1\n",
    "\n",
    "        print(f\"数据行数: {row_count}\")\n",
    "        print(\"各字段空值数量:\")\n",
    "        if field_names and null_counts: # 如果有字段名，则一起输出\n",
    "            for i in range(field_count):\n",
    "                print(f\"字段 {field_names[i]}: {null_counts[i]} 个空值\")\n",
    "        else: # 否则只输出字段序号和空值数量\n",
    "            for i in range(field_count):\n",
    "                print(f\"字段 {i+1}: {null_counts[i]} 个空值\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生错误: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 直接指定文件名\n",
    "    tsv_file_path = \"SciSciNet_MergedData_CareerYear.tsv\"\n",
    "    # 注意：请确保 SciSciNet_MergedData_CareerYear.tsv 文件与该 Python 脚本在同一目录下，\n",
    "    # 或者提供文件的完整路径。\n",
    "\n",
    "    analyze_tsv(tsv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件字段数: 25\n",
      "数据行数: 11756016\n",
      "各字段空值数量:\n",
      "字段 FieldID: 0 个空值\n",
      "字段 PaperID: 0 个空值\n",
      "字段 C_f: 3 个空值\n",
      "字段 Year: 3 个空值\n",
      "字段 Citation_Count: 0 个空值\n",
      "字段 C10: 6031619 个空值\n",
      "字段 C5: 3154820 个空值\n",
      "字段 Team_size: 167 个空值\n",
      "字段 Disruption: 4741979 个空值\n",
      "字段 Atyp_Median_Z: 7856467 个空值\n",
      "字段 SB_B: 7475837 个空值\n",
      "字段 SB_T: 7475837 个空值\n",
      "字段 InTraFlowf: 5626542 个空值\n",
      "字段 InTraFlow: 0 个空值\n",
      "字段 N_InTraFlow: 44181 个空值\n",
      "字段 Patent_Count: 0 个空值\n",
      "字段 Fund: 0 个空值\n",
      "字段 Field_CS: 0 个空值\n",
      "字段 Field_Eng: 0 个空值\n",
      "字段 Field_Eco: 0 个空值\n",
      "字段 Log_Team_size: 0 个空值\n",
      "字段 Log_C5: 0 个空值\n",
      "字段 Log_Patent_Count: 0 个空值\n",
      "字段 Log_Fund: 0 个空值\n",
      "字段 Career Year: 0 个空值\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def analyze_tsv(file_path):\n",
    "    \"\"\"\n",
    "    分析大型TSV文件，输出字段数、行数和空值数量。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV文件路径。\n",
    "    \"\"\"\n",
    "    field_count = 0\n",
    "    row_count = 0\n",
    "    null_counts = None  # 用于存储每个字段的空值计数\n",
    "    field_names = None # 用于存储字段名\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_number, line in enumerate(f, start=1):\n",
    "                line = line.strip()  # 移除行尾空白\n",
    "                if not line:  # 跳过空行\n",
    "                    continue\n",
    "\n",
    "                fields = line.split('\\t')\n",
    "\n",
    "                if line_number == 1:\n",
    "                    # 第一行作为字段名行\n",
    "                    field_count = len(fields)\n",
    "                    null_counts = [0] * field_count  # 初始化空值计数列表\n",
    "                    print(f\"文件字段数: {field_count}\")\n",
    "                    field_names = fields # 保存字段名\n",
    "                else:\n",
    "                    row_count += 1\n",
    "                    # 统计空值\n",
    "                    for i, field in enumerate(fields):\n",
    "                        if i < field_count and not field:  # 检查是否为空值 (针对空字符串)\n",
    "                            null_counts[i] += 1\n",
    "\n",
    "        print(f\"数据行数: {row_count}\")\n",
    "        print(\"各字段空值数量:\")\n",
    "        if field_names and null_counts: # 如果有字段名，则一起输出\n",
    "            for i in range(field_count):\n",
    "                print(f\"字段 {field_names[i]}: {null_counts[i]} 个空值\")\n",
    "        else: # 否则只输出字段序号和空值数量\n",
    "            for i in range(field_count):\n",
    "                print(f\"字段 {i+1}: {null_counts[i]} 个空值\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生错误: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 直接指定文件名\n",
    "    tsv_file_path = \"Merged_Cleaned_InTraFlow_CareerYear.tsv\"\n",
    "    # 注意：请确保 SciSciNet_MergedData_CareerYear.tsv 文件与该 Python 脚本在同一目录下，\n",
    "    # 或者提供文件的完整路径。\n",
    "\n",
    "    analyze_tsv(tsv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "高 N_InTraFlow 组 (High_N_Avg) Atyp_Median_Z 平均值最高的前 10 个 Career Year:\n",
      "  Rank 123: Career Year: 62.0, 平均值: 375.8459\n",
      "  Rank 125: Career Year: 63.0, 平均值: 260.5829\n",
      "  Rank 139: Career Year: 70.0, 平均值: 255.4369\n",
      "  Rank 111: Career Year: 56.0, 平均值: 251.5660\n",
      "  Rank 141: Career Year: 71.0, 平均值: 228.8893\n",
      "  Rank 159: Career Year: 80.0, 平均值: 211.0743\n",
      "  Rank 1: Career Year: 1.0, 平均值: 210.9407\n",
      "  Rank 3: Career Year: 2.0, 平均值: 197.0672\n",
      "  Rank 105: Career Year: 53.0, 平均值: 192.0372\n",
      "  Rank 5: Career Year: 3.0, 平均值: 191.6492\n",
      "--------------------------------------------------\n",
      "低 N_InTraFlow 组 (Low_N_Avg) Atyp_Median_Z 平均值最高的前 10 个 Career Year:\n",
      "  Rank 152: Career Year: 76.0, 平均值: 341.8383\n",
      "  Rank 160: Career Year: 80.0, 平均值: 265.8446\n",
      "  Rank 100: Career Year: 50.0, 平均值: 219.5578\n",
      "  Rank 2: Career Year: 1.0, 平均值: 214.5946\n",
      "  Rank 72: Career Year: 36.0, 平均值: 214.4926\n",
      "  Rank 132: Career Year: 66.0, 平均值: 212.9746\n",
      "  Rank 90: Career Year: 45.0, 平均值: 211.9668\n",
      "  Rank 64: Career Year: 32.0, 平均值: 209.8641\n",
      "  Rank 58: Career Year: 29.0, 平均值: 202.0224\n",
      "  Rank 70: Career Year: 35.0, 平均值: 200.0517\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 80 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 80]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 定义需要分析的列名，这里只关注 'Atyp_Median_Z'\n",
    "columns_to_analyze = ['Atyp_Median_Z']\n",
    "\n",
    "# 步骤 2: 处理 inf 值，将 inf 替换为 NaN\n",
    "for col in columns_to_analyze:\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 步骤 3: 计算 N_InTraFlow 的总体平均值 (与之前的代码相同)\n",
    "overall_mean_n_intraflow = df['N_InTraFlow'].mean()\n",
    "\n",
    "# 步骤 4: 基于总体平均值划分 N_InTraFlow 高低组 (与之前的代码相同)\n",
    "df['N_InTraFlow_Group'] = np.where(df['N_InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 5: 按照 Career Year 和 N_InTraFlow_Group 分组，计算 'Atyp_Median_Z' 的平均值\n",
    "mean_atyp_median_z_by_group_year = df.groupby(['Career Year', 'N_InTraFlow_Group'])[columns_to_analyze].mean().reset_index()\n",
    "\n",
    "# 步骤 6: 分别找到高低组中 'Atyp_Median_Z' 平均值最高的前十个 Career Year\n",
    "top_n = 10 # 定义要获取的前N个 Career Year\n",
    "\n",
    "max_atyp_year_high_n_top10 = mean_atyp_median_z_by_group_year[mean_atyp_median_z_by_group_year['N_InTraFlow_Group'] == 'High_N_Avg'].sort_values(\n",
    "    by='Atyp_Median_Z', ascending=False\n",
    ").head(top_n) # 使用 head(top_n) 获取前N行\n",
    "\n",
    "max_atyp_year_low_n_top10 = mean_atyp_median_z_by_group_year[mean_atyp_median_z_by_group_year['N_InTraFlow_Group'] == 'Low_N_Avg'].sort_values(\n",
    "    by='Atyp_Median_Z', ascending=False\n",
    ").head(top_n) # 使用 head(top_n) 获取前N行\n",
    "\n",
    "# 步骤 7 & 8: 提取结果并输出 - 遍历 top 10 结果\n",
    "print(\"=\" * 50)\n",
    "print(f\"高 N_InTraFlow 组 (High_N_Avg) Atyp_Median_Z 平均值最高的前 {top_n} 个 Career Year:\")\n",
    "for index, row in max_atyp_year_high_n_top10.iterrows():\n",
    "    career_year_high_n = row['Career Year']\n",
    "    max_atyp_value_high_n = row['Atyp_Median_Z']\n",
    "    print(f\"  Rank {index+1}: Career Year: {career_year_high_n}, 平均值: {max_atyp_value_high_n:.4f}\") # 格式化输出，保留4位小数\n",
    "\n",
    "print(\"-\" * 50) # 分隔线\n",
    "\n",
    "print(f\"低 N_InTraFlow 组 (Low_N_Avg) Atyp_Median_Z 平均值最高的前 {top_n} 个 Career Year:\")\n",
    "for index, row in max_atyp_year_low_n_top10.iterrows():\n",
    "    career_year_low_n = row['Career Year']\n",
    "    max_atyp_value_low_n = row['Atyp_Median_Z']\n",
    "    print(f\"  Rank {index+1}: Career Year: {career_year_low_n}, 平均值: {max_atyp_value_low_n:.4f}\") # 格式化输出，保留4位小数\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已计算并输出论文数量 (基于 PaperID 计数，按 Career Year) 的变异系数 (CV) 到文件: CV_PublicationCounts_PaperID_AcrossCareerYears.xlsx\n",
      "输出文件路径: CV_PublicationCounts_PaperID_AcrossCareerYears.xlsx\n",
      "警告信息 (如果存在): 运行时可能会出现关于除以零的警告，已在代码中处理。\n",
      "请检查输出的 Excel 文件，名为： CV_PublicationCounts_PaperID_AcrossCareerYears.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 60 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 60]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 步骤 2:  使用 PaperID 列的数量作为每年发表论文数量的代表\n",
    "publication_count_column = 'PaperID' #  使用 'PaperID' 列\n",
    "\n",
    "# 步骤 3: 按照 Career Year 分组，计算每个 Career Year 的 PaperID 数量 (即论文数量)\n",
    "paper_counts_by_career_year = df.groupby('Career Year')[publication_count_column].count()\n",
    "\n",
    "# 步骤 4: 定义计算变异系数 (CV) 的函数\n",
    "def coefficient_of_variation(series):\n",
    "    \"\"\"计算变异系数 (Coefficient of Variation, CV)，处理均值为 0 的情况\"\"\"\n",
    "    mean_val = series.mean()\n",
    "    if mean_val == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return series.std() / mean_val\n",
    "\n",
    "# 步骤 5: 计算论文数量序列 (按 Career Year) 的变异系数 (CV)\n",
    "cv_publication_counts = coefficient_of_variation(paper_counts_by_career_year)\n",
    "\n",
    "# 步骤 6: 创建 DataFrame 存储结果 (可选，但为了方便输出到 Excel)\n",
    "cv_result_df = pd.DataFrame({\n",
    "    'Metric': ['CV of Publication Counts (PaperID) across Career Years'],\n",
    "    'Value': [cv_publication_counts]\n",
    "})\n",
    "\n",
    "# 步骤 7: 输出到 Excel 文件\n",
    "output_excel_file = 'CV_PublicationCounts_PaperID_AcrossCareerYears.xlsx' # 修改文件名，更明确\n",
    "cv_result_df.to_excel(output_excel_file, sheet_name='CV_PublicationCounts_PaperID', index=False) # 修改 sheet 名\n",
    "\n",
    "print(f\"已计算并输出论文数量 (基于 PaperID 计数，按 Career Year) 的变异系数 (CV) 到文件: {output_excel_file}\")\n",
    "print(f\"输出文件路径: {output_excel_file}\")\n",
    "print(\"警告信息 (如果存在): 运行时可能会出现关于除以零的警告，已在代码中处理。\")\n",
    "print(\"请检查输出的 Excel 文件，名为：\", output_excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已分别为 N_InTraFlow 高低组计算并输出论文数量 (基于 PaperID 计数，按 Career Year) 的变异系数 (CV) 到文件: CV_PublicationCounts_PaperID_by_NGroup.xlsx\n",
      "输出文件路径: CV_PublicationCounts_PaperID_by_NGroup.xlsx\n",
      "警告信息 (如果存在): 运行时可能会出现关于除以零的警告，已在代码中处理。\n",
      "请检查输出的 Excel 文件，名为： CV_PublicationCounts_PaperID_by_NGroup.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 60 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 60]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 步骤 2: 计算 N_InTraFlow 的总体平均值\n",
    "overall_mean_n_intraflow = df['N_InTraFlow'].mean()\n",
    "\n",
    "# 步骤 3: 基于总体平均值划分 N_InTraFlow 高低组\n",
    "df['N_InTraFlow_Group'] = np.where(df['N_InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 4:  指定 PaperID 列作为论文数量的代表\n",
    "publication_count_column = 'PaperID'\n",
    "\n",
    "# 步骤 5: 定义计算变异系数 (CV) 的函数\n",
    "def coefficient_of_variation(series):\n",
    "    \"\"\"计算变异系数 (Coefficient of Variation, CV)，处理均值为 0 的情况\"\"\"\n",
    "    mean_val = series.mean()\n",
    "    if mean_val == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return series.std() / mean_val\n",
    "\n",
    "# 步骤 6: 分别为 High_N_Avg 和 Low_N_Avg 组计算每个 Career Year 的论文数量，并计算 CV\n",
    "cv_publication_counts_by_group = {} # 用字典存储结果\n",
    "\n",
    "for group_name, group_df in df.groupby('N_InTraFlow_Group'):\n",
    "    # 计算每个 Career Year 的论文数量 (PaperID 计数)\n",
    "    paper_counts_by_career_year = group_df.groupby('Career Year')[publication_count_column].count()\n",
    "    # 计算论文数量序列的 CV\n",
    "    cv_publication_counts = coefficient_of_variation(paper_counts_by_career_year)\n",
    "    cv_publication_counts_by_group[group_name] = cv_publication_counts\n",
    "\n",
    "# 步骤 7: 创建 DataFrame 存储结果\n",
    "cv_result_df = pd.DataFrame({\n",
    "    'N_InTraFlow_Group': list(cv_publication_counts_by_group.keys()),\n",
    "    'CV_PublicationCounts_PaperID': list(cv_publication_counts_by_group.values())\n",
    "})\n",
    "\n",
    "# 步骤 8: 输出到 Excel 文件\n",
    "output_excel_file = 'CV_PublicationCounts_PaperID_by_NGroup.xlsx' # 修改文件名，更明确\n",
    "cv_result_df.to_excel(output_excel_file, sheet_name='CV_PublicationCounts_by_NGroup', index=False) # 修改 sheet 名\n",
    "\n",
    "print(f\"已分别为 N_InTraFlow 高低组计算并输出论文数量 (基于 PaperID 计数，按 Career Year) 的变异系数 (CV) 到文件: {output_excel_file}\")\n",
    "print(f\"输出文件路径: {output_excel_file}\")\n",
    "print(\"警告信息 (如果存在): 运行时可能会出现关于除以零的警告，已在代码中处理。\")\n",
    "print(\"请检查输出的 Excel 文件，名为：\", output_excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已按 Career Year 和 N_InTraFlow 组分组计算的论文数量 (基于 PaperID 计数) 变异系数 (CV) 结果输出到文件: CareerYear_PublicationCount_CV_by_NGroup.xlsx\n",
      "输出文件路径: CareerYear_PublicationCount_CV_by_NGroup.xlsx\n",
      "警告信息 (如果存在): 运行时可能会出现关于除以零的警告，已在代码中处理。\n",
      "请检查输出的 Excel 文件，名为： CareerYear_PublicationCount_CV_by_NGroup.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 步骤 1: 直接根据 Career Year 筛选，排除 Career Year 大于 60 的数据\n",
    "df_filtered_career_year = df[df['Career Year'] <= 60]\n",
    "df = df_filtered_career_year # 更新 DataFrame 为 Career Year 过滤后的数据\n",
    "\n",
    "# 步骤 2: 计算 N_InTraFlow 的总体平均值\n",
    "overall_mean_n_intraflow = df['N_InTraFlow'].mean()\n",
    "\n",
    "# 步骤 3: 基于总体平均值划分 N_InTraFlow 高低组\n",
    "df['N_InTraFlow_Group'] = np.where(df['N_InTraFlow'] >= overall_mean_n_intraflow, 'High_N_Avg', 'Low_N_Avg')\n",
    "\n",
    "# 步骤 4:  指定 PaperID 列作为论文数量的代表\n",
    "publication_count_column = 'PaperID'\n",
    "\n",
    "# 步骤 5: 定义计算变异系数 (CV) 的函数\n",
    "def coefficient_of_variation(series):\n",
    "    \"\"\"计算变异系数 (Coefficient of Variation, CV)，处理均值为 0 的情况\"\"\"\n",
    "    mean_val = series.mean()\n",
    "    if mean_val == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return series.std() / mean_val\n",
    "\n",
    "# 步骤 6: 按照 Career Year 和 N_InTraFlow_Group 分组，计算每个组的论文数量 CV\n",
    "cv_publication_counts_by_year_group = df.groupby(['Career Year', 'N_InTraFlow_Group'])[publication_count_column].agg(coefficient_of_variation).reset_index()\n",
    "\n",
    "# 步骤 7:  数据透视，将 'N_InTraFlow_Group' 的 'Low_N_Avg' 和 'High_N_Avg' 变为列\n",
    "pivot_cv_df = cv_publication_counts_by_year_group.pivot(index='Career Year', columns='N_InTraFlow_Group', values=publication_count_column)\n",
    "\n",
    "# 步骤 8: 展平多级列索引，并重命名列名\n",
    "pivot_cv_df.columns = [f'PublicationCount_CV_{group}' for group in pivot_cv_df.columns]\n",
    "pivot_cv_df = pivot_cv_df.reset_index() # 将 Career Year 变回列\n",
    "\n",
    "# 步骤 9: 输出到 Excel 文件\n",
    "output_excel_file = 'CareerYear_PublicationCount_CV_by_NGroup.xlsx' # 修改文件名，更明确\n",
    "pivot_cv_df.to_excel(output_excel_file, sheet_name='CV_PubCount_Year_NGroup', index=False) # 修改 sheet 名，缩短 sheet name\n",
    "\n",
    "print(f\"已按 Career Year 和 N_InTraFlow 组分组计算的论文数量 (基于 PaperID 计数) 变异系数 (CV) 结果输出到文件: {output_excel_file}\")\n",
    "print(f\"输出文件路径: {output_excel_file}\")\n",
    "print(\"警告信息 (如果存在): 运行时可能会出现关于除以零的警告，已在代码中处理。\")\n",
    "print(\"请检查输出的 Excel 文件，名为：\", output_excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件字段数: 29\n",
      "数据行数: 11910273\n",
      "各字段空值数量:\n",
      "字段 Author: 0 个空值\n",
      "字段 FieldID: 0 个空值\n",
      "字段 PaperID: 0 个空值\n",
      "字段 IMCp: 1855094 个空值\n",
      "字段 IMCft: 327 个空值\n",
      "字段 Year: 0 个空值\n",
      "字段 Citation_Count: 0 个空值\n",
      "字段 Team_size: 0 个空值\n",
      "字段 Disruption: 1837707 个空值\n",
      "字段 Atyp_Median_Z: 0 个空值\n",
      "字段 SB_B: 2350821 个空值\n",
      "字段 SB_T: 2350821 个空值\n",
      "字段 CIMC: 1855277 个空值\n",
      "字段 Crisis Year: 0 个空值\n",
      "字段 Reference_Count: 0 个空值\n",
      "字段 NIH_Count: 0 个空值\n",
      "字段 NSF_Count: 0 个空值\n",
      "字段 IMC: 0 个空值\n",
      "字段 C_n: 0 个空值\n",
      "字段 NIMC: 0 个空值\n",
      "字段 Patent_Count: 0 个空值\n",
      "字段 Funding: 0 个空值\n",
      "字段 Field_CS: 0 个空值\n",
      "字段 Field_Eng: 0 个空值\n",
      "字段 Field_Eco: 0 个空值\n",
      "字段 Crisis: 0 个空值\n",
      "字段 Patent_ln: 0 个空值\n",
      "字段 TS_ln: 0 个空值\n",
      "字段 imputed: 0 个空值\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def analyze_tsv(file_path):\n",
    "    \"\"\"\n",
    "    分析大型TSV文件，输出字段数、行数和空值数量。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV文件路径。\n",
    "    \"\"\"\n",
    "    field_count = 0\n",
    "    row_count = 0\n",
    "    null_counts = None  # 用于存储每个字段的空值计数\n",
    "    field_names = None # 用于存储字段名\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_number, line in enumerate(f, start=1):\n",
    "                line = line.strip()  # 移除行尾空白\n",
    "                if not line:  # 跳过空行\n",
    "                    continue\n",
    "\n",
    "                fields = line.split('\\t')\n",
    "\n",
    "                if line_number == 1:\n",
    "                    # 第一行作为字段名行\n",
    "                    field_count = len(fields)\n",
    "                    null_counts = [0] * field_count  # 初始化空值计数列表\n",
    "                    print(f\"文件字段数: {field_count}\")\n",
    "                    field_names = fields # 保存字段名\n",
    "                else:\n",
    "                    row_count += 1\n",
    "                    # 统计空值\n",
    "                    for i, field in enumerate(fields):\n",
    "                        if i < field_count and not field:  # 检查是否为空值 (针对空字符串)\n",
    "                            null_counts[i] += 1\n",
    "\n",
    "        print(f\"数据行数: {row_count}\")\n",
    "        print(\"各字段空值数量:\")\n",
    "        if field_names and null_counts: # 如果有字段名，则一起输出\n",
    "            for i in range(field_count):\n",
    "                print(f\"字段 {field_names[i]}: {null_counts[i]} 个空值\")\n",
    "        else: # 否则只输出字段序号和空值数量\n",
    "            for i in range(field_count):\n",
    "                print(f\"字段 {i+1}: {null_counts[i]} 个空值\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生错误: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 直接指定文件名\n",
    "    tsv_file_path = \"author_crisis_year_modified.tsv\"\n",
    "    # 注意：请确保 SciSciNet_MergedData_CareerYear.tsv 文件与该 Python 脚本在同一目录下，\n",
    "    # 或者提供文件的完整路径。\n",
    "\n",
    "    analyze_tsv(tsv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged_Cleaned_InTraFlow_CareerYear.tsv 列名: ['FieldID', 'PaperID', 'C_f', 'Year', 'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'InTraFlowf', 'InTraFlow', 'N_InTraFlow', 'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng', 'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'Career Year']\n",
      "author_crisis_year_modified.tsv 列名: ['Author', 'FieldID', 'PaperID', 'IMCp', 'IMCft', 'Year', 'Citation_Count', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'CIMC', 'Crisis Year', 'Reference_Count', 'NIH_Count', 'NSF_Count', 'IMC', 'C_n', 'NIMC', 'Patent_Count', 'Funding', 'Field_CS', 'Field_Eng', 'Field_Eco', 'Crisis', 'Patent_ln', 'TS_ln', 'imputed']\n",
      "合并后的 DataFrame 列名: ['FieldID', 'PaperID', 'C_f', 'Year', 'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'InTraFlowf', 'InTraFlow', 'N_InTraFlow', 'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng', 'Field_Eco', 'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'Career Year', 'Crisis Year', 'Crisis']\n",
      "合并后的 DataFrame 前几行数据:\n",
      "       FieldID  PaperID       C_f    Year  Citation_Count  C10   C5  \\\n",
      "0  127413603.0      125  0.110697  1988.0             1.0  1.0  1.0   \n",
      "1  127413603.0      997  0.546211  2006.0             4.0  4.0  4.0   \n",
      "2  127413603.0     3393  0.107428  1993.0             1.0  1.0  1.0   \n",
      "3  127413603.0     5156  0.851101  2011.0             5.0  5.0  4.0   \n",
      "4  127413603.0     8107  0.757411  2005.0             6.0  5.0  2.0   \n",
      "\n",
      "   Team_size  Disruption  Atyp_Median_Z  ...  Field_CS  Field_Eng  Field_Eco  \\\n",
      "0        4.0    0.000275            NaN  ...         0          1          0   \n",
      "1        5.0         NaN            NaN  ...         0          1          0   \n",
      "2        1.0    0.000851            NaN  ...         0          1          0   \n",
      "3        4.0         NaN            NaN  ...         0          1          0   \n",
      "4        1.0    0.000053      58.137767  ...         0          1          0   \n",
      "\n",
      "   Log_Team_size    Log_C5  Log_Patent_Count  Log_Fund  Career Year  \\\n",
      "0       1.609438  0.693147               0.0       0.0          2.0   \n",
      "1       1.791759  1.609438               0.0       0.0         28.0   \n",
      "2       0.693147  0.693147               0.0       0.0          1.0   \n",
      "3       1.609438  1.609438               0.0       0.0          1.0   \n",
      "4       0.693147  1.098612               0.0       0.0          6.0   \n",
      "\n",
      "   Crisis Year  Crisis  \n",
      "0          NaN     NaN  \n",
      "1          NaN     NaN  \n",
      "2          NaN     NaN  \n",
      "3          NaN     NaN  \n",
      "4         -5.0     0.0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "合并后 'Crisis Year' 列非空值的数量: 12475358\n",
      "author_crisis_year_modified.tsv 文件行数: 11910273\n",
      "已将合并后的数据保存到文件: Merged_InTraFlow_CareerYear_Crisis.tsv\n",
      "数据合并完成，已将 'Crisis Year' 和 'Crisis' 列添加到 Merged_Cleaned_InTraFlow_CareerYear.tsv 数据中。\n",
      "请检查合并后的 DataFrame `df_merged` 和输出文件。 Merged_InTraFlow_CareerYear_Crisis.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载已有的数据\n",
    "file_path_merged = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df = pd.read_csv(file_path_merged, sep='\\t')\n",
    "\n",
    "# 加载 author_crisis_year_modified.tsv 数据\n",
    "file_path_crisis = 'author_crisis_year_modified.tsv'\n",
    "df_crisis = pd.read_csv(file_path_crisis, sep='\\t')\n",
    "\n",
    "# 检查两个 DataFrame 的列名，确保有 'PaperID' 列，并查看 'author_crisis_year_modified.tsv' 的列名\n",
    "print(\"Merged_Cleaned_InTraFlow_CareerYear.tsv 列名:\", df.columns.tolist())\n",
    "print(\"author_crisis_year_modified.tsv 列名:\", df_crisis.columns.tolist())\n",
    "\n",
    "# 步骤 1: 确保两个 DataFrame 都有 'PaperID' 列，且列名一致\n",
    "# 假设两个文件中的 'PaperID' 列名一致，如果列名不一致，需要先进行重命名\n",
    "if 'PaperID' not in df.columns or 'PaperID' not in df_crisis.columns:\n",
    "    raise ValueError(\"两个文件中必须都存在 'PaperID' 列才能进行匹配。请检查列名是否正确。\")\n",
    "\n",
    "# 步骤 2: 使用 'PaperID' 进行 left merge，将 crisis 数据合并到 df 中\n",
    "df_merged = pd.merge(df, df_crisis[['PaperID', 'Crisis Year', 'Crisis']], on='PaperID', how='left')\n",
    "\n",
    "# 检查合并后的 DataFrame 的列名和前几行数据\n",
    "print(\"合并后的 DataFrame 列名:\", df_merged.columns.tolist())\n",
    "print(\"合并后的 DataFrame 前几行数据:\")\n",
    "print(df_merged.head())\n",
    "\n",
    "# 步骤 3: (可选) 验证合并结果，例如检查 'Crisis Year' 和 'Crisis' 列是否有成功添加\n",
    "# 可以统计合并后 'Crisis Year' 列非空值的数量，与 df_crisis 中的行数进行比较 (如果PaperID都是唯一的话)\n",
    "print(\"合并后 'Crisis Year' 列非空值的数量:\", df_merged['Crisis Year'].count())\n",
    "print(\"author_crisis_year_modified.tsv 文件行数:\", len(df_crisis))\n",
    "\n",
    "# **重要提示**:  由于是 left merge，`df_merged` 会保留 `df` 中的所有行。\n",
    "# 如果 `df_crisis` 中没有对应 `df` 中 'PaperID' 的记录，则合并后的 'Crisis Year' 和 'Crisis' 列会显示 NaN。\n",
    "# 如果你想使用 inner merge (只保留两个文件中都有 'PaperID' 的行)，请将 `how='left'` 修改为 `how='inner'`。\n",
    "\n",
    "# 保存合并后的 DataFrame 到新的文件 (可选)\n",
    "output_merged_file = 'Merged_InTraFlow_CareerYear_Crisis.tsv'\n",
    "df_merged.to_csv(output_merged_file, sep='\\t', index=False)\n",
    "print(f\"已将合并后的数据保存到文件: {output_merged_file}\")\n",
    "\n",
    "print(\"数据合并完成，已将 'Crisis Year' 和 'Crisis' 列添加到 Merged_Cleaned_InTraFlow_CareerYear.tsv 数据中。\")\n",
    "print(\"请检查合并后的 DataFrame `df_merged` 和输出文件。\", output_merged_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件字段数: 27\n",
      "数据行数: 20331825\n",
      "各字段空值数量:\n",
      "字段 FieldID: 0 个空值\n",
      "字段 PaperID: 0 个空值\n",
      "字段 C_f: 3 个空值\n",
      "字段 Year: 3 个空值\n",
      "字段 Citation_Count: 0 个空值\n",
      "字段 C10: 12078540 个空值\n",
      "字段 C5: 6798056 个空值\n",
      "字段 Team_size: 167 个空值\n",
      "字段 Disruption: 6027911 个空值\n",
      "字段 Atyp_Median_Z: 7856467 个空值\n",
      "字段 SB_B: 9116931 个空值\n",
      "字段 SB_T: 9116931 个空值\n",
      "字段 InTraFlowf: 9981426 个空值\n",
      "字段 InTraFlow: 0 个空值\n",
      "字段 N_InTraFlow: 55811 个空值\n",
      "字段 Patent_Count: 0 个空值\n",
      "字段 Fund: 0 个空值\n",
      "字段 Field_CS: 0 个空值\n",
      "字段 Field_Eng: 0 个空值\n",
      "字段 Field_Eco: 0 个空值\n",
      "字段 Log_Team_size: 0 个空值\n",
      "字段 Log_C5: 0 个空值\n",
      "字段 Log_Patent_Count: 0 个空值\n",
      "字段 Log_Fund: 0 个空值\n",
      "字段 Career Year: 4626 个空值\n",
      "字段 Crisis Year: 0 个空值\n",
      "字段 Crisis: 0 个空值\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def analyze_tsv(file_path):\n",
    "    \"\"\"\n",
    "    分析大型TSV文件，输出字段数、行数和空值数量。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV文件路径。\n",
    "    \"\"\"\n",
    "    field_count = 0\n",
    "    row_count = 0\n",
    "    null_counts = None  # 用于存储每个字段的空值计数\n",
    "    field_names = None # 用于存储字段名\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_number, line in enumerate(f, start=1):\n",
    "                line = line.strip()  # 移除行尾空白\n",
    "                if not line:  # 跳过空行\n",
    "                    continue\n",
    "\n",
    "                fields = line.split('\\t')\n",
    "\n",
    "                if line_number == 1:\n",
    "                    # 第一行作为字段名行\n",
    "                    field_count = len(fields)\n",
    "                    null_counts = [0] * field_count  # 初始化空值计数列表\n",
    "                    print(f\"文件字段数: {field_count}\")\n",
    "                    field_names = fields # 保存字段名\n",
    "                else:\n",
    "                    row_count += 1\n",
    "                    # 统计空值\n",
    "                    for i, field in enumerate(fields):\n",
    "                        if i < field_count and not field:  # 检查是否为空值 (针对空字符串)\n",
    "                            null_counts[i] += 1\n",
    "\n",
    "        print(f\"数据行数: {row_count}\")\n",
    "        print(\"各字段空值数量:\")\n",
    "        if field_names and null_counts: # 如果有字段名，则一起输出\n",
    "            for i in range(field_count):\n",
    "                print(f\"字段 {field_names[i]}: {null_counts[i]} 个空值\")\n",
    "        else: # 否则只输出字段序号和空值数量\n",
    "            for i in range(field_count):\n",
    "                print(f\"字段 {i+1}: {null_counts[i]} 个空值\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生错误: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 直接指定文件名\n",
    "    tsv_file_path = \"Merged_InTraFlow_CareerYear_Crisis.tsv\"\n",
    "    # 注意：请确保 SciSciNet_MergedData_CareerYear.tsv 文件与该 Python 脚本在同一目录下，\n",
    "    # 或者提供文件的完整路径。\n",
    "\n",
    "    analyze_tsv(tsv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并前的 df (Merged_Cleaned_InTraFlow_CareerYear.tsv) 行数: 11756016\n",
      "合并后的 df (df_merged) 行数: 20331825\n",
      "\n",
      "合并后的 DataFrame 列名 (部分): ['FieldID', 'PaperID', 'C_f', 'Year', 'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'InTraFlowf', 'InTraFlow', 'N_InTraFlow', 'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng', 'Field_Eco']\n",
      "\n",
      "合并后的 DataFrame 'Crisis Year' 列的信息:\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 20331825 entries, 0 to 20331824\n",
      "Series name: Crisis Year\n",
      "Non-Null Count     Dtype  \n",
      "--------------     -----  \n",
      "12475358 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 155.1 MB\n",
      "None\n",
      "\n",
      "合并后的 DataFrame 'Crisis' 列的信息:\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 20331825 entries, 0 to 20331824\n",
      "Series name: Crisis\n",
      "Non-Null Count     Dtype  \n",
      "--------------     -----  \n",
      "12475358 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 155.1 MB\n",
      "None\n",
      "\n",
      "合并后的 DataFrame 前 10 行 (包含 Crisis Year 和 Crisis 列):\n",
      "   PaperID  Career Year  Crisis Year  Crisis\n",
      "0      125          2.0          NaN     NaN\n",
      "1      997         28.0          NaN     NaN\n",
      "2     3393          1.0          NaN     NaN\n",
      "3     5156          1.0          NaN     NaN\n",
      "4     8107          6.0         -5.0     0.0\n",
      "5    12678          1.0          NaN     NaN\n",
      "6    13070          3.0          NaN     NaN\n",
      "7    13101          1.0          NaN     NaN\n",
      "8    13407          1.0          NaN     NaN\n",
      "9    14447         17.0         -6.0     0.0\n",
      "\n",
      "**验证**: 没有发现 PaperID 在 df_crisis 中可能存在，但在合并后的 df_merged 中 'Crisis Year' 列为 NaN。合并初步验证通过。\n",
      "\n",
      "已将合并后的数据保存到文件: Merged_InTraFlow_CareerYear_Crisis.tsv\n",
      "\n",
      "数据合并完成，'Crisis Year' 和 'Crisis' 列已根据 'PaperID' 添加到 'Merged_Cleaned_InTraFlow_CareerYear.tsv' 数据中。\n",
      "请检查合并后的 DataFrame `df_merged` 的输出信息和输出文件。 Merged_InTraFlow_CareerYear_Crisis.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载已有的数据\n",
    "file_path_merged = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "df_merged_original = pd.read_csv(file_path_merged, sep='\\t') # 先加载到一个不同的变量名，方便后续比较\n",
    "df = df_merged_original.copy() # 使用 copy，避免修改原始数据\n",
    "\n",
    "# 加载 author_crisis_year_modified.tsv 数据\n",
    "file_path_crisis = 'author_crisis_year_modified.tsv'\n",
    "df_crisis = pd.read_csv(file_path_crisis, sep='\\t')\n",
    "\n",
    "# 步骤 1: 确保两个 DataFrame 都有 'PaperID' 列，且列名一致\n",
    "if 'PaperID' not in df.columns or 'PaperID' not in df_crisis.columns:\n",
    "    raise ValueError(\"两个文件中必须都存在 'PaperID' 列才能进行匹配。请检查列名是否正确。\")\n",
    "\n",
    "# 步骤 2: 选择 df_crisis 中需要的列，并进行合并 (left merge)\n",
    "df_crisis_subset = df_crisis[['PaperID', 'Crisis Year', 'Crisis']] # 显式选择需要的列\n",
    "df_merged = pd.merge(df, df_crisis_subset, on='PaperID', how='left')\n",
    "\n",
    "# 步骤 3: 验证合并结果 (更详细的验证)\n",
    "print(\"合并前的 df (Merged_Cleaned_InTraFlow_CareerYear.tsv) 行数:\", len(df_merged_original))\n",
    "print(\"合并后的 df (df_merged) 行数:\", len(df_merged))\n",
    "# 行数应该保持不变，因为是 left merge\n",
    "\n",
    "print(\"\\n合并后的 DataFrame 列名 (部分):\", df_merged.columns.tolist()[:20]) # 打印前 20 个列名，避免列名太多刷屏\n",
    "print(\"\\n合并后的 DataFrame 'Crisis Year' 列的信息:\")\n",
    "print(df_merged['Crisis Year'].info()) # 查看 'Crisis Year' 列的信息，包括非空值数量和数据类型\n",
    "print(\"\\n合并后的 DataFrame 'Crisis' 列的信息:\")\n",
    "print(df_merged['Crisis'].info()) # 查看 'Crisis' 列的信息\n",
    "\n",
    "print(\"\\n合并后的 DataFrame 前 10 行 (包含 Crisis Year 和 Crisis 列):\")\n",
    "print(df_merged[['PaperID', 'Career Year', 'Crisis Year', 'Crisis']].head(10)) # 显示 PaperID, Career Year, Crisis Year, Crisis 这几列的前 10 行\n",
    "\n",
    "# 检查是否有 PaperID 在 df_crisis 中存在，但在 df_merged 中 Crisis Year 为 NaN (表示没有成功合并)\n",
    "nan_crisis_year_with_possible_match = df_merged[df_merged['Crisis Year'].isnull() & df_merged['PaperID'].isin(df_crisis['PaperID'])]\n",
    "if not nan_crisis_year_with_possible_match.empty:\n",
    "    print(\"\\n**警告**: 发现以下 PaperID 在 df_crisis 中可能存在，但在合并后的 df_merged 中 'Crisis Year' 列为 NaN。请检查数据一致性：\")\n",
    "    print(nan_crisis_year_with_possible_match[['PaperID', 'Career Year']].head())\n",
    "else:\n",
    "    print(\"\\n**验证**: 没有发现 PaperID 在 df_crisis 中可能存在，但在合并后的 df_merged 中 'Crisis Year' 列为 NaN。合并初步验证通过。\")\n",
    "\n",
    "\n",
    "# 步骤 4: 保存合并后的 DataFrame 到新的文件 (可选)\n",
    "output_merged_file = 'Merged_InTraFlow_CareerYear_Crisis.tsv'\n",
    "df_merged.to_csv(output_merged_file, sep='\\t', index=False)\n",
    "print(f\"\\n已将合并后的数据保存到文件: {output_merged_file}\")\n",
    "\n",
    "print(\"\\n数据合并完成，'Crisis Year' 和 'Crisis' 列已根据 'PaperID' 添加到 'Merged_Cleaned_InTraFlow_CareerYear.tsv' 数据中。\")\n",
    "print(\"请检查合并后的 DataFrame `df_merged` 的输出信息和输出文件。\", output_merged_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略警告信息\n",
    "\n",
    "# 读取TSV文件\n",
    "file_path = 'Merged_Cleaned_InTraFlow.tsv'\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "print(f\"原始数据集大小: {data.shape}\")\n",
    "\n",
    "# 定义因变量\n",
    "dependent_vars = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "\n",
    "# 定义两组自变量（移除Field_Eco）\n",
    "independent_vars_1 = ['InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', \n",
    "                     'Field_CS', 'Field_Eng']  # 第一组模型的自变量\n",
    "                     \n",
    "independent_vars_2 = ['N_InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', \n",
    "                     'Field_CS', 'Field_Eng']  # 第二组模型的自变量\n",
    "\n",
    "# 检查列是否存在\n",
    "all_vars = list(set(dependent_vars + independent_vars_1 + independent_vars_2))\n",
    "missing_cols = [col for col in all_vars if col not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\"错误: 以下列不存在于数据中: {missing_cols}\")\n",
    "    print(f\"可用的列: {data.columns.tolist()}\")\n",
    "    exit(1)\n",
    "\n",
    "# 打印每个变量的基本信息\n",
    "print(\"\\n各变量缺失值情况:\")\n",
    "for col in all_vars:\n",
    "    na_count = data[col].isna().sum()\n",
    "    inf_count = np.isinf(data[col]).sum() if pd.api.types.is_numeric_dtype(data[col]) else 0\n",
    "    print(f\"{col}: 缺失值={na_count}, 无穷值={inf_count}\")\n",
    "\n",
    "# 执行回归分析并存储结果\n",
    "results = []\n",
    "\n",
    "# 模型1-5: 使用InTraFlow\n",
    "for i, dv in enumerate(dependent_vars):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理 Model {i+1}: {dv} (使用InTraFlow)\")\n",
    "    \n",
    "    # 为每个模型单独提取数据并处理缺失值\n",
    "    model_vars = [dv] + independent_vars_1\n",
    "    model_data = data[model_vars].copy()\n",
    "    \n",
    "    # 打印处理前的样本量\n",
    "    print(f\"处理前样本量: {len(model_data)}\")\n",
    "    \n",
    "    # 替换无穷值为NaN并删除缺失值\n",
    "    model_data = model_data.replace([np.inf, -np.inf], np.nan)\n",
    "    model_data = model_data.dropna()\n",
    "    print(f\"处理后有效样本量: {len(model_data)}\")\n",
    "    \n",
    "    if len(model_data) == 0:\n",
    "        print(f\"错误: Model {i+1} ({dv}) 没有有效数据!\")\n",
    "        continue\n",
    "    \n",
    "    # 检查多重共线性\n",
    "    X_check = sm.add_constant(model_data[independent_vars_1])\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X_check.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_check.values, j) \n",
    "                       for j in range(X_check.shape[1])]\n",
    "    print(\"VIF值 (多重共线性检测):\")\n",
    "    print(vif_data)\n",
    "    \n",
    "    # 执行OLS回归\n",
    "    y = model_data[dv]\n",
    "    X = sm.add_constant(model_data[independent_vars_1])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # 输出基本回归结果\n",
    "    print(f\"回归结果摘要:\")\n",
    "    print(f\"  R-squared: {model.rsquared:.4f}\")\n",
    "    print(f\"  Adj R-squared: {model.rsquared_adj:.4f}\")\n",
    "    print(f\"  F-statistic: {model.fvalue:.4f} (p-value: {model.f_pvalue:.4f})\")\n",
    "    \n",
    "    # 提取结果\n",
    "    result = {\n",
    "        'Model': f\"Model {i+1}\",\n",
    "        'DV': dv,\n",
    "        'IV': 'InTraFlow',\n",
    "        'Coefficients': model.params,\n",
    "        'P_values': model.pvalues,\n",
    "        'Std_Errors': model.bse,\n",
    "        'R_squared': model.rsquared,\n",
    "        'Adj_R_squared': model.rsquared_adj,\n",
    "        'F_statistic': model.fvalue,\n",
    "        'F_pvalue': model.f_pvalue,\n",
    "        'N': model.nobs\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# 模型6-10: 使用N_InTraFlow\n",
    "for i, dv in enumerate(dependent_vars):\n",
    "    model_number = i + 6  # 模型编号从6开始\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理 Model {model_number}: {dv} (使用N_InTraFlow)\")\n",
    "    \n",
    "    # 为每个模型单独提取数据并处理缺失值\n",
    "    model_vars = [dv] + independent_vars_2\n",
    "    model_data = data[model_vars].copy()\n",
    "    \n",
    "    # 打印处理前的样本量\n",
    "    print(f\"处理前样本量: {len(model_data)}\")\n",
    "    \n",
    "    # 替换无穷值为NaN并删除缺失值\n",
    "    model_data = model_data.replace([np.inf, -np.inf], np.nan)\n",
    "    model_data = model_data.dropna()\n",
    "    print(f\"处理后有效样本量: {len(model_data)}\")\n",
    "    \n",
    "    if len(model_data) == 0:\n",
    "        print(f\"错误: Model {model_number} ({dv}) 没有有效数据!\")\n",
    "        continue\n",
    "    \n",
    "    # 检查多重共线性\n",
    "    X_check = sm.add_constant(model_data[independent_vars_2])\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X_check.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_check.values, j) \n",
    "                       for j in range(X_check.shape[1])]\n",
    "    print(\"VIF值 (多重共线性检测):\")\n",
    "    print(vif_data)\n",
    "    \n",
    "    # 执行OLS回归\n",
    "    y = model_data[dv]\n",
    "    X = sm.add_constant(model_data[independent_vars_2])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # 输出基本回归结果\n",
    "    print(f\"回归结果摘要:\")\n",
    "    print(f\"  R-squared: {model.rsquared:.4f}\")\n",
    "    print(f\"  Adj R-squared: {model.rsquared_adj:.4f}\")\n",
    "    print(f\"  F-statistic: {model.fvalue:.4f} (p-value: {model.f_pvalue:.4f})\")\n",
    "    \n",
    "    # 提取结果\n",
    "    result = {\n",
    "        'Model': f\"Model {model_number}\",\n",
    "        'DV': dv,\n",
    "        'IV': 'N_InTraFlow',\n",
    "        'Coefficients': model.params,\n",
    "        'P_values': model.pvalues,\n",
    "        'Std_Errors': model.bse,\n",
    "        'R_squared': model.rsquared,\n",
    "        'Adj_R_squared': model.rsquared_adj,\n",
    "        'F_statistic': model.fvalue,\n",
    "        'F_pvalue': model.f_pvalue,\n",
    "        'N': model.nobs\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# 创建结果DataFrame\n",
    "output_file = 'Regression_Results_2.xlsx'\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 添加变量名 (使用第一组变量的名称，但在展示时会区分)\n",
    "var_names = ['Constant'] + independent_vars_1[1:]  # 除了第一个变量外的所有变量\n",
    "result_df['Variable'] = ['InTraFlow/N_InTraFlow'] + var_names + ['', 'Observations', 'R-squared', 'Adjusted R-squared', 'F-statistic', 'Prob > F']\n",
    "\n",
    "# 添加每个模型的结果\n",
    "for result in results:\n",
    "    model_col = []\n",
    "    \n",
    "    # 确定使用哪组变量\n",
    "    if result['IV'] == 'InTraFlow':\n",
    "        iv_vars = ['InTraFlow'] + independent_vars_1[1:]\n",
    "    else:\n",
    "        iv_vars = ['N_InTraFlow'] + independent_vars_2[1:]\n",
    "    \n",
    "    # 添加系数和标准误\n",
    "    for var in ['const'] + iv_vars:\n",
    "        coef = result['Coefficients'][var]\n",
    "        stderr = result['Std_Errors'][var]\n",
    "        pval = result['P_values'][var]\n",
    "        \n",
    "        # 添加显著性星号\n",
    "        stars = ''\n",
    "        if pval < 0.01:\n",
    "            stars = '***'\n",
    "        elif pval < 0.05:\n",
    "            stars = '**'\n",
    "        elif pval < 0.1:\n",
    "            stars = '*'\n",
    "        \n",
    "        # 格式化系数和标准误\n",
    "        model_col.append(f\"{coef:.3f}{stars}\\n({stderr:.3f})\")\n",
    "    \n",
    "    # 添加空行和统计量\n",
    "    model_col.append('')\n",
    "    model_col.append(f\"{int(result['N'])}\")\n",
    "    model_col.append(f\"{result['R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['Adj_R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['F_statistic']:.3f}\")\n",
    "    model_col.append(f\"{result['F_pvalue']:.6f}\")\n",
    "    \n",
    "    # 添加到结果DataFrame\n",
    "    result_df[f\"Model {result['Model'].split()[1]}\\n{result['DV']}\"] = model_col\n",
    "\n",
    "# 保存到Excel\n",
    "result_df.to_excel(output_file, sheet_name='Regression Results', index=False)\n",
    "\n",
    "# 格式化Excel文件\n",
    "wb = load_workbook(output_file)\n",
    "ws = wb['Regression Results']\n",
    "\n",
    "# 设置列宽和样式\n",
    "for col in ws.columns:\n",
    "    column = col[0].column_letter\n",
    "    max_length = max(len(str(cell.value or '')) for cell in col)\n",
    "    adjusted_width = max(max_length + 2, 15)  # 最小宽度15\n",
    "    ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "# 设置样式\n",
    "header_font = Font(bold=True)\n",
    "align_center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "align_left = Alignment(horizontal='left', vertical='center', wrap_text=True)\n",
    "border = Border(left=Side(style='thin'), right=Side(style='thin'), \n",
    "                top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "# 应用样式\n",
    "for row_idx, row in enumerate(ws.rows, 1):\n",
    "    for col_idx, cell in enumerate(row, 1):\n",
    "        cell.border = border\n",
    "        \n",
    "        if row_idx == 1:  # 标题行\n",
    "            cell.font = header_font\n",
    "            cell.alignment = align_center\n",
    "        else:\n",
    "            if col_idx == 1:  # 变量名列\n",
    "                cell.alignment = align_left\n",
    "            else:\n",
    "                cell.alignment = align_center\n",
    "\n",
    "# 添加注释说明星号的含义\n",
    "footnote_row = ws.max_row + 2\n",
    "ws.cell(row=footnote_row, column=1, value=\"注: *** p<0.01, ** p<0.05, * p<0.1，括号内为标准误\")\n",
    "ws.cell(row=footnote_row+1, column=1, value=\"Model 1-5使用InTraFlow作为自变量，Model 6-10使用N_InTraFlow作为自变量\")\n",
    "\n",
    "# 保存格式化后的Excel\n",
    "wb.save(output_file)\n",
    "\n",
    "print(f\"\\n回归结果已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: 文件 'Merged_Cleaned_InTraFlow_CareerYear.tsv' 中 'PaperID' 列 **不是唯一的**，存在重复值。\n",
      "  重复 'PaperID' 的总数量 (包括首次出现的): 278424\n",
      "  不同重复 'PaperID' 的数量: 135731\n",
      "\n",
      "重复的 'PaperID' 示例 (最多显示 5 个不同的 PaperID):\n",
      "\n",
      "PaperID: 269276\n",
      "         FieldID  PaperID       C_f    Year  Citation_Count  C10   C5  \\\n",
      "114  127413603.0   269276  0.164888  2013.0             1.0  NaN  1.0   \n",
      "115  127413603.0   269276  0.164888  2013.0             1.0  NaN  1.0   \n",
      "\n",
      "     Team_size  Disruption  Atyp_Median_Z  ...  Patent_Count  Fund  Field_CS  \\\n",
      "114        1.0    0.000972            NaN  ...             0     0         0   \n",
      "115        1.0    0.000972            NaN  ...             0     0         0   \n",
      "\n",
      "     Field_Eng  Field_Eco  Log_Team_size    Log_C5  Log_Patent_Count  \\\n",
      "114          1          0       0.693147  0.693147               0.0   \n",
      "115          1          0       0.693147  0.693147               0.0   \n",
      "\n",
      "     Log_Fund  Career Year  \n",
      "114       0.0         28.0  \n",
      "115       0.0         28.0  \n",
      "\n",
      "[2 rows x 25 columns]\n",
      "------------------------------\n",
      "\n",
      "PaperID: 367061\n",
      "         FieldID  PaperID       C_f    Year  Citation_Count  C10   C5  \\\n",
      "152  127413603.0   367061  0.659553  2013.0             4.0  NaN  4.0   \n",
      "153  127413603.0   367061  0.659553  2013.0             4.0  NaN  4.0   \n",
      "\n",
      "     Team_size  Disruption  Atyp_Median_Z  ...  Patent_Count  Fund  Field_CS  \\\n",
      "152        8.0   -0.002604       2.573659  ...             0     0         0   \n",
      "153        8.0   -0.002604       2.573659  ...             0     0         0   \n",
      "\n",
      "     Field_Eng  Field_Eco  Log_Team_size    Log_C5  Log_Patent_Count  \\\n",
      "152          1          0       2.197225  1.609438               0.0   \n",
      "153          1          0       2.197225  1.609438               0.0   \n",
      "\n",
      "     Log_Fund  Career Year  \n",
      "152       0.0          1.0  \n",
      "153       0.0          1.0  \n",
      "\n",
      "[2 rows x 25 columns]\n",
      "------------------------------\n",
      "\n",
      "PaperID: 1498789\n",
      "         FieldID  PaperID       C_f    Year  Citation_Count  C10   C5  \\\n",
      "520  127413603.0  1498789  0.444464  1961.0             1.0  1.0  1.0   \n",
      "521  127413603.0  1498789  0.444464  1961.0             1.0  1.0  1.0   \n",
      "522  127413603.0  1498789  0.444464  1961.0             1.0  1.0  1.0   \n",
      "\n",
      "     Team_size  Disruption  Atyp_Median_Z  ...  Patent_Count  Fund  Field_CS  \\\n",
      "520        3.0    0.000146            NaN  ...             0     0         0   \n",
      "521        3.0    0.000146            NaN  ...             0     0         0   \n",
      "522        3.0    0.000146            NaN  ...             0     0         0   \n",
      "\n",
      "     Field_Eng  Field_Eco  Log_Team_size    Log_C5  Log_Patent_Count  \\\n",
      "520          1          0       1.386294  0.693147               0.0   \n",
      "521          1          0       1.386294  0.693147               0.0   \n",
      "522          1          0       1.386294  0.693147               0.0   \n",
      "\n",
      "     Log_Fund  Career Year  \n",
      "520       0.0          1.0  \n",
      "521       0.0          1.0  \n",
      "522       0.0          1.0  \n",
      "\n",
      "[3 rows x 25 columns]\n",
      "------------------------------\n",
      "\n",
      "PaperID: 2096018\n",
      "         FieldID  PaperID       C_f    Year  Citation_Count   C10   C5  \\\n",
      "733  127413603.0  2096018  3.404404  2011.0            20.0  20.0  9.0   \n",
      "734  127413603.0  2096018  3.404404  2011.0            20.0  20.0  9.0   \n",
      "\n",
      "     Team_size  Disruption  Atyp_Median_Z  ...  Patent_Count  Fund  Field_CS  \\\n",
      "733        5.0   -0.000758        9.64419  ...             0     0         0   \n",
      "734        5.0   -0.000758        9.64419  ...             0     0         0   \n",
      "\n",
      "     Field_Eng  Field_Eco  Log_Team_size    Log_C5  Log_Patent_Count  \\\n",
      "733          1          0       1.791759  2.302585               0.0   \n",
      "734          1          0       1.791759  2.302585               0.0   \n",
      "\n",
      "     Log_Fund  Career Year  \n",
      "733       0.0          1.0  \n",
      "734       0.0          1.0  \n",
      "\n",
      "[2 rows x 25 columns]\n",
      "------------------------------\n",
      "\n",
      "PaperID: 2541563\n",
      "         FieldID  PaperID      C_f    Year  Citation_Count  C10   C5  \\\n",
      "930  127413603.0  2541563  0.84776  2012.0             5.0  NaN  2.0   \n",
      "931  127413603.0  2541563  0.84776  2012.0             5.0  NaN  2.0   \n",
      "\n",
      "     Team_size  Disruption  Atyp_Median_Z  ...  Patent_Count  Fund  Field_CS  \\\n",
      "930        2.0    0.001819       6.793465  ...             0     0         0   \n",
      "931        2.0    0.001819       6.793465  ...             0     0         0   \n",
      "\n",
      "     Field_Eng  Field_Eco  Log_Team_size    Log_C5  Log_Patent_Count  \\\n",
      "930          1          0       1.098612  1.098612               0.0   \n",
      "931          1          0       1.098612  1.098612               0.0   \n",
      "\n",
      "     Log_Fund  Career Year  \n",
      "930       0.0          1.0  \n",
      "931       0.0          1.0  \n",
      "\n",
      "[2 rows x 25 columns]\n",
      "------------------------------\n",
      "\n",
      "PaperID 唯一性验证完成。请查看以上输出信息。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "file_path_merged = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "\n",
    "# 加载数据\n",
    "try:\n",
    "    df = pd.read_csv(file_path_merged, sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误: 文件 '{file_path_merged}' 未找到，请检查文件路径是否正确。\")\n",
    "    exit()\n",
    "\n",
    "# 检查 'PaperID' 列是否存在\n",
    "if 'PaperID' not in df.columns:\n",
    "    print(f\"错误: 文件 '{file_path_merged}' 中缺少 'PaperID' 列。请检查文件结构。\")\n",
    "    exit()\n",
    "\n",
    "# 检查 'PaperID' 列的唯一性\n",
    "is_unique_paperid = df['PaperID'].is_unique\n",
    "\n",
    "if is_unique_paperid:\n",
    "    print(f\"文件 '{file_path_merged}' 中 'PaperID' 列是唯一的。\")\n",
    "else:\n",
    "    print(f\"警告: 文件 '{file_path_merged}' 中 'PaperID' 列 **不是唯一的**，存在重复值。\")\n",
    "\n",
    "    # 统计重复 PaperID 的数量\n",
    "    duplicate_paper_count = df['PaperID'].duplicated(keep=False).sum() # keep=False 标记所有重复项为 True\n",
    "    print(f\"  重复 'PaperID' 的总数量 (包括首次出现的): {duplicate_paper_count}\")\n",
    "\n",
    "    # 统计有多少个不同的 PaperID 出现了重复\n",
    "    unique_duplicate_paper_ids_count = df[df['PaperID'].duplicated(keep=False)]['PaperID'].nunique()\n",
    "    print(f\"  不同重复 'PaperID' 的数量: {unique_duplicate_paper_ids_count}\")\n",
    "\n",
    "    # 显示一些重复的 PaperID 示例 (最多显示 5 个不同的 PaperID)\n",
    "    print(\"\\n重复的 'PaperID' 示例 (最多显示 5 个不同的 PaperID):\")\n",
    "    duplicate_example_paper_ids = df[df['PaperID'].duplicated(keep='first')]['PaperID'].unique()[:5] # keep='first' 标记除首次出现外的重复项为 True\n",
    "    for paper_id in duplicate_example_paper_ids:\n",
    "        example_rows = df[df['PaperID'] == paper_id]\n",
    "        print(f\"\\nPaperID: {paper_id}\")\n",
    "        print(example_rows)\n",
    "        print(\"-\" * 30) # 分隔线\n",
    "\n",
    "print(\"\\nPaperID 唯一性验证完成。请查看以上输出信息。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前 DataFrame 行数: 11756016\n",
      "去重后 DataFrame 行数: 11613323\n",
      "删除的完全重复行数: 142693\n",
      "已将去重后的数据保存到文件: 'Merged_Cleaned_InTraFlow_CareerYear_Deduplicated.tsv'\n",
      "\n",
      "完全相同数据行去重操作完成。请查看以上输出信息和生成的新文件。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "file_path_merged = 'Merged_Cleaned_InTraFlow_CareerYear.tsv'\n",
    "file_path_output_deduplicated = 'Merged_Cleaned_InTraFlow_CareerYear_Deduplicated.tsv'\n",
    "\n",
    "# 加载数据\n",
    "try:\n",
    "    df = pd.read_csv(file_path_merged, sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误: 文件 '{file_path_merged}' 未找到，请检查文件路径是否正确。\")\n",
    "    exit()\n",
    "\n",
    "# 记录去重前的行数\n",
    "original_row_count = len(df)\n",
    "\n",
    "# 进行去重 (默认情况下，drop_duplicates() 会删除所有列完全相同的重复行，并保留第一行)\n",
    "df_deduplicated = df.drop_duplicates()\n",
    "\n",
    "# 记录去重后的行数\n",
    "deduplicated_row_count = len(df_deduplicated)\n",
    "\n",
    "# 计算删除的行数\n",
    "rows_dropped = original_row_count - deduplicated_row_count\n",
    "\n",
    "# 输出去重前后的行数和删除的行数\n",
    "print(f\"去重前 DataFrame 行数: {original_row_count}\")\n",
    "print(f\"去重后 DataFrame 行数: {deduplicated_row_count}\")\n",
    "print(f\"删除的完全重复行数: {rows_dropped}\")\n",
    "\n",
    "# 保存去重后的 DataFrame 到新的文件\n",
    "try:\n",
    "    df_deduplicated.to_csv(file_path_output_deduplicated, sep='\\t', index=False)\n",
    "    print(f\"已将去重后的数据保存到文件: '{file_path_output_deduplicated}'\")\n",
    "except Exception as e:\n",
    "    print(f\"保存文件时出错: {e}\")\n",
    "    print(f\"请检查是否有写入权限，或者磁盘空间是否充足。\")\n",
    "\n",
    "print(\"\\n完全相同数据行去重操作完成。请查看以上输出信息和生成的新文件。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并前的去重后 df (Merged_Cleaned_InTraFlow_CareerYear_Deduplicated.tsv) 行数: 11613323\n",
      "合并后的 df (df_merged) 行数: 11613323\n",
      "\n",
      "合并后的 DataFrame 列名 (部分): ['FieldID', 'PaperID', 'C_f', 'Year', 'Citation_Count', 'C10', 'C5', 'Team_size', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'InTraFlowf', 'InTraFlow', 'N_InTraFlow', 'Patent_Count', 'Fund', 'Field_CS', 'Field_Eng', 'Field_Eco']\n",
      "\n",
      "合并后的 DataFrame 'Crisis' 列的信息:\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 11613323 entries, 0 to 11613322\n",
      "Series name: Crisis\n",
      "Non-Null Count    Dtype  \n",
      "--------------    -----  \n",
      "3797147 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 88.6 MB\n",
      "None\n",
      "\n",
      "合并后的 DataFrame 前 10 行 (包含 Crisis 列):\n",
      "   PaperID  Career Year  Crisis\n",
      "0      125          2.0     NaN\n",
      "1      997         28.0     NaN\n",
      "2     3393          1.0     NaN\n",
      "3     5156          1.0     NaN\n",
      "4     8107          6.0     0.0\n",
      "5    12678          1.0     NaN\n",
      "6    13070          3.0     NaN\n",
      "7    13101          1.0     NaN\n",
      "8    13407          1.0     NaN\n",
      "9    14447         17.0     0.0\n",
      "\n",
      "已将合并后的数据保存到文件: Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv\n",
      "\n",
      "数据合并完成，'Crisis' 列已根据 'PaperID' (仅首次匹配) 添加到去重后的 'Merged_Cleaned_InTraFlow_CareerYear_Deduplicated.tsv' 数据中。\n",
      "请检查合并后的 DataFrame `df_merged` 的输出信息和输出文件。 Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载去重后的数据\n",
    "file_path_merged_deduplicated = 'Merged_Cleaned_InTraFlow_CareerYear_Deduplicated.tsv'\n",
    "df_merged_deduplicated_original = pd.read_csv(file_path_merged_deduplicated, sep='\\t')\n",
    "df = df_merged_deduplicated_original.copy()\n",
    "\n",
    "# 加载 author_crisis_year_modified.tsv 数据\n",
    "file_path_crisis = 'author_crisis_year_modified.tsv'\n",
    "df_crisis = pd.read_csv(file_path_crisis, sep='\\t')\n",
    "\n",
    "# **步骤 1: 处理 df_crisis 中的重复 PaperID，只保留第一次出现的记录**\n",
    "# 针对 'PaperID' 列去重，保留第一次出现的行\n",
    "df_crisis_unique_paperid = df_crisis.drop_duplicates(subset=['PaperID'], keep='first')\n",
    "\n",
    "# 步骤 2: 选择 df_crisis_unique_paperid 中需要的列 (只保留 'PaperID' 和 'Crisis')\n",
    "df_crisis_subset = df_crisis_unique_paperid[['PaperID', 'Crisis']]\n",
    "\n",
    "# 步骤 3: 进行 left merge，只合并 'Crisis' 列\n",
    "df_merged = pd.merge(df, df_crisis_subset, on='PaperID', how='left')\n",
    "\n",
    "# 步骤 4: 验证合并结果 (简化验证，只关注行数和列名)\n",
    "print(\"合并前的去重后 df (Merged_Cleaned_InTraFlow_CareerYear_Deduplicated.tsv) 行数:\", len(df_merged_deduplicated_original))\n",
    "print(\"合并后的 df (df_merged) 行数:\", len(df_merged))\n",
    "# 行数应该保持不变，因为是 left merge\n",
    "\n",
    "print(\"\\n合并后的 DataFrame 列名 (部分):\", df_merged.columns.tolist()[:20]) # 打印前 20 个列名\n",
    "print(\"\\n合并后的 DataFrame 'Crisis' 列的信息:\")\n",
    "print(df_merged['Crisis'].info())\n",
    "\n",
    "print(\"\\n合并后的 DataFrame 前 10 行 (包含 Crisis 列):\")\n",
    "print(df_merged[['PaperID', 'Career Year', 'Crisis']].head(10))\n",
    "\n",
    "# 步骤 5: 保存合并后的 DataFrame 到新的文件 (修改输出文件名)\n",
    "output_merged_file = 'Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv' # 修改文件名，更详细\n",
    "df_merged.to_csv(output_merged_file, sep='\\t', index=False)\n",
    "print(f\"\\n已将合并后的数据保存到文件: {output_merged_file}\")\n",
    "\n",
    "print(\"\\n数据合并完成，'Crisis' 列已根据 'PaperID' (仅首次匹配) 添加到去重后的 'Merged_Cleaned_InTraFlow_CareerYear_Deduplicated.tsv' 数据中。\")\n",
    "print(\"请检查合并后的 DataFrame `df_merged` 的输出信息和输出文件。\", output_merged_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件字段数: 26\n",
      "数据行数: 11613323\n",
      "各字段空值数量:\n",
      "字段 FieldID: 0 个空值\n",
      "字段 PaperID: 0 个空值\n",
      "字段 C_f: 3 个空值\n",
      "字段 Year: 3 个空值\n",
      "字段 Citation_Count: 0 个空值\n",
      "字段 C10: 5924481 个空值\n",
      "字段 C5: 3085294 个空值\n",
      "字段 Team_size: 167 个空值\n",
      "字段 Disruption: 4711622 个空值\n",
      "字段 Atyp_Median_Z: 7816176 个空值\n",
      "字段 SB_B: 7423844 个空值\n",
      "字段 SB_T: 7423844 个空值\n",
      "字段 InTraFlowf: 5546180 个空值\n",
      "字段 InTraFlow: 0 个空值\n",
      "字段 N_InTraFlow: 43895 个空值\n",
      "字段 Patent_Count: 0 个空值\n",
      "字段 Fund: 0 个空值\n",
      "字段 Field_CS: 0 个空值\n",
      "字段 Field_Eng: 0 个空值\n",
      "字段 Field_Eco: 0 个空值\n",
      "字段 Log_Team_size: 0 个空值\n",
      "字段 Log_C5: 0 个空值\n",
      "字段 Log_Patent_Count: 0 个空值\n",
      "字段 Log_Fund: 0 个空值\n",
      "字段 Career Year: 1603 个空值\n",
      "字段 Crisis: 0 个空值\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def analyze_tsv(file_path):\n",
    "    \"\"\"\n",
    "    分析大型TSV文件，输出字段数、行数和空值数量。\n",
    "\n",
    "    Args:\n",
    "        file_path (str): TSV文件路径。\n",
    "    \"\"\"\n",
    "    field_count = 0\n",
    "    row_count = 0\n",
    "    null_counts = None  # 用于存储每个字段的空值计数\n",
    "    field_names = None # 用于存储字段名\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_number, line in enumerate(f, start=1):\n",
    "                line = line.strip()  # 移除行尾空白\n",
    "                if not line:  # 跳过空行\n",
    "                    continue\n",
    "\n",
    "                fields = line.split('\\t')\n",
    "\n",
    "                if line_number == 1:\n",
    "                    # 第一行作为字段名行\n",
    "                    field_count = len(fields)\n",
    "                    null_counts = [0] * field_count  # 初始化空值计数列表\n",
    "                    print(f\"文件字段数: {field_count}\")\n",
    "                    field_names = fields # 保存字段名\n",
    "                else:\n",
    "                    row_count += 1\n",
    "                    # 统计空值\n",
    "                    for i, field in enumerate(fields):\n",
    "                        if i < field_count and not field:  # 检查是否为空值 (针对空字符串)\n",
    "                            null_counts[i] += 1\n",
    "\n",
    "        print(f\"数据行数: {row_count}\")\n",
    "        print(\"各字段空值数量:\")\n",
    "        if field_names and null_counts: # 如果有字段名，则一起输出\n",
    "            for i in range(field_count):\n",
    "                print(f\"字段 {field_names[i]}: {null_counts[i]} 个空值\")\n",
    "        else: # 否则只输出字段序号和空值数量\n",
    "            for i in range(field_count):\n",
    "                print(f\"字段 {i+1}: {null_counts[i]} 个空值\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生错误: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 直接指定文件名\n",
    "    tsv_file_path = \"Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv\"\n",
    "    # 注意：请确保 SciSciNet_MergedData_CareerYear.tsv 文件与该 Python 脚本在同一目录下，\n",
    "    # 或者提供文件的完整路径。\n",
    "\n",
    "    analyze_tsv(tsv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, NaN 值统计 - 文件: 'Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv':\n",
      "列名 'FieldID': NaN 值数量 = 0, 0 值数量 = 0, 1 值数量 = 0\n",
      "列名 'PaperID': NaN 值数量 = 0, 0 值数量 = 0, 1 值数量 = 0\n",
      "列名 'C_f': NaN 值数量 = 3, 0 值数量 = 2497546, 1 值数量 = 128\n",
      "列名 'Year': NaN 值数量 = 3, 0 值数量 = 0, 1 值数量 = 0\n",
      "列名 'Citation_Count': NaN 值数量 = 0, 0 值数量 = 2497546, 1 值数量 = 2038304\n",
      "列名 'C10': NaN 值数量 = 5924481, 0 值数量 = 1188107, 1 值数量 = 1018048\n",
      "列名 'C5': NaN 值数量 = 3085294, 0 值数量 = 2460886, 1 值数量 = 1584006\n",
      "列名 'Team_size': NaN 值数量 = 167, 0 值数量 = 0, 1 值数量 = 2743150\n",
      "列名 'Disruption': NaN 值数量 = 4711622, 0 值数量 = 495638, 1 值数量 = 0\n",
      "列名 'Atyp_Median_Z': NaN 值数量 = 7816176, 0 值数量 = 2039, 1 值数量 = 1329\n",
      "列名 'SB_B': NaN 值数量 = 7423844, 0 值数量 = 1104951, 1 值数量 = 377281\n",
      "列名 'SB_T': NaN 值数量 = 7423844, 0 值数量 = 1098895, 1 值数量 = 844702\n",
      "列名 'InTraFlowf': NaN 值数量 = 5546180, 0 值数量 = 1111093, 1 值数量 = 29\n",
      "列名 'InTraFlow': NaN 值数量 = 0, 0 值数量 = 3826262, 1 值数量 = 516340\n",
      "列名 'N_InTraFlow': NaN 值数量 = 43895, 0 值数量 = 3826265, 1 值数量 = 93\n",
      "列名 'Patent_Count': NaN 值数量 = 0, 0 值数量 = 10807124, 1 值数量 = 325006\n",
      "列名 'Fund': NaN 值数量 = 0, 0 值数量 = 11378618, 1 值数量 = 152844\n",
      "列名 'Field_CS': NaN 值数量 = 0, 0 值数量 = 4365254, 1 值数量 = 7248069\n",
      "列名 'Field_Eng': NaN 值数量 = 0, 0 值数量 = 8718227, 1 值数量 = 2895096\n",
      "列名 'Field_Eco': NaN 值数量 = 0, 0 值数量 = 10143165, 1 值数量 = 1470158\n",
      "列名 'Log_Team_size': NaN 值数量 = 0, 0 值数量 = 167, 1 值数量 = 0\n",
      "列名 'Log_C5': NaN 值数量 = 0, 0 值数量 = 5546180, 1 值数量 = 0\n",
      "列名 'Log_Patent_Count': NaN 值数量 = 0, 0 值数量 = 10807124, 1 值数量 = 0\n",
      "列名 'Log_Fund': NaN 值数量 = 0, 0 值数量 = 11378618, 1 值数量 = 0\n",
      "列名 'Career Year': NaN 值数量 = 13627, 0 值数量 = 0, 1 值数量 = 5337170\n",
      "列名 'Crisis': NaN 值数量 = 7816176, 0 值数量 = 2306703, 1 值数量 = 1490444\n",
      "\n",
      "0, 1, NaN 值统计完成。请查看以上输出信息。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径 (新生成的文件)\n",
    "output_merged_file = 'Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv'\n",
    "\n",
    "# 加载合并后的 DataFrame\n",
    "try:\n",
    "    df_merged = pd.read_csv(output_merged_file, sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误: 文件 '{output_merged_file}' 未找到，请检查文件路径是否正确。\")\n",
    "    exit()\n",
    "\n",
    "# 步骤 1: 遍历 DataFrame 的所有列\n",
    "print(f\"0, 1, NaN 值统计 - 文件: '{output_merged_file}':\")\n",
    "for col in df_merged.columns:\n",
    "    # 获取当前列的 Series\n",
    "    series = df_merged[col]\n",
    "\n",
    "    # 步骤 2: 统计每列的 NaN 值数量\n",
    "    nan_count = series.isna().sum()\n",
    "\n",
    "    # 步骤 3: 统计每列的 0 值数量 (只针对数值列，避免在字符串列上尝试比较)\n",
    "    zero_count = 0\n",
    "    if series.dtype in ['int64', 'float64']: # 检查列的数据类型是否为数值型\n",
    "        zero_count = (series == 0).sum()\n",
    "\n",
    "    # 步骤 4: 统计每列的 1 值数量 (只针对数值列)\n",
    "    one_count = 0\n",
    "    if series.dtype in ['int64', 'float64']: # 检查列的数据类型是否为数值型\n",
    "        one_count = (series == 1).sum()\n",
    "\n",
    "    # 步骤 5: 打印列名和统计结果\n",
    "    print(f\"列名 '{col}': NaN 值数量 = {nan_count}, 0 值数量 = {zero_count}, 1 值数量 = {one_count}\")\n",
    "\n",
    "print(\"\\n0, 1, NaN 值统计完成。请查看以上输出信息。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据集大小: (11613323, 26)\n",
      "\n",
      "各变量缺失值情况:\n",
      "N_InTraFlow: 缺失值=43895, 无穷值=0\n",
      "Field_CS: 缺失值=0, 无穷值=0\n",
      "Log_Fund: 缺失值=0, 无穷值=0\n",
      "Disruption: 缺失值=4711622, 无穷值=0\n",
      "SB_T: 缺失值=7423844, 无穷值=0\n",
      "Log_Team_size: 缺失值=0, 无穷值=0\n",
      "Log_Patent_Count: 缺失值=0, 无穷值=0\n",
      "Crisis: 缺失值=7816176, 无穷值=0\n",
      "Field_Eng: 缺失值=0, 无穷值=0\n",
      "SB_B: 缺失值=7423844, 无穷值=0\n",
      "Log_C5: 缺失值=0, 无穷值=0\n",
      "InTraFlow: 缺失值=0, 无穷值=43895\n",
      "Atyp_Median_Z: 缺失值=7816176, 无穷值=0\n",
      "\n",
      "==================================================\n",
      "处理 Model 1: Disruption (使用InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3181974\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.586804\n",
      "1         InTraFlow   1.159118\n",
      "2     Log_Team_size   1.125842\n",
      "3  Log_Patent_Count   1.020219\n",
      "4          Log_Fund   1.021426\n",
      "5          Field_CS   1.960053\n",
      "6         Field_Eng   1.912930\n",
      "7            Crisis   1.035982\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0099\n",
      "  Adj R-squared: 0.0099\n",
      "  F-statistic: 4534.7075 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 2: Atyp_Median_Z (使用InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3790718\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.856154\n",
      "1         InTraFlow   1.128997\n",
      "2     Log_Team_size   1.121948\n",
      "3  Log_Patent_Count   1.016326\n",
      "4          Log_Fund   1.019229\n",
      "5          Field_CS   1.977463\n",
      "6         Field_Eng   1.924917\n",
      "7            Crisis   1.029649\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0376\n",
      "  Adj R-squared: 0.0376\n",
      "  F-statistic: 21182.6395 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 3: SB_B (使用InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3012743\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.449106\n",
      "1         InTraFlow   1.160139\n",
      "2     Log_Team_size   1.126671\n",
      "3  Log_Patent_Count   1.021084\n",
      "4          Log_Fund   1.022070\n",
      "5          Field_CS   1.952028\n",
      "6         Field_Eng   1.905309\n",
      "7            Crisis   1.035093\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0290\n",
      "  Adj R-squared: 0.0290\n",
      "  F-statistic: 12862.6302 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 4: SB_T (使用InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3012743\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.449106\n",
      "1         InTraFlow   1.160139\n",
      "2     Log_Team_size   1.126671\n",
      "3  Log_Patent_Count   1.021084\n",
      "4          Log_Fund   1.022070\n",
      "5          Field_CS   1.952028\n",
      "6         Field_Eng   1.905309\n",
      "7            Crisis   1.035093\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0755\n",
      "  Adj R-squared: 0.0755\n",
      "  F-statistic: 35168.4236 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 5: Log_C5 (使用InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3790718\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.856154\n",
      "1         InTraFlow   1.128997\n",
      "2     Log_Team_size   1.121948\n",
      "3  Log_Patent_Count   1.016326\n",
      "4          Log_Fund   1.019229\n",
      "5          Field_CS   1.977463\n",
      "6         Field_Eng   1.924917\n",
      "7            Crisis   1.029649\n",
      "回归结果摘要:\n",
      "  R-squared: 0.1260\n",
      "  Adj R-squared: 0.1260\n",
      "  F-statistic: 78040.6364 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 6: Disruption (使用N_InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3181974\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.395485\n",
      "1       N_InTraFlow   1.008060\n",
      "2     Log_Team_size   1.123567\n",
      "3  Log_Patent_Count   1.012732\n",
      "4          Log_Fund   1.021584\n",
      "5          Field_CS   1.940811\n",
      "6         Field_Eng   1.863226\n",
      "7            Crisis   1.011487\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0104\n",
      "  Adj R-squared: 0.0104\n",
      "  F-statistic: 4760.6729 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 7: Atyp_Median_Z (使用N_InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3790718\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.694675\n",
      "1       N_InTraFlow   1.007055\n",
      "2     Log_Team_size   1.120690\n",
      "3  Log_Patent_Count   1.010898\n",
      "4          Log_Fund   1.019305\n",
      "5          Field_CS   1.958223\n",
      "6         Field_Eng   1.884428\n",
      "7            Crisis   1.016028\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0374\n",
      "  Adj R-squared: 0.0374\n",
      "  F-statistic: 21030.8789 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 8: SB_B (使用N_InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3012743\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.280174\n",
      "1       N_InTraFlow   1.008283\n",
      "2     Log_Team_size   1.124561\n",
      "3  Log_Patent_Count   1.013505\n",
      "4          Log_Fund   1.022151\n",
      "5          Field_CS   1.933414\n",
      "6         Field_Eng   1.853735\n",
      "7            Crisis   1.010616\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0292\n",
      "  Adj R-squared: 0.0292\n",
      "  F-statistic: 12938.5363 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 9: SB_T (使用N_InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3012743\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.280174\n",
      "1       N_InTraFlow   1.008283\n",
      "2     Log_Team_size   1.124561\n",
      "3  Log_Patent_Count   1.013505\n",
      "4          Log_Fund   1.022151\n",
      "5          Field_CS   1.933414\n",
      "6         Field_Eng   1.853735\n",
      "7            Crisis   1.010616\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0757\n",
      "  Adj R-squared: 0.0757\n",
      "  F-statistic: 35245.4262 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 10: Log_C5 (使用N_InTraFlow)\n",
      "处理前样本量: 11613323\n",
      "处理后有效样本量: 3790718\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable        VIF\n",
      "0             const  13.694675\n",
      "1       N_InTraFlow   1.007055\n",
      "2     Log_Team_size   1.120690\n",
      "3  Log_Patent_Count   1.010898\n",
      "4          Log_Fund   1.019305\n",
      "5          Field_CS   1.958223\n",
      "6         Field_Eng   1.884428\n",
      "7            Crisis   1.016028\n",
      "回归结果摘要:\n",
      "  R-squared: 0.1296\n",
      "  Adj R-squared: 0.1296\n",
      "  F-statistic: 80631.8547 (p-value: 0.0000)\n",
      "\n",
      "回归结果已保存到 Regression_Results_Pitfall.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略警告信息\n",
    "\n",
    "# 读取TSV文件\n",
    "file_path = 'Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv'\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "print(f\"原始数据集大小: {data.shape}\")\n",
    "\n",
    "# 定义因变量\n",
    "dependent_vars = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "\n",
    "# 定义两组自变量（移除Field_Eco）\n",
    "independent_vars_1 = ['InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', \n",
    "                     'Field_CS', 'Field_Eng','Crisis']  # 第一组模型的自变量\n",
    "                     \n",
    "independent_vars_2 = ['N_InTraFlow', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund', \n",
    "                     'Field_CS', 'Field_Eng', 'Crisis']  # 第二组模型的自变量\n",
    "\n",
    "# 检查列是否存在\n",
    "all_vars = list(set(dependent_vars + independent_vars_1 + independent_vars_2))\n",
    "missing_cols = [col for col in all_vars if col not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\"错误: 以下列不存在于数据中: {missing_cols}\")\n",
    "    print(f\"可用的列: {data.columns.tolist()}\")\n",
    "    exit(1)\n",
    "\n",
    "# 打印每个变量的基本信息\n",
    "print(\"\\n各变量缺失值情况:\")\n",
    "for col in all_vars:\n",
    "    na_count = data[col].isna().sum()\n",
    "    inf_count = np.isinf(data[col]).sum() if pd.api.types.is_numeric_dtype(data[col]) else 0\n",
    "    print(f\"{col}: 缺失值={na_count}, 无穷值={inf_count}\")\n",
    "\n",
    "# 执行回归分析并存储结果\n",
    "results = []\n",
    "\n",
    "# 模型1-5: 使用InTraFlow\n",
    "for i, dv in enumerate(dependent_vars):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理 Model {i+1}: {dv} (使用InTraFlow)\")\n",
    "    \n",
    "    # 为每个模型单独提取数据并处理缺失值\n",
    "    model_vars = [dv] + independent_vars_1\n",
    "    model_data = data[model_vars].copy()\n",
    "    \n",
    "    # 打印处理前的样本量\n",
    "    print(f\"处理前样本量: {len(model_data)}\")\n",
    "    \n",
    "    # 替换无穷值为NaN并删除缺失值\n",
    "    model_data = model_data.replace([np.inf, -np.inf], np.nan)\n",
    "    model_data = model_data.dropna()\n",
    "    print(f\"处理后有效样本量: {len(model_data)}\")\n",
    "    \n",
    "    if len(model_data) == 0:\n",
    "        print(f\"错误: Model {i+1} ({dv}) 没有有效数据!\")\n",
    "        continue\n",
    "    \n",
    "    # 检查多重共线性\n",
    "    X_check = sm.add_constant(model_data[independent_vars_1])\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X_check.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_check.values, j) \n",
    "                       for j in range(X_check.shape[1])]\n",
    "    print(\"VIF值 (多重共线性检测):\")\n",
    "    print(vif_data)\n",
    "    \n",
    "    # 执行OLS回归\n",
    "    y = model_data[dv]\n",
    "    X = sm.add_constant(model_data[independent_vars_1])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # 输出基本回归结果\n",
    "    print(f\"回归结果摘要:\")\n",
    "    print(f\"  R-squared: {model.rsquared:.4f}\")\n",
    "    print(f\"  Adj R-squared: {model.rsquared_adj:.4f}\")\n",
    "    print(f\"  F-statistic: {model.fvalue:.4f} (p-value: {model.f_pvalue:.4f})\")\n",
    "    \n",
    "    # 提取结果\n",
    "    result = {\n",
    "        'Model': f\"Model {i+1}\",\n",
    "        'DV': dv,\n",
    "        'IV': 'InTraFlow',\n",
    "        'Coefficients': model.params,\n",
    "        'P_values': model.pvalues,\n",
    "        'Std_Errors': model.bse,\n",
    "        'R_squared': model.rsquared,\n",
    "        'Adj_R_squared': model.rsquared_adj,\n",
    "        'F_statistic': model.fvalue,\n",
    "        'F_pvalue': model.f_pvalue,\n",
    "        'N': model.nobs\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# 模型6-10: 使用N_InTraFlow\n",
    "for i, dv in enumerate(dependent_vars):\n",
    "    model_number = i + 6  # 模型编号从6开始\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理 Model {model_number}: {dv} (使用N_InTraFlow)\")\n",
    "    \n",
    "    # 为每个模型单独提取数据并处理缺失值\n",
    "    model_vars = [dv] + independent_vars_2\n",
    "    model_data = data[model_vars].copy()\n",
    "    \n",
    "    # 打印处理前的样本量\n",
    "    print(f\"处理前样本量: {len(model_data)}\")\n",
    "    \n",
    "    # 替换无穷值为NaN并删除缺失值\n",
    "    model_data = model_data.replace([np.inf, -np.inf], np.nan)\n",
    "    model_data = model_data.dropna()\n",
    "    print(f\"处理后有效样本量: {len(model_data)}\")\n",
    "    \n",
    "    if len(model_data) == 0:\n",
    "        print(f\"错误: Model {model_number} ({dv}) 没有有效数据!\")\n",
    "        continue\n",
    "    \n",
    "    # 检查多重共线性\n",
    "    X_check = sm.add_constant(model_data[independent_vars_2])\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X_check.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_check.values, j) \n",
    "                       for j in range(X_check.shape[1])]\n",
    "    print(\"VIF值 (多重共线性检测):\")\n",
    "    print(vif_data)\n",
    "    \n",
    "    # 执行OLS回归\n",
    "    y = model_data[dv]\n",
    "    X = sm.add_constant(model_data[independent_vars_2])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # 输出基本回归结果\n",
    "    print(f\"回归结果摘要:\")\n",
    "    print(f\"  R-squared: {model.rsquared:.4f}\")\n",
    "    print(f\"  Adj R-squared: {model.rsquared_adj:.4f}\")\n",
    "    print(f\"  F-statistic: {model.fvalue:.4f} (p-value: {model.f_pvalue:.4f})\")\n",
    "    \n",
    "    # 提取结果\n",
    "    result = {\n",
    "        'Model': f\"Model {model_number}\",\n",
    "        'DV': dv,\n",
    "        'IV': 'N_InTraFlow',\n",
    "        'Coefficients': model.params,\n",
    "        'P_values': model.pvalues,\n",
    "        'Std_Errors': model.bse,\n",
    "        'R_squared': model.rsquared,\n",
    "        'Adj_R_squared': model.rsquared_adj,\n",
    "        'F_statistic': model.fvalue,\n",
    "        'F_pvalue': model.f_pvalue,\n",
    "        'N': model.nobs\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# 创建结果DataFrame\n",
    "output_file = 'Regression_Results_Pitfall.xlsx'\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 添加变量名 (使用第一组变量的名称，但在展示时会区分)\n",
    "var_names = ['Constant'] + independent_vars_1[1:]  # 除了第一个变量外的所有变量\n",
    "result_df['Variable'] = ['InTraFlow/N_InTraFlow'] + var_names + ['', 'Observations', 'R-squared', 'Adjusted R-squared', 'F-statistic', 'Prob > F']\n",
    "\n",
    "# 添加每个模型的结果\n",
    "for result in results:\n",
    "    model_col = []\n",
    "    \n",
    "    # 确定使用哪组变量\n",
    "    if result['IV'] == 'InTraFlow':\n",
    "        iv_vars = ['InTraFlow'] + independent_vars_1[1:]\n",
    "    else:\n",
    "        iv_vars = ['N_InTraFlow'] + independent_vars_2[1:]\n",
    "    \n",
    "    # 添加系数和标准误\n",
    "    for var in ['const'] + iv_vars:\n",
    "        coef = result['Coefficients'][var]\n",
    "        stderr = result['Std_Errors'][var]\n",
    "        pval = result['P_values'][var]\n",
    "        \n",
    "        # 添加显著性星号\n",
    "        stars = ''\n",
    "        if pval < 0.01:\n",
    "            stars = '***'\n",
    "        elif pval < 0.05:\n",
    "            stars = '**'\n",
    "        elif pval < 0.1:\n",
    "            stars = '*'\n",
    "        \n",
    "        # 格式化系数和标准误\n",
    "        model_col.append(f\"{coef:.3f}{stars}\\n({stderr:.3f})\")\n",
    "    \n",
    "    # 添加空行和统计量\n",
    "    model_col.append('')\n",
    "    model_col.append(f\"{int(result['N'])}\")\n",
    "    model_col.append(f\"{result['R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['Adj_R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['F_statistic']:.3f}\")\n",
    "    model_col.append(f\"{result['F_pvalue']:.6f}\")\n",
    "    \n",
    "    # 添加到结果DataFrame\n",
    "    result_df[f\"Model {result['Model'].split()[1]}\\n{result['DV']}\"] = model_col\n",
    "\n",
    "# 保存到Excel\n",
    "result_df.to_excel(output_file, sheet_name='Regression Results', index=False)\n",
    "\n",
    "# 格式化Excel文件\n",
    "wb = load_workbook(output_file)\n",
    "ws = wb['Regression Results']\n",
    "\n",
    "# 设置列宽和样式\n",
    "for col in ws.columns:\n",
    "    column = col[0].column_letter\n",
    "    max_length = max(len(str(cell.value or '')) for cell in col)\n",
    "    adjusted_width = max(max_length + 2, 15)  # 最小宽度15\n",
    "    ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "# 设置样式\n",
    "header_font = Font(bold=True)\n",
    "align_center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "align_left = Alignment(horizontal='left', vertical='center', wrap_text=True)\n",
    "border = Border(left=Side(style='thin'), right=Side(style='thin'), \n",
    "                top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "# 应用样式\n",
    "for row_idx, row in enumerate(ws.rows, 1):\n",
    "    for col_idx, cell in enumerate(row, 1):\n",
    "        cell.border = border\n",
    "        \n",
    "        if row_idx == 1:  # 标题行\n",
    "            cell.font = header_font\n",
    "            cell.alignment = align_center\n",
    "        else:\n",
    "            if col_idx == 1:  # 变量名列\n",
    "                cell.alignment = align_left\n",
    "            else:\n",
    "                cell.alignment = align_center\n",
    "\n",
    "# 添加注释说明星号的含义\n",
    "footnote_row = ws.max_row + 2\n",
    "ws.cell(row=footnote_row, column=1, value=\"注: *** p<0.01, ** p<0.05, * p<0.1，括号内为标准误\")\n",
    "ws.cell(row=footnote_row+1, column=1, value=\"Model 1-5使用InTraFlow作为自变量，Model 6-10使用N_InTraFlow作为自变量\")\n",
    "\n",
    "# 保存格式化后的Excel\n",
    "wb.save(output_file)\n",
    "\n",
    "print(f\"\\n回归结果已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分析基于 Complete Cases: 符合所有变量均非空值的行数: 3012743\n",
      "已成功计算 Complete Case 变量相关性、均值和标准差，并输出到 Excel 文件: Correlation_Matrix_Descriptive_CompleteCases_2.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def calculate_correlations_descriptive_complete_cases_corrected_excel_sheet_names(input_file_path, output_excel_path, variables):\n",
    "    \"\"\"\n",
    "    计算指定变量的 complete case 相关性、均值和标准差，输出到 Excel 文件，并标记相关性显著性.\n",
    "    Uses only rows where ALL specified variables have non-missing values (complete cases).\n",
    "    Corrected version to handle FutureWarning and Excel sheet name length limit.\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): 输入 TSV 文件路径.\n",
    "        output_excel_path (str): 输出 Excel 文件路径.\n",
    "        variables (list): 需要计算相关性和描述性统计的变量名列表.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 读取 TSV 文件\n",
    "        df = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "        # 检查变量是否存在于 DataFrame 中\n",
    "        missing_variables = [var for var in variables if var not in df.columns]\n",
    "        if missing_variables:\n",
    "            print(f\"警告: 以下变量未在文件中找到，将跳过这些变量: {missing_variables}\")\n",
    "            variables = [var for var in variables if var in df.columns]\n",
    "            if not variables:\n",
    "                print(\"错误: 指定的变量列表中没有找到任何有效的列名，无法计算相关性和描述性统计。\")\n",
    "                return\n",
    "\n",
    "        # 提取需要计算的变量列\n",
    "        data = df[variables].copy()\n",
    "\n",
    "        # Convert all relevant columns to numeric, coercing errors to NaN\n",
    "        for var in variables:\n",
    "            data[var] = pd.to_numeric(data[var], errors='coerce')\n",
    "\n",
    "        # Filter out rows where ANY of the specified variables are NaN (complete case analysis)\n",
    "        complete_data = data.dropna(subset=variables)\n",
    "\n",
    "        print(f\"分析基于 Complete Cases: 符合所有变量均非空值的行数: {len(complete_data)}\")\n",
    "\n",
    "        if complete_data.empty:\n",
    "            print(\"警告: 没有 Complete Cases (所有指定变量均非空的行)，无法计算相关性和描述性统计。\")\n",
    "            return\n",
    "\n",
    "        # 计算相关性矩阵 (Pearson correlation) on complete cases\n",
    "        correlation_matrix = complete_data.corr(method='pearson')\n",
    "\n",
    "        # 计算 p-value 矩阵 on complete cases\n",
    "        p_value_matrix = pd.DataFrame(index=correlation_matrix.index, columns=correlation_matrix.columns)\n",
    "        for col in correlation_matrix.columns:\n",
    "            for row in correlation_matrix.index:\n",
    "                if row != col: # Avoid calculating p-value for correlation of variable with itself\n",
    "                    corr_val = correlation_matrix.loc[row, col]\n",
    "                    if pd.notna(corr_val): # Check for NaN correlation values\n",
    "                        series_x = complete_data[row].dropna() # dropna here is redundant as complete_data is already dropna, but kept for consistency\n",
    "                        series_y = complete_data[col].dropna() # dropna here is redundant as complete_data is already dropna, but kept for consistency\n",
    "\n",
    "                        if len(series_x) == len(series_y) and len(series_x) > 0:\n",
    "                            try:\n",
    "                                p_value = stats.pearsonr(series_x, series_y)[1]\n",
    "                                p_value_matrix.loc[row, col] = p_value\n",
    "                            except ValueError as ve:\n",
    "                                print(f\"警告: ValueError in pearsonr for '{row}' and '{col}': {ve}. Setting p-value to NaN.\")\n",
    "                                p_value_matrix.loc[row, col] = np.nan\n",
    "                            except Exception as e:\n",
    "                                print(f\"警告: Unexpected error in pearsonr for '{row}' and '{col}': {e}. Setting p-value to NaN.\")\n",
    "                                p_value_matrix.loc[row, col] = np.nan\n",
    "                        else:\n",
    "                            print(f\"警告: 变量 '{row}' 和 '{col}' 在Complete Cases中去除 NaN 值后长度不一致 或 为空，跳过 p-value 计算。\")\n",
    "                            p_value_matrix.loc[row, col] = np.nan\n",
    "                    else:\n",
    "                        p_value_matrix.loc[row, col] = np.nan\n",
    "                else:\n",
    "                    p_value_matrix.loc[row, col] = np.nan # No p-value for self-correlation\n",
    "\n",
    "        # 定义显著性标记函数 (no change needed)\n",
    "        def get_significance_stars(p_value):\n",
    "            if pd.isna(p_value): # Handle NaN p-values\n",
    "                return \"\"\n",
    "            if p_value < 0.001:\n",
    "                return \"***\"\n",
    "            elif p_value < 0.01:\n",
    "                return \"**\"\n",
    "            elif p_value < 0.05:\n",
    "                return \"*\"\n",
    "            else:\n",
    "                return \"\"\n",
    "\n",
    "        # 应用显著性标记到相关性矩阵\n",
    "        correlation_matrix_with_stars = correlation_matrix.copy().astype(str) # Explicitly cast to string type HERE\n",
    "        for col in correlation_matrix.columns:\n",
    "            for row in correlation_matrix.index:\n",
    "                if row != col:\n",
    "                    p_val = p_value_matrix.loc[row, col]\n",
    "                    stars = get_significance_stars(p_val)\n",
    "                    correlation_matrix_with_stars.loc[row, col] = f\"{correlation_matrix.loc[row, col]:.2f}{stars}\" # Format to 2 decimal places\n",
    "\n",
    "        # 计算均值和标准差 on complete cases (no change needed)\n",
    "        descriptive_stats = pd.DataFrame({\n",
    "            'Mean': complete_data.mean(),\n",
    "            'Standard Deviation': complete_data.std()\n",
    "        })\n",
    "\n",
    "        # 将结果输出到 Excel 文件 (Sheet names shortened to be <= 31 chars)\n",
    "        with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "            correlation_matrix_with_stars.to_excel(writer, sheet_name='Corr Matrix (Complete)', index=True) # Shortened sheet name\n",
    "            correlation_matrix.to_excel(writer, sheet_name='Corr Values (Complete)', index=True) # Shortened sheet name\n",
    "            p_value_matrix.to_excel(writer, sheet_name='P-Values (Complete)', index=True) # Shortened sheet name\n",
    "            descriptive_stats.to_excel(writer, sheet_name='Descriptive Stats (Complete)', index=True) # Shortened sheet name\n",
    "\n",
    "        print(f\"已成功计算 Complete Case 变量相关性、均值和标准差，并输出到 Excel 文件: {output_excel_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 未找到，请检查文件路径。\")\n",
    "    except KeyError:\n",
    "        print(f\"错误: 文件 '{input_file_path}' 缺少指定列，请检查文件结构。\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时发生错误: {e}\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 定义文件路径和变量列表 (no change needed)\n",
    "input_file_path = \"Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv\"  # 修改为你的输入文件路径\n",
    "output_excel_path = \"Correlation_Matrix_Descriptive_CompleteCases_2.xlsx\" # 输出 Excel 文件路径 (修改了输出文件名)\n",
    "variables_to_correlate_descriptive_complete_cases = [\n",
    "    'InTraFlow', 'N_InTraFlow', 'Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T',\n",
    "    'Log_Team_size', 'Log_C5', 'Log_Patent_Count', 'Log_Fund', 'Field_CS', 'Field_Eng', 'Field_Eco', 'Crisis'\n",
    "]\n",
    "\n",
    "# 调用函数计算相关性、描述性统计并输出到 Excel (no change needed)\n",
    "calculate_correlations_descriptive_complete_cases_corrected_excel_sheet_names(input_file_path, output_excel_path, variables_to_correlate_descriptive_complete_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在文件 'Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv' 中的 PaperID 对应的去重作者数量为: 5875151\n"
     ]
    }
   ],
   "source": [
    "def count_unique_authors_for_paperids(file1_path, file2_path):\n",
    "    \"\"\"\n",
    "    计算第一个文件中 PaperID 对应的在第二个文件中的去重作者数量。\n",
    "\n",
    "    Args:\n",
    "        file1_path (str): 第一个文件的路径，包含 PaperID 在第二列。\n",
    "        file2_path (str): 第二个文件的路径，包含 PaperID 在第一列，AuthorID 在第二列。\n",
    "\n",
    "    Returns:\n",
    "        int: 第一个文件中 PaperID 对应的去重作者数量。\n",
    "             如果文件读取失败，返回 None。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取第一个文件，获取目标 PaperID 集合\n",
    "        target_paper_ids = set()\n",
    "        with open(file1_path, 'r', encoding='utf-8') as f1:\n",
    "            next(f1)  # 跳过表头，如果存在\n",
    "            for line in f1:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) > 1: # 确保行有第二列\n",
    "                    try:\n",
    "                        paper_id_file1 = parts[1] # 第二列是 PaperID\n",
    "                        target_paper_ids.add(paper_id_file1)\n",
    "                    except IndexError:\n",
    "                        print(f\"警告: 文件 {file1_path} 中行数据列数不足: {line.strip()}\")\n",
    "                        continue\n",
    "\n",
    "        # 读取第二个文件，查找 PaperID 对应的作者\n",
    "        unique_authors = set()\n",
    "        with open(file2_path, 'r', encoding='utf-8') as f2:\n",
    "            next(f2) # 跳过表头，如果存在\n",
    "            for line in f2:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) > 1: # 确保行有两列\n",
    "                    try:\n",
    "                        paper_id_file2 = parts[0] # 第一列是 PaperID\n",
    "                        author_id = parts[1]      # 第二列是 AuthorID\n",
    "                        if paper_id_file2 in target_paper_ids:\n",
    "                            unique_authors.add(author_id)\n",
    "                    except IndexError:\n",
    "                        print(f\"警告: 文件 {file2_path} 中行数据列数不足: {line.strip()}\")\n",
    "                        continue\n",
    "\n",
    "        return len(unique_authors)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到，请检查文件路径是否正确。\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file1_path = \"Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv\"\n",
    "    file2_path = \"SciSciNet_MergedData_CareerYear.tsv\"\n",
    "\n",
    "    unique_author_count = count_unique_authors_for_paperids(file1_path, file2_path)\n",
    "\n",
    "    if unique_author_count is not None:\n",
    "        print(f\"在文件 '{file1_path}' 中的 PaperID 对应的去重作者数量为: {unique_author_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理...\n",
      "正在读取文件: Merged_IMC_多字段.tsv\n",
      "正在读取文件: Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv\n",
      "正在根据 'PaperID' 合并数据...\n",
      "正在将结果保存到: Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp.tsv\n",
      "处理完成！\n",
      "合并后的文件已保存至: .\\Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 配置 ---\n",
    "# 定义文件所在的目录路径 (请根据你的实际情况修改)\n",
    "# 如果脚本和文件在同一个目录下，可以使用 '.'\n",
    "file_directory = '.'\n",
    "# 或者指定一个绝对/相对路径，例如:\n",
    "# file_directory = '/path/to/your/files'\n",
    "# file_directory = 'C:\\\\Users\\\\YourUsername\\\\Documents\\\\Data'\n",
    "\n",
    "# 定义文件名\n",
    "imc_file_name = 'Merged_IMC_多字段.tsv'\n",
    "intraf_file_name = 'Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated.tsv'\n",
    "output_file_name = 'Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp.tsv'\n",
    "\n",
    "# 构建完整的文件路径\n",
    "imc_file_path = os.path.join(file_directory, imc_file_name)\n",
    "intraf_file_path = os.path.join(file_directory, intraf_file_name)\n",
    "output_file_path = os.path.join(file_directory, output_file_name)\n",
    "\n",
    "# 定义关键列的名称 (假设列名就是 'PaperID' 和 'IMCp')\n",
    "# 如果列名不同或者文件没有标题行，需要调整读取方式\n",
    "paperid_col = 'PaperID'\n",
    "imcp_col = 'IMCp'\n",
    "\n",
    "# --- 数据处理 ---\n",
    "try:\n",
    "    print(f\"开始处理...\")\n",
    "    print(f\"正在读取文件: {imc_file_name}\")\n",
    "    # 读取第一个文件 (Merged_IMC)，只读取需要的列 'PaperID' 和 'IMCp'\n",
    "    # 假设第二列的列名为 'PaperID'，包含IMCp的列名为 'IMCp'\n",
    "    # 如果文件第一行不是标题，需要设置 header=None 并使用列索引 (iloc)\n",
    "    df_imc = pd.read_csv(\n",
    "        imc_file_path,\n",
    "        sep='\\t',        # TSV 文件使用制表符分隔\n",
    "        usecols=[paperid_col, imcp_col], # 只加载这两列，提高效率\n",
    "        encoding='utf-8' # 使用 utf-8 编码，兼容中文等字符\n",
    "    )\n",
    "\n",
    "    # 处理第一个文件中可能存在的重复 PaperID\n",
    "    # 如果一个 PaperID 有多个 IMCp 值，这里默认保留第一个出现的\n",
    "    df_imc = df_imc.drop_duplicates(subset=[paperid_col], keep='first')\n",
    "\n",
    "    print(f\"正在读取文件: {intraf_file_name}\")\n",
    "    # 读取第二个文件 (Merged_InTraFlow)\n",
    "    # 假设第二列的列名为 'PaperID'\n",
    "    df_intraf = pd.read_csv(\n",
    "        intraf_file_path,\n",
    "        sep='\\t',\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "\n",
    "    # 确保用于合并的 PaperID 列是相同的数据类型（通常字符串类型更安全）\n",
    "    df_imc[paperid_col] = df_imc[paperid_col].astype(str)\n",
    "    df_intraf[paperid_col] = df_intraf[paperid_col].astype(str)\n",
    "\n",
    "    print(f\"正在根据 '{paperid_col}' 合并数据...\")\n",
    "    # 使用左合并 (left merge)，将 df_imc 中的 IMCp 合并到 df_intraf\n",
    "    # 'how='left'' 表示以 df_intraf 为基础，保留 df_intraf 的所有行\n",
    "    # 如果 df_intraf 中的某个 PaperID 在 df_imc 中找不到，则对应的 IMCp 列会是 NaN (空值)\n",
    "    merged_df = pd.merge(\n",
    "        df_intraf,\n",
    "        df_imc,\n",
    "        on=paperid_col,  # 指定合并依据的列\n",
    "        how='left'       # 使用左合并\n",
    "    )\n",
    "\n",
    "    print(f\"正在将结果保存到: {output_file_name}\")\n",
    "    # 将合并后的 DataFrame 保存为新的 TSV 文件\n",
    "    merged_df.to_csv(\n",
    "        output_file_path,\n",
    "        sep='\\t',        # 使用制表符分隔\n",
    "        index=False,     # 不保存 DataFrame 的索引到文件中\n",
    "        encoding='utf-8' # 使用 utf-8 编码\n",
    "    )\n",
    "\n",
    "    print(\"处理完成！\")\n",
    "    print(f\"合并后的文件已保存至: {output_file_path}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误：找不到一个或多个输入文件。请确保文件路径和名称正确。\")\n",
    "    print(f\"检查路径: \\n - {imc_file_path}\\n - {intraf_file_path}\")\n",
    "except KeyError as e:\n",
    "    print(f\"错误：在文件中找不到列 '{e}'。请检查文件中的列名是否为 '{paperid_col}' 和 '{imcp_col}'。\")\n",
    "except Exception as e:\n",
    "    print(f\"处理过程中发生意外错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据集大小: (11613323, 27)\n",
      "\n",
      "各变量缺失值情况:\n",
      "Log_Patent_Count: 缺失值=0, 无穷值=0\n",
      "Field_Eng: 缺失值=0, 无穷值=0\n",
      "Disruption: 缺失值=4711622, 无穷值=0\n",
      "IMCp: 缺失值=2497546, 无穷值=43895\n",
      "Log_C5: 缺失值=0, 无穷值=0\n",
      "Log_Team_size: 缺失值=0, 无穷值=0\n",
      "SB_T: 缺失值=7423844, 无穷值=0\n",
      "Log_Fund: 缺失值=0, 无穷值=0\n",
      "Field_CS: 缺失值=0, 无穷值=0\n",
      "Crisis: 缺失值=7816176, 无穷值=0\n",
      "SB_B: 缺失值=7423844, 无穷值=0\n",
      "Atyp_Median_Z: 缺失值=7816176, 无穷值=0\n",
      "\n",
      "开始执行回归分析 (模型 1-5, 使用 IMCp)...\n",
      "\n",
      "==================================================\n",
      "处理 Model 1: Disruption (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8431349\n",
      "处理后有效样本量: 3181974\n",
      "警告: VIF 计算检测到方差接近0的列: ['const']。可能影响VIF结果或导致错误。\n",
      "错误: 计算VIF时发生错误: Length of values (7) does not match length of index (8)\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0098\n",
      "  Adj R-squared: 0.0098\n",
      "  F-statistic: 4502.1327 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 2: Atyp_Median_Z (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8431349\n",
      "处理后有效样本量: 3181974\n",
      "警告: VIF 计算检测到方差接近0的列: ['const']。可能影响VIF结果或导致错误。\n",
      "错误: 计算VIF时发生错误: Length of values (7) does not match length of index (8)\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0376\n",
      "  Adj R-squared: 0.0376\n",
      "  F-statistic: 17753.9973 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 3: SB_B (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8600580\n",
      "处理后有效样本量: 3012743\n",
      "警告: VIF 计算检测到方差接近0的列: ['const']。可能影响VIF结果或导致错误。\n",
      "错误: 计算VIF时发生错误: Length of values (7) does not match length of index (8)\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0293\n",
      "  Adj R-squared: 0.0293\n",
      "  F-statistic: 12981.3706 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 4: SB_T (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8600580\n",
      "处理后有效样本量: 3012743\n",
      "警告: VIF 计算检测到方差接近0的列: ['const']。可能影响VIF结果或导致错误。\n",
      "错误: 计算VIF时发生错误: Length of values (7) does not match length of index (8)\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0754\n",
      "  Adj R-squared: 0.0754\n",
      "  F-statistic: 35079.6817 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 5: Log_C5 (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8431349\n",
      "处理后有效样本量: 3181974\n",
      "警告: VIF 计算检测到方差接近0的列: ['const']。可能影响VIF结果或导致错误。\n",
      "错误: 计算VIF时发生错误: Length of values (7) does not match length of index (8)\n",
      "回归结果摘要:\n",
      "  R-squared: 0.1233\n",
      "  Adj R-squared: 0.1233\n",
      "  F-statistic: 63945.5635 (p-value: 0.0000)\n",
      "\n",
      "回归结果已成功保存并格式化到 Regression_Results_IMCp_Models_1_to_5.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略警告信息\n",
    "\n",
    "# 读取TSV文件\n",
    "file_path = 'Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp.tsv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path, sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误: 文件 '{file_path}' 未找到。请确保文件路径正确。\")\n",
    "    exit(1)\n",
    "print(f\"原始数据集大小: {data.shape}\")\n",
    "\n",
    "# 定义因变量\n",
    "dependent_vars = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "\n",
    "# 定义一组自变量 (使用 IMCp 替换 InTraFlow，移除 Field_Eco)\n",
    "independent_vars = ['IMCp', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund',\n",
    "                    'Field_CS', 'Field_Eng','Crisis'] # 修改后的自变量\n",
    "\n",
    "# 检查列是否存在\n",
    "all_vars = list(set(dependent_vars + independent_vars)) # 更新使用的变量\n",
    "missing_cols = [col for col in all_vars if col not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\"错误: 以下列不存在于数据中: {missing_cols}\")\n",
    "    print(f\"可用的列: {data.columns.tolist()}\")\n",
    "    exit(1) # 如果关键列缺失则退出\n",
    "\n",
    "# 打印每个变量的基本信息\n",
    "print(\"\\n各变量缺失值情况:\")\n",
    "for col in all_vars:\n",
    "    if col in data.columns: # 再次确认列存在\n",
    "        na_count = data[col].isna().sum()\n",
    "        inf_count = np.isinf(data[col]).sum() if pd.api.types.is_numeric_dtype(data[col]) else 0\n",
    "        print(f\"{col}: 缺失值={na_count}, 无穷值={inf_count}\")\n",
    "    else:\n",
    "        # 理论上不应执行到这里，因为前面有检查\n",
    "        print(f\"{col}: 列不存在！\")\n",
    "\n",
    "\n",
    "# 执行回归分析并存储结果 (只执行前5个模型)\n",
    "results = []\n",
    "\n",
    "# 模型1-5: 使用 IMCp\n",
    "print(\"\\n开始执行回归分析 (模型 1-5, 使用 IMCp)...\")\n",
    "for i, dv in enumerate(dependent_vars):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理 Model {i+1}: {dv} (使用 IMCp)\")\n",
    "\n",
    "    # 为每个模型单独提取数据并处理缺失值\n",
    "    model_vars = [dv] + independent_vars\n",
    "    model_data = data[model_vars].copy()\n",
    "\n",
    "    # 打印处理前的样本量\n",
    "    print(f\"处理前样本量: {len(model_data)}\")\n",
    "\n",
    "    # 替换无穷值为NaN并删除缺失值\n",
    "    # 确保在替换前检查数据类型，避免对非数值列操作\n",
    "    numeric_cols = model_data.select_dtypes(include=np.number).columns\n",
    "    model_data[numeric_cols] = model_data[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    initial_rows = len(model_data)\n",
    "    model_data = model_data.dropna()\n",
    "    final_rows = len(model_data)\n",
    "    print(f\"因缺失值/无穷值移除的行数: {initial_rows - final_rows}\")\n",
    "    print(f\"处理后有效样本量: {final_rows}\")\n",
    "\n",
    "    if final_rows == 0:\n",
    "        print(f\"警告: Model {i+1} ({dv}) 清理后没有有效数据! 跳过此模型。\")\n",
    "        continue # 跳到下一个因变量\n",
    "\n",
    "    if final_rows < len(independent_vars) + 1: # 样本量少于变量数+1\n",
    "        print(f\"警告: Model {i+1} ({dv}) 的有效样本量 ({final_rows}) 过少，无法进行回归。跳过此模型。\")\n",
    "        continue\n",
    "\n",
    "    # 检查多重共线性\n",
    "    try:\n",
    "        # 确保只对数值型自变量计算VIF（分类变量如Field_XX通常排除或特殊处理）\n",
    "        # 这里假设 Field_CS, Field_Eng, Crisis 是 0/1 编码，可以包含\n",
    "        X_check_df = model_data[independent_vars]\n",
    "        # 检查是否存在非数值类型，理论上前面已过滤，但以防万一\n",
    "        if X_check_df.select_dtypes(exclude=np.number).shape[1] > 0:\n",
    "             print(\"警告：VIF 检查包含非数值列，可能导致错误。\")\n",
    "\n",
    "        X_check = sm.add_constant(X_check_df)\n",
    "        vif_data = pd.DataFrame()\n",
    "        vif_data[\"Variable\"] = X_check.columns\n",
    "        # 检查是否存在方差为0的列（常数或近似常数列），这会导致VIF计算错误\n",
    "        non_constant_cols_mask = X_check.var() > 1e-8 # 允许非常小的方差\n",
    "        if not non_constant_cols_mask.all():\n",
    "            constant_vars = X_check.columns[~non_constant_cols_mask].tolist()\n",
    "            print(f\"警告: VIF 计算检测到方差接近0的列: {constant_vars}。可能影响VIF结果或导致错误。\")\n",
    "            # 选择性地只计算非恒定列的VIF，或者在这里停止并报告问题\n",
    "            # 为了继续，我们只计算有方差的列\n",
    "            X_check_filtered = X_check.loc[:, non_constant_cols_mask]\n",
    "            if X_check_filtered.shape[1] > 1: # 至少需要两列才能计算VIF\n",
    "                 vif_data[\"VIF\"] = [variance_inflation_factor(X_check_filtered.values, j)\n",
    "                                   for j in range(X_check_filtered.shape[1])]\n",
    "                 vif_data[\"Variable\"] = X_check_filtered.columns # 更新变量名以匹配\n",
    "                 print(\"VIF值 (多重共线性检测，已移除零方差列):\")\n",
    "                 print(vif_data)\n",
    "            else:\n",
    "                 print(\"警告: 移除零方差列后，剩余变量不足以计算VIF。\")\n",
    "\n",
    "        else: # 所有列都有足够的方差\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(X_check.values, j)\n",
    "                               for j in range(X_check.shape[1])]\n",
    "            print(\"VIF值 (多重共线性检测):\")\n",
    "            print(vif_data)\n",
    "            high_vif = vif_data[vif_data['VIF'] > 10] # 检查高VIF值\n",
    "            if not high_vif.empty:\n",
    "                print(\"\\n警告: 检测到高VIF值 (>10)，可能存在多重共线性问题:\")\n",
    "                print(high_vif)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 计算VIF时发生错误: {e}\")\n",
    "        # 可以在这里选择继续执行回归或跳过\n",
    "\n",
    "    # 执行OLS回归\n",
    "    y = model_data[dv]\n",
    "    X = sm.add_constant(model_data[independent_vars])\n",
    "    try:\n",
    "        model = sm.OLS(y, X).fit()\n",
    "\n",
    "        # 输出基本回归结果\n",
    "        print(f\"回归结果摘要:\")\n",
    "        print(f\"  R-squared: {model.rsquared:.4f}\")\n",
    "        print(f\"  Adj R-squared: {model.rsquared_adj:.4f}\")\n",
    "        print(f\"  F-statistic: {model.fvalue:.4f} (p-value: {model.f_pvalue:.4f})\")\n",
    "\n",
    "        # 提取结果\n",
    "        result = {\n",
    "            'Model': f\"Model {i+1}\",\n",
    "            'DV': dv,\n",
    "            'IV': 'IMCp', # 明确记录主要自变量\n",
    "            'Coefficients': model.params,\n",
    "            'P_values': model.pvalues,\n",
    "            'Std_Errors': model.bse,\n",
    "            'R_squared': model.rsquared,\n",
    "            'Adj_R_squared': model.rsquared_adj,\n",
    "            'F_statistic': model.fvalue,\n",
    "            'F_pvalue': model.f_pvalue,\n",
    "            'N': model.nobs\n",
    "        }\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 执行OLS回归时发生错误 for Model {i+1} ({dv}): {e}\")\n",
    "        print(\"可能的原因包括完全共线性（perfect multicollinearity）或数据问题。\")\n",
    "        continue # 跳到下一个模型\n",
    "\n",
    "# 检查是否有任何结果生成\n",
    "if not results:\n",
    "    print(\"\\n错误：没有成功生成任何模型结果。无法创建Excel文件。\")\n",
    "    exit(1)\n",
    "\n",
    "# --- 创建结果DataFrame ---\n",
    "output_file = 'Regression_Results_IMCp_Models_1_to_5.xlsx' # 修改输出文件名\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 添加变量名 (使用更新后的自变量列表)\n",
    "var_names_display = ['Constant'] + independent_vars[1:] # 除了第一个自变量外的所有变量\n",
    "result_df['Variable'] = ['IMCp'] + var_names_display + ['', 'Observations', 'R-squared', 'Adjusted R-squared', 'F-statistic', 'Prob > F']\n",
    "\n",
    "# 添加每个模型的结果\n",
    "for result in results:\n",
    "    model_col = []\n",
    "\n",
    "    # 自变量列表 (现在只有一种)\n",
    "    iv_vars_in_model = ['IMCp'] + independent_vars[1:] # 确保顺序与模型一致\n",
    "\n",
    "    # 添加系数和标准误\n",
    "    # 确保我们按正确的顺序添加：截距(const) -> IMCp -> 其他自变量\n",
    "    var_order_for_output = ['const'] + iv_vars_in_model\n",
    "\n",
    "    for var in var_order_for_output:\n",
    "        # 检查变量是否存在于模型结果中，以防万一（例如，如果某个变量因共线性被移除）\n",
    "        if var in result['Coefficients']:\n",
    "            coef = result['Coefficients'][var]\n",
    "            stderr = result['Std_Errors'][var]\n",
    "            pval = result['P_values'][var]\n",
    "\n",
    "            # 添加显著性星号\n",
    "            stars = ''\n",
    "            if pval < 0.01: stars = '***'\n",
    "            elif pval < 0.05: stars = '**'\n",
    "            elif pval < 0.1: stars = '*'\n",
    "\n",
    "            # 格式化系数和标准误\n",
    "            model_col.append(f\"{coef:.3f}{stars}\\n({stderr:.3f})\")\n",
    "        else:\n",
    "             model_col.append(\"N/A\") # 如果变量不在模型中（不太可能除非有错误）\n",
    "\n",
    "    # 添加空行和统计量\n",
    "    model_col.append('') # 空行\n",
    "    model_col.append(f\"{int(result['N'])}\")\n",
    "    model_col.append(f\"{result['R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['Adj_R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['F_statistic']:.3f}\")\n",
    "    # 对于非常小的p值，使用科学记数法或更小的阈值\n",
    "    f_pvalue_str = f\"{result['F_pvalue']:.6f}\"\n",
    "    if result['F_pvalue'] < 0.000001 and result['F_pvalue'] > 0:\n",
    "        f_pvalue_str = \"<0.000001\"\n",
    "    elif result['F_pvalue'] == 0: # 处理精确的0\n",
    "        f_pvalue_str = \"0.000000\"\n",
    "\n",
    "    model_col.append(f_pvalue_str)\n",
    "\n",
    "    # 添加到结果DataFrame\n",
    "    result_df[f\"Model {result['Model'].split()[1]}\\n{result['DV']}\"] = model_col\n",
    "\n",
    "# --- 保存到Excel ---\n",
    "try:\n",
    "    result_df.to_excel(output_file, sheet_name='Regression Results', index=False)\n",
    "except Exception as e:\n",
    "     print(f\"错误: 保存Excel文件 '{output_file}' 时失败: {e}\")\n",
    "     exit(1)\n",
    "\n",
    "\n",
    "# --- 格式化Excel文件 ---\n",
    "try:\n",
    "    wb = load_workbook(output_file)\n",
    "    ws = wb['Regression Results']\n",
    "\n",
    "    # 设置列宽和样式\n",
    "    for col in ws.columns:\n",
    "        column = col[0].column_letter\n",
    "        max_length = 0\n",
    "        for cell in col:\n",
    "             try: # 防止对NoneType调用len\n",
    "                 cell_str = str(cell.value)\n",
    "                 # 处理包含换行符的单元格\n",
    "                 lines = cell_str.split('\\n')\n",
    "                 cell_max_len = max(len(line) for line in lines) if lines else 0\n",
    "                 if cell_max_len > max_length:\n",
    "                     max_length = cell_max_len\n",
    "             except:\n",
    "                 pass\n",
    "        adjusted_width = max(max_length + 4, 15) # 增加一点边距，最小宽度15\n",
    "        ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "    # 设置样式\n",
    "    header_font = Font(bold=True)\n",
    "    align_center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "    align_left = Alignment(horizontal='left', vertical='center', wrap_text=True)\n",
    "    border = Border(left=Side(style='thin'), right=Side(style='thin'),\n",
    "                    top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "    # 应用样式\n",
    "    for row_idx, row in enumerate(ws.rows, 1):\n",
    "        for col_idx, cell in enumerate(row, 1):\n",
    "            cell.border = border\n",
    "\n",
    "            if row_idx == 1:  # 标题行\n",
    "                cell.font = header_font\n",
    "                cell.alignment = align_center\n",
    "            else:\n",
    "                if col_idx == 1:  # 变量名列\n",
    "                    cell.alignment = align_left\n",
    "                else:\n",
    "                    cell.alignment = align_center\n",
    "\n",
    "    # 添加注释说明星号的含义\n",
    "    footnote_row = ws.max_row + 2\n",
    "    ws.cell(row=footnote_row, column=1, value=\"注: *** p<0.01, ** p<0.05, * p<0.1，括号内为标准误\")\n",
    "    # (移除了关于模型6-10的注释)\n",
    "\n",
    "    # 保存格式化后的Excel\n",
    "    wb.save(output_file)\n",
    "\n",
    "    print(f\"\\n回归结果已成功保存并格式化到 {output_file}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "     print(f\"错误: 无法加载 '{output_file}' 进行格式化。文件可能未成功创建。\")\n",
    "except Exception as e:\n",
    "     print(f\"错误: 格式化Excel文件时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告: 无法获取脚本目录 (__file__未定义)，将使用当前工作目录。\n",
      "输入文件路径: d:\\BaiduNetdiskDownload\\SciSci\\2-IMC Calculate\\3 filed cited_citing\\Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp.tsv\n",
      "输出文件路径: d:\\BaiduNetdiskDownload\\SciSci\\2-IMC Calculate\\3 filed cited_citing\\Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp_with_product.tsv\n",
      "将要相乘的列: 'C_f' 和 'IMCp'\n",
      "新列名称: 'C_f_x_IMCp'\n",
      "\n",
      "正在读取文件: Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp.tsv ...\n",
      "文件读取成功. 数据形状: (11613323, 27)\n",
      "列 'C_f' 和 'IMCp' 均已找到。\n",
      "\n",
      "正在计算 'C_f' * 'IMCp' ...\n",
      "警告: 列 'C_f' 中发现 3 个非数值，已转换为 NaN。\n",
      "警告: 列 'IMCp' 中发现 2497546 个非数值，已转换为 NaN。\n",
      "新列 'C_f_x_IMCp' 已成功创建。\n",
      "\n",
      "正在将结果保存到文件: Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp_with_product.tsv ...\n",
      "文件已成功保存到: d:\\BaiduNetdiskDownload\\SciSci\\2-IMC Calculate\\3 filed cited_citing\\Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp_with_product.tsv\n",
      "新文件数据形状: (11613323, 28)\n",
      "\n",
      "脚本执行完毕。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np # Import numpy for NaN handling if needed\n",
    "\n",
    "# --- Configuration ---\n",
    "input_file_name = 'Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp.tsv'\n",
    "col1_name = 'C_f'\n",
    "col2_name = 'IMCp'\n",
    "product_col_name = 'C_f_x_IMCp' # Name for the new column\n",
    "\n",
    "# --- Get File Paths ---\n",
    "# THIS PART IS KEY: It assumes the script and file are in the same directory\n",
    "try:\n",
    "    # Gets the directory where the script is located\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "     # If running interactively (like in Jupyter or Python console),\n",
    "     # __file__ might not be defined. Assume current working directory.\n",
    "     script_dir = os.getcwd()\n",
    "     print(\"警告: 无法获取脚本目录 (__file__未定义)，将使用当前工作目录。\")\n",
    "\n",
    "# Builds the full path by joining the directory and the filename\n",
    "input_file_path = os.path.join(script_dir, input_file_name)\n",
    "\n",
    "# Construct the output file path in the same directory\n",
    "base_name, ext = os.path.splitext(input_file_name)\n",
    "output_file_name = f\"{base_name}_with_product{ext}\"\n",
    "output_file_path = os.path.join(script_dir, output_file_name) # Output will also be here\n",
    "\n",
    "print(f\"输入文件路径: {input_file_path}\")\n",
    "print(f\"输出文件路径: {output_file_path}\")\n",
    "print(f\"将要相乘的列: '{col1_name}' 和 '{col2_name}'\")\n",
    "print(f\"新列名称: '{product_col_name}'\")\n",
    "\n",
    "# --- Read the Input File ---\n",
    "try:\n",
    "    print(f\"\\n正在读取文件: {input_file_name} ...\")\n",
    "    # Because input_file_path is built correctly, pandas finds the file\n",
    "    data = pd.read_csv(input_file_path, sep='\\t')\n",
    "    print(f\"文件读取成功. 数据形状: {data.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误: 输入文件 '{input_file_path}' 未找到。请再次确认文件名和位置。\")\n",
    "    exit(1) # Exit if the file doesn't exist\n",
    "except Exception as e:\n",
    "    print(f\"错误: 读取文件时发生意外错误: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# --- Check if Columns Exist ---\n",
    "if col1_name not in data.columns:\n",
    "    print(f\"错误: 列 '{col1_name}' 不存在于文件中。可用的列: {data.columns.tolist()}\")\n",
    "    exit(1)\n",
    "if col2_name not in data.columns:\n",
    "    print(f\"错误: 列 '{col2_name}' 不存在于文件中。可用的列: {data.columns.tolist()}\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"列 '{col1_name}' 和 '{col2_name}' 均已找到。\")\n",
    "\n",
    "# --- Perform Multiplication ---\n",
    "print(f\"\\n正在计算 '{col1_name}' * '{col2_name}' ...\")\n",
    "\n",
    "# Optional: Handle potential non-numeric data or NaNs before multiplication\n",
    "data[col1_name] = pd.to_numeric(data[col1_name], errors='coerce')\n",
    "data[col2_name] = pd.to_numeric(data[col2_name], errors='coerce')\n",
    "\n",
    "# Check if any values were turned into NaN during conversion\n",
    "nan_count1 = data[col1_name].isna().sum()\n",
    "nan_count2 = data[col2_name].isna().sum()\n",
    "if nan_count1 > 0:\n",
    "    print(f\"警告: 列 '{col1_name}' 中发现 {nan_count1} 个非数值，已转换为 NaN。\")\n",
    "if nan_count2 > 0:\n",
    "    print(f\"警告: 列 '{col2_name}' 中发现 {nan_count2} 个非数值，已转换为 NaN。\")\n",
    "\n",
    "# Perform the element-wise multiplication\n",
    "data[product_col_name] = data[col1_name] * data[col2_name]\n",
    "\n",
    "print(f\"新列 '{product_col_name}' 已成功创建。\")\n",
    "\n",
    "# --- Save the New File ---\n",
    "try:\n",
    "    print(f\"\\n正在将结果保存到文件: {output_file_name} ...\")\n",
    "    # The output_file_path is also in the same directory\n",
    "    data.to_csv(output_file_path, sep='\\t', index=False)\n",
    "    print(f\"文件已成功保存到: {output_file_path}\")\n",
    "    print(f\"新文件数据形状: {data.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"错误: 保存文件时发生错误: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"\\n脚本执行完毕。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据集大小: (11613323, 28)\n",
      "\n",
      "各变量缺失值情况:\n",
      "Log_Patent_Count: 缺失值=0, 无穷值=0\n",
      "Field_Eng: 缺失值=0, 无穷值=0\n",
      "Disruption: 缺失值=4711622, 无穷值=0\n",
      "Log_C5: 缺失值=0, 无穷值=0\n",
      "Log_Team_size: 缺失值=0, 无穷值=0\n",
      "SB_T: 缺失值=7423844, 无穷值=0\n",
      "Log_Fund: 缺失值=0, 无穷值=0\n",
      "Field_CS: 缺失值=0, 无穷值=0\n",
      "Crisis: 缺失值=7816176, 无穷值=0\n",
      "SB_B: 缺失值=7423844, 无穷值=0\n",
      "C_f_x_IMCp: 缺失值=2497549, 无穷值=43895\n",
      "Atyp_Median_Z: 缺失值=7816176, 无穷值=0\n",
      "\n",
      "开始执行回归分析 (模型 1-5, 使用 IMCp)...\n",
      "\n",
      "==================================================\n",
      "处理 Model 1: Disruption (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8431349\n",
      "处理后有效样本量: 3181974\n",
      "警告: VIF 计算检测到方差接近0的列: ['const']。可能影响VIF结果或导致错误。\n",
      "错误: 计算VIF时发生错误: Length of values (7) does not match length of index (8)\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0102\n",
      "  Adj R-squared: 0.0102\n",
      "  F-statistic: 4667.4893 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 2: Atyp_Median_Z (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8431349\n",
      "处理后有效样本量: 3181974\n",
      "警告: VIF 计算检测到方差接近0的列: ['const']。可能影响VIF结果或导致错误。\n",
      "错误: 计算VIF时发生错误: Length of values (7) does not match length of index (8)\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0374\n",
      "  Adj R-squared: 0.0374\n",
      "  F-statistic: 17654.1209 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 3: SB_B (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8600580\n",
      "处理后有效样本量: 3012743\n",
      "警告: VIF 计算检测到方差接近0的列: ['const']。可能影响VIF结果或导致错误。\n",
      "错误: 计算VIF时发生错误: Length of values (7) does not match length of index (8)\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0290\n",
      "  Adj R-squared: 0.0290\n",
      "  F-statistic: 12859.9621 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 4: SB_T (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8600580\n",
      "处理后有效样本量: 3012743\n",
      "警告: VIF 计算检测到方差接近0的列: ['const']。可能影响VIF结果或导致错误。\n",
      "错误: 计算VIF时发生错误: Length of values (7) does not match length of index (8)\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0755\n",
      "  Adj R-squared: 0.0755\n",
      "  F-statistic: 35150.5741 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 5: Log_C5 (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8431349\n",
      "处理后有效样本量: 3181974\n",
      "警告: VIF 计算检测到方差接近0的列: ['const']。可能影响VIF结果或导致错误。\n",
      "错误: 计算VIF时发生错误: Length of values (7) does not match length of index (8)\n",
      "回归结果摘要:\n",
      "  R-squared: 0.1138\n",
      "  Adj R-squared: 0.1138\n",
      "  F-statistic: 58372.4494 (p-value: 0.0000)\n",
      "\n",
      "回归结果已成功保存并格式化到 Regression_Results_IMCp_Models_1_to_5.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略警告信息\n",
    "\n",
    "# 读取TSV文件\n",
    "file_path = 'Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp_with_product.tsv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path, sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误: 文件 '{file_path}' 未找到。请确保文件路径正确。\")\n",
    "    exit(1)\n",
    "print(f\"原始数据集大小: {data.shape}\")\n",
    "\n",
    "# 定义因变量\n",
    "dependent_vars = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "\n",
    "# 定义一组自变量 (使用 IMCp 替换 InTraFlow，移除 Field_Eco)\n",
    "independent_vars = ['C_f_x_IMCp', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund',\n",
    "                    'Field_CS', 'Field_Eng','Crisis'] # 修改后的自变量\n",
    "\n",
    "# 检查列是否存在\n",
    "all_vars = list(set(dependent_vars + independent_vars)) # 更新使用的变量\n",
    "missing_cols = [col for col in all_vars if col not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\"错误: 以下列不存在于数据中: {missing_cols}\")\n",
    "    print(f\"可用的列: {data.columns.tolist()}\")\n",
    "    exit(1) # 如果关键列缺失则退出\n",
    "\n",
    "# 打印每个变量的基本信息\n",
    "print(\"\\n各变量缺失值情况:\")\n",
    "for col in all_vars:\n",
    "    if col in data.columns: # 再次确认列存在\n",
    "        na_count = data[col].isna().sum()\n",
    "        inf_count = np.isinf(data[col]).sum() if pd.api.types.is_numeric_dtype(data[col]) else 0\n",
    "        print(f\"{col}: 缺失值={na_count}, 无穷值={inf_count}\")\n",
    "    else:\n",
    "        # 理论上不应执行到这里，因为前面有检查\n",
    "        print(f\"{col}: 列不存在！\")\n",
    "\n",
    "\n",
    "# 执行回归分析并存储结果 (只执行前5个模型)\n",
    "results = []\n",
    "\n",
    "# 模型1-5: 使用 IMCp\n",
    "print(\"\\n开始执行回归分析 (模型 1-5, 使用 IMCp)...\")\n",
    "for i, dv in enumerate(dependent_vars):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理 Model {i+1}: {dv} (使用 IMCp)\")\n",
    "\n",
    "    # 为每个模型单独提取数据并处理缺失值\n",
    "    model_vars = [dv] + independent_vars\n",
    "    model_data = data[model_vars].copy()\n",
    "\n",
    "    # 打印处理前的样本量\n",
    "    print(f\"处理前样本量: {len(model_data)}\")\n",
    "\n",
    "    # 替换无穷值为NaN并删除缺失值\n",
    "    # 确保在替换前检查数据类型，避免对非数值列操作\n",
    "    numeric_cols = model_data.select_dtypes(include=np.number).columns\n",
    "    model_data[numeric_cols] = model_data[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    initial_rows = len(model_data)\n",
    "    model_data = model_data.dropna()\n",
    "    final_rows = len(model_data)\n",
    "    print(f\"因缺失值/无穷值移除的行数: {initial_rows - final_rows}\")\n",
    "    print(f\"处理后有效样本量: {final_rows}\")\n",
    "\n",
    "    if final_rows == 0:\n",
    "        print(f\"警告: Model {i+1} ({dv}) 清理后没有有效数据! 跳过此模型。\")\n",
    "        continue # 跳到下一个因变量\n",
    "\n",
    "    if final_rows < len(independent_vars) + 1: # 样本量少于变量数+1\n",
    "        print(f\"警告: Model {i+1} ({dv}) 的有效样本量 ({final_rows}) 过少，无法进行回归。跳过此模型。\")\n",
    "        continue\n",
    "\n",
    "    # 检查多重共线性\n",
    "    try:\n",
    "        # 确保只对数值型自变量计算VIF（分类变量如Field_XX通常排除或特殊处理）\n",
    "        # 这里假设 Field_CS, Field_Eng, Crisis 是 0/1 编码，可以包含\n",
    "        X_check_df = model_data[independent_vars]\n",
    "        # 检查是否存在非数值类型，理论上前面已过滤，但以防万一\n",
    "        if X_check_df.select_dtypes(exclude=np.number).shape[1] > 0:\n",
    "             print(\"警告：VIF 检查包含非数值列，可能导致错误。\")\n",
    "\n",
    "        X_check = sm.add_constant(X_check_df)\n",
    "        vif_data = pd.DataFrame()\n",
    "        vif_data[\"Variable\"] = X_check.columns\n",
    "        # 检查是否存在方差为0的列（常数或近似常数列），这会导致VIF计算错误\n",
    "        non_constant_cols_mask = X_check.var() > 1e-8 # 允许非常小的方差\n",
    "        if not non_constant_cols_mask.all():\n",
    "            constant_vars = X_check.columns[~non_constant_cols_mask].tolist()\n",
    "            print(f\"警告: VIF 计算检测到方差接近0的列: {constant_vars}。可能影响VIF结果或导致错误。\")\n",
    "            # 选择性地只计算非恒定列的VIF，或者在这里停止并报告问题\n",
    "            # 为了继续，我们只计算有方差的列\n",
    "            X_check_filtered = X_check.loc[:, non_constant_cols_mask]\n",
    "            if X_check_filtered.shape[1] > 1: # 至少需要两列才能计算VIF\n",
    "                 vif_data[\"VIF\"] = [variance_inflation_factor(X_check_filtered.values, j)\n",
    "                                   for j in range(X_check_filtered.shape[1])]\n",
    "                 vif_data[\"Variable\"] = X_check_filtered.columns # 更新变量名以匹配\n",
    "                 print(\"VIF值 (多重共线性检测，已移除零方差列):\")\n",
    "                 print(vif_data)\n",
    "            else:\n",
    "                 print(\"警告: 移除零方差列后，剩余变量不足以计算VIF。\")\n",
    "\n",
    "        else: # 所有列都有足够的方差\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(X_check.values, j)\n",
    "                               for j in range(X_check.shape[1])]\n",
    "            print(\"VIF值 (多重共线性检测):\")\n",
    "            print(vif_data)\n",
    "            high_vif = vif_data[vif_data['VIF'] > 10] # 检查高VIF值\n",
    "            if not high_vif.empty:\n",
    "                print(\"\\n警告: 检测到高VIF值 (>10)，可能存在多重共线性问题:\")\n",
    "                print(high_vif)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 计算VIF时发生错误: {e}\")\n",
    "        # 可以在这里选择继续执行回归或跳过\n",
    "\n",
    "    # 执行OLS回归\n",
    "    y = model_data[dv]\n",
    "    X = sm.add_constant(model_data[independent_vars])\n",
    "    try:\n",
    "        model = sm.OLS(y, X).fit()\n",
    "\n",
    "        # 输出基本回归结果\n",
    "        print(f\"回归结果摘要:\")\n",
    "        print(f\"  R-squared: {model.rsquared:.4f}\")\n",
    "        print(f\"  Adj R-squared: {model.rsquared_adj:.4f}\")\n",
    "        print(f\"  F-statistic: {model.fvalue:.4f} (p-value: {model.f_pvalue:.4f})\")\n",
    "\n",
    "        # 提取结果\n",
    "        result = {\n",
    "            'Model': f\"Model {i+1}\",\n",
    "            'DV': dv,\n",
    "            'IV': 'IMCp', # 明确记录主要自变量\n",
    "            'Coefficients': model.params,\n",
    "            'P_values': model.pvalues,\n",
    "            'Std_Errors': model.bse,\n",
    "            'R_squared': model.rsquared,\n",
    "            'Adj_R_squared': model.rsquared_adj,\n",
    "            'F_statistic': model.fvalue,\n",
    "            'F_pvalue': model.f_pvalue,\n",
    "            'N': model.nobs\n",
    "        }\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 执行OLS回归时发生错误 for Model {i+1} ({dv}): {e}\")\n",
    "        print(\"可能的原因包括完全共线性（perfect multicollinearity）或数据问题。\")\n",
    "        continue # 跳到下一个模型\n",
    "\n",
    "# 检查是否有任何结果生成\n",
    "if not results:\n",
    "    print(\"\\n错误：没有成功生成任何模型结果。无法创建Excel文件。\")\n",
    "    exit(1)\n",
    "\n",
    "# --- 创建结果DataFrame ---\n",
    "output_file = 'Regression_Results_IMCp_Models_1_to_5.xlsx' # 修改输出文件名\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 添加变量名 (使用更新后的自变量列表)\n",
    "var_names_display = ['Constant'] + independent_vars[1:] # 除了第一个自变量外的所有变量\n",
    "result_df['Variable'] = ['IMCp'] + var_names_display + ['', 'Observations', 'R-squared', 'Adjusted R-squared', 'F-statistic', 'Prob > F']\n",
    "\n",
    "# 添加每个模型的结果\n",
    "for result in results:\n",
    "    model_col = []\n",
    "\n",
    "    # 自变量列表 (现在只有一种)\n",
    "    iv_vars_in_model = ['IMCp'] + independent_vars[1:] # 确保顺序与模型一致\n",
    "\n",
    "    # 添加系数和标准误\n",
    "    # 确保我们按正确的顺序添加：截距(const) -> IMCp -> 其他自变量\n",
    "    var_order_for_output = ['const'] + iv_vars_in_model\n",
    "\n",
    "    for var in var_order_for_output:\n",
    "        # 检查变量是否存在于模型结果中，以防万一（例如，如果某个变量因共线性被移除）\n",
    "        if var in result['Coefficients']:\n",
    "            coef = result['Coefficients'][var]\n",
    "            stderr = result['Std_Errors'][var]\n",
    "            pval = result['P_values'][var]\n",
    "\n",
    "            # 添加显著性星号\n",
    "            stars = ''\n",
    "            if pval < 0.01: stars = '***'\n",
    "            elif pval < 0.05: stars = '**'\n",
    "            elif pval < 0.1: stars = '*'\n",
    "\n",
    "            # 格式化系数和标准误\n",
    "            model_col.append(f\"{coef:.3f}{stars}\\n({stderr:.3f})\")\n",
    "        else:\n",
    "             model_col.append(\"N/A\") # 如果变量不在模型中（不太可能除非有错误）\n",
    "\n",
    "    # 添加空行和统计量\n",
    "    model_col.append('') # 空行\n",
    "    model_col.append(f\"{int(result['N'])}\")\n",
    "    model_col.append(f\"{result['R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['Adj_R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['F_statistic']:.3f}\")\n",
    "    # 对于非常小的p值，使用科学记数法或更小的阈值\n",
    "    f_pvalue_str = f\"{result['F_pvalue']:.6f}\"\n",
    "    if result['F_pvalue'] < 0.000001 and result['F_pvalue'] > 0:\n",
    "        f_pvalue_str = \"<0.000001\"\n",
    "    elif result['F_pvalue'] == 0: # 处理精确的0\n",
    "        f_pvalue_str = \"0.000000\"\n",
    "\n",
    "    model_col.append(f_pvalue_str)\n",
    "\n",
    "    # 添加到结果DataFrame\n",
    "    result_df[f\"Model {result['Model'].split()[1]}\\n{result['DV']}\"] = model_col\n",
    "\n",
    "# --- 保存到Excel ---\n",
    "try:\n",
    "    result_df.to_excel(output_file, sheet_name='Regression Results', index=False)\n",
    "except Exception as e:\n",
    "     print(f\"错误: 保存Excel文件 '{output_file}' 时失败: {e}\")\n",
    "     exit(1)\n",
    "\n",
    "\n",
    "# --- 格式化Excel文件 ---\n",
    "try:\n",
    "    wb = load_workbook(output_file)\n",
    "    ws = wb['Regression Results']\n",
    "\n",
    "    # 设置列宽和样式\n",
    "    for col in ws.columns:\n",
    "        column = col[0].column_letter\n",
    "        max_length = 0\n",
    "        for cell in col:\n",
    "             try: # 防止对NoneType调用len\n",
    "                 cell_str = str(cell.value)\n",
    "                 # 处理包含换行符的单元格\n",
    "                 lines = cell_str.split('\\n')\n",
    "                 cell_max_len = max(len(line) for line in lines) if lines else 0\n",
    "                 if cell_max_len > max_length:\n",
    "                     max_length = cell_max_len\n",
    "             except:\n",
    "                 pass\n",
    "        adjusted_width = max(max_length + 4, 15) # 增加一点边距，最小宽度15\n",
    "        ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "    # 设置样式\n",
    "    header_font = Font(bold=True)\n",
    "    align_center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "    align_left = Alignment(horizontal='left', vertical='center', wrap_text=True)\n",
    "    border = Border(left=Side(style='thin'), right=Side(style='thin'),\n",
    "                    top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "    # 应用样式\n",
    "    for row_idx, row in enumerate(ws.rows, 1):\n",
    "        for col_idx, cell in enumerate(row, 1):\n",
    "            cell.border = border\n",
    "\n",
    "            if row_idx == 1:  # 标题行\n",
    "                cell.font = header_font\n",
    "                cell.alignment = align_center\n",
    "            else:\n",
    "                if col_idx == 1:  # 变量名列\n",
    "                    cell.alignment = align_left\n",
    "                else:\n",
    "                    cell.alignment = align_center\n",
    "\n",
    "    # 添加注释说明星号的含义\n",
    "    footnote_row = ws.max_row + 2\n",
    "    ws.cell(row=footnote_row, column=1, value=\"注: *** p<0.01, ** p<0.05, * p<0.1，括号内为标准误\")\n",
    "    # (移除了关于模型6-10的注释)\n",
    "\n",
    "    # 保存格式化后的Excel\n",
    "    wb.save(output_file)\n",
    "\n",
    "    print(f\"\\n回归结果已成功保存并格式化到 {output_file}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "     print(f\"错误: 无法加载 '{output_file}' 进行格式化。文件可能未成功创建。\")\n",
    "except Exception as e:\n",
    "     print(f\"错误: 格式化Excel文件时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据集大小: (11613323, 28)\n",
      "\n",
      "各变量缺失值情况:\n",
      "Log_Patent_Count: 缺失值=0, 无穷值=0\n",
      "Field_Eng: 缺失值=0, 无穷值=0\n",
      "Disruption: 缺失值=4711622, 无穷值=0\n",
      "Log_C5: 缺失值=0, 无穷值=0\n",
      "Log_Team_size: 缺失值=0, 无穷值=0\n",
      "SB_T: 缺失值=7423844, 无穷值=0\n",
      "Log_Fund: 缺失值=0, 无穷值=0\n",
      "Field_CS: 缺失值=0, 无穷值=0\n",
      "Crisis: 缺失值=7816176, 无穷值=0\n",
      "SB_B: 缺失值=7423844, 无穷值=0\n",
      "C_f_x_IMCp: 缺失值=2497549, 无穷值=43895\n",
      "Atyp_Median_Z: 缺失值=7816176, 无穷值=0\n",
      "\n",
      "开始执行回归分析 (模型 1-5, 使用 IMCp)...\n",
      "\n",
      "==================================================\n",
      "处理 Model 1: Disruption (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8431349\n",
      "处理后有效样本量: 3181974\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable       VIF\n",
      "0        C_f_x_IMCp  1.011782\n",
      "1     Log_Team_size  5.380594\n",
      "2  Log_Patent_Count  1.072552\n",
      "3          Log_Fund  1.053667\n",
      "4          Field_CS  4.064786\n",
      "5         Field_Eng  2.313091\n",
      "6            Crisis  1.477265\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0102\n",
      "  Adj R-squared: 0.0102\n",
      "  F-statistic: 4667.4893 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 2: Atyp_Median_Z (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8431349\n",
      "处理后有效样本量: 3181974\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable       VIF\n",
      "0        C_f_x_IMCp  1.011782\n",
      "1     Log_Team_size  5.380594\n",
      "2  Log_Patent_Count  1.072552\n",
      "3          Log_Fund  1.053667\n",
      "4          Field_CS  4.064786\n",
      "5         Field_Eng  2.313091\n",
      "6            Crisis  1.477265\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0374\n",
      "  Adj R-squared: 0.0374\n",
      "  F-statistic: 17654.1209 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 3: SB_B (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8600580\n",
      "处理后有效样本量: 3012743\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable       VIF\n",
      "0        C_f_x_IMCp  1.012154\n",
      "1     Log_Team_size  5.328054\n",
      "2  Log_Patent_Count  1.075420\n",
      "3          Log_Fund  1.054969\n",
      "4          Field_CS  3.998400\n",
      "5         Field_Eng  2.319186\n",
      "6            Crisis  1.465959\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0290\n",
      "  Adj R-squared: 0.0290\n",
      "  F-statistic: 12859.9621 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 4: SB_T (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8600580\n",
      "处理后有效样本量: 3012743\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable       VIF\n",
      "0        C_f_x_IMCp  1.012154\n",
      "1     Log_Team_size  5.328054\n",
      "2  Log_Patent_Count  1.075420\n",
      "3          Log_Fund  1.054969\n",
      "4          Field_CS  3.998400\n",
      "5         Field_Eng  2.319186\n",
      "6            Crisis  1.465959\n",
      "回归结果摘要:\n",
      "  R-squared: 0.0755\n",
      "  Adj R-squared: 0.0755\n",
      "  F-statistic: 35150.5741 (p-value: 0.0000)\n",
      "\n",
      "==================================================\n",
      "处理 Model 5: Log_C5 (使用 IMCp)\n",
      "处理前样本量: 11613323\n",
      "因缺失值/无穷值移除的行数: 8431349\n",
      "处理后有效样本量: 3181974\n",
      "VIF值 (多重共线性检测):\n",
      "           Variable       VIF\n",
      "0        C_f_x_IMCp  1.011782\n",
      "1     Log_Team_size  5.380594\n",
      "2  Log_Patent_Count  1.072552\n",
      "3          Log_Fund  1.053667\n",
      "4          Field_CS  4.064786\n",
      "5         Field_Eng  2.313091\n",
      "6            Crisis  1.477265\n",
      "回归结果摘要:\n",
      "  R-squared: 0.1138\n",
      "  Adj R-squared: 0.1138\n",
      "  F-statistic: 58372.4494 (p-value: 0.0000)\n",
      "\n",
      "初步结果已保存到 Regression_Results_IMCp_Models_1_to_5.xlsx\n",
      "回归结果已成功保存并格式化到 Regression_Results_IMCp_Models_1_to_5.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略警告信息\n",
    "\n",
    "# 读取TSV文件\n",
    "file_path = 'Merged_InTraFlow_CareerYear_Crisis_SingleMatch_Deduplicated_with_IMCp_with_product.tsv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path, sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误: 文件 '{file_path}' 未找到。请确保文件路径正确。\")\n",
    "    exit(1)\n",
    "print(f\"原始数据集大小: {data.shape}\")\n",
    "\n",
    "# 定义因变量\n",
    "dependent_vars = ['Disruption', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Log_C5']\n",
    "\n",
    "# 定义一组自变量 (使用 IMCp 替换 InTraFlow，移除 Field_Eco)\n",
    "# !!! 注意: 'C_f_x_IMCp' 是模型中实际使用的变量名 !!!\n",
    "independent_vars = ['C_f_x_IMCp', 'Log_Team_size', 'Log_Patent_Count', 'Log_Fund',\n",
    "                    'Field_CS', 'Field_Eng','Crisis'] # 修改后的自变量\n",
    "\n",
    "# 检查列是否存在\n",
    "all_vars = list(set(dependent_vars + independent_vars)) # 更新使用的变量\n",
    "missing_cols = [col for col in all_vars if col not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\"错误: 以下列不存在于数据中: {missing_cols}\")\n",
    "    print(f\"可用的列: {data.columns.tolist()}\")\n",
    "    exit(1) # 如果关键列缺失则退出\n",
    "\n",
    "# 打印每个变量的基本信息\n",
    "print(\"\\n各变量缺失值情况:\")\n",
    "for col in all_vars:\n",
    "    if col in data.columns: # 再次确认列存在\n",
    "        na_count = data[col].isna().sum()\n",
    "        inf_count = np.isinf(data[col]).sum() if pd.api.types.is_numeric_dtype(data[col]) else 0\n",
    "        print(f\"{col}: 缺失值={na_count}, 无穷值={inf_count}\")\n",
    "    else:\n",
    "        # 理论上不应执行到这里，因为前面有检查\n",
    "        print(f\"{col}: 列不存在！\")\n",
    "\n",
    "\n",
    "# 执行回归分析并存储结果 (只执行前5个模型)\n",
    "results = []\n",
    "\n",
    "# 模型1-5: 使用 IMCp\n",
    "print(\"\\n开始执行回归分析 (模型 1-5, 使用 IMCp)...\")\n",
    "for i, dv in enumerate(dependent_vars):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"处理 Model {i+1}: {dv} (使用 IMCp)\")\n",
    "\n",
    "    # 为每个模型单独提取数据并处理缺失值\n",
    "    model_vars = [dv] + independent_vars\n",
    "    model_data = data[model_vars].copy()\n",
    "\n",
    "    # 打印处理前的样本量\n",
    "    print(f\"处理前样本量: {len(model_data)}\")\n",
    "\n",
    "    # 替换无穷值为NaN并删除缺失值\n",
    "    # 确保在替换前检查数据类型，避免对非数值列操作\n",
    "    numeric_cols = model_data.select_dtypes(include=np.number).columns\n",
    "    model_data[numeric_cols] = model_data[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    initial_rows = len(model_data)\n",
    "    model_data = model_data.dropna()\n",
    "    final_rows = len(model_data)\n",
    "    print(f\"因缺失值/无穷值移除的行数: {initial_rows - final_rows}\")\n",
    "    print(f\"处理后有效样本量: {final_rows}\")\n",
    "\n",
    "    if final_rows == 0:\n",
    "        print(f\"警告: Model {i+1} ({dv}) 清理后没有有效数据! 跳过此模型。\")\n",
    "        continue # 跳到下一个因变量\n",
    "\n",
    "    if final_rows < len(independent_vars) + 1: # 样本量少于变量数+1\n",
    "        print(f\"警告: Model {i+1} ({dv}) 的有效样本量 ({final_rows}) 过少，无法进行回归。跳过此模型。\")\n",
    "        continue\n",
    "\n",
    "    # 检查多重共线性\n",
    "    try:\n",
    "        # 确保只对数值型自变量计算VIF（分类变量如Field_XX通常排除或特殊处理）\n",
    "        # 这里假设 Field_CS, Field_Eng, Crisis 是 0/1 编码，可以包含\n",
    "        X_check_df = model_data[independent_vars]\n",
    "        # 检查是否存在非数值类型，理论上前面已过滤，但以防万一\n",
    "        if X_check_df.select_dtypes(exclude=np.number).shape[1] > 0:\n",
    "             print(\"警告：VIF 检查包含非数值列，可能导致错误。\")\n",
    "\n",
    "        X_check = sm.add_constant(X_check_df, has_constant='add') # 显式添加常数项\n",
    "        vif_data = pd.DataFrame()\n",
    "\n",
    "        # 检查是否存在方差为0的列（常数或近似常数列），这会导致VIF计算错误\n",
    "        # 计算VIF前排除常数项列\n",
    "        X_vif = X_check.drop('const', axis=1)\n",
    "        non_constant_cols_mask = X_vif.var() > 1e-8 # 允许非常小的方差\n",
    "\n",
    "        if not non_constant_cols_mask.all():\n",
    "            constant_vars = X_vif.columns[~non_constant_cols_mask].tolist()\n",
    "            print(f\"警告: VIF 计算检测到方差接近0的列: {constant_vars}。可能影响VIF结果或导致错误。\")\n",
    "            # 选择性地只计算非恒定列的VIF\n",
    "            X_vif_filtered = X_vif.loc[:, non_constant_cols_mask]\n",
    "            if X_vif_filtered.shape[1] > 1: # 至少需要两个（非共线）变量才能计算VIF\n",
    "                 vif_data[\"Variable\"] = X_vif_filtered.columns # 更新变量名以匹配\n",
    "                 vif_data[\"VIF\"] = [variance_inflation_factor(X_vif_filtered.values, j)\n",
    "                                   for j in range(X_vif_filtered.shape[1])]\n",
    "                 print(\"VIF值 (多重共线性检测，已移除零方差列):\")\n",
    "                 print(vif_data)\n",
    "            else:\n",
    "                 print(\"警告: 移除零方差列后，剩余变量不足以计算VIF。\")\n",
    "        else: # 所有列都有足够的方差\n",
    "            vif_data[\"Variable\"] = X_vif.columns\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, j)\n",
    "                               for j in range(X_vif.shape[1])]\n",
    "            print(\"VIF值 (多重共线性检测):\")\n",
    "            print(vif_data)\n",
    "            high_vif = vif_data[vif_data['VIF'] > 10] # 检查高VIF值\n",
    "            if not high_vif.empty:\n",
    "                print(\"\\n警告: 检测到高VIF值 (>10)，可能存在多重共线性问题:\")\n",
    "                print(high_vif)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 计算VIF时发生错误: {e}\")\n",
    "        # 可以在这里选择继续执行回归或跳过\n",
    "\n",
    "    # 执行OLS回归\n",
    "    y = model_data[dv]\n",
    "    X = sm.add_constant(model_data[independent_vars], has_constant='add') # 显式添加常数项\n",
    "    try:\n",
    "        model = sm.OLS(y, X).fit()\n",
    "\n",
    "        # 输出基本回归结果\n",
    "        print(f\"回归结果摘要:\")\n",
    "        print(f\"  R-squared: {model.rsquared:.4f}\")\n",
    "        print(f\"  Adj R-squared: {model.rsquared_adj:.4f}\")\n",
    "        print(f\"  F-statistic: {model.fvalue:.4f} (p-value: {model.f_pvalue:.4f})\")\n",
    "\n",
    "        # 提取结果\n",
    "        result = {\n",
    "            'Model': f\"Model {i+1}\",\n",
    "            'DV': dv,\n",
    "            # 'IV': 'IMCp', # 这个字段意义不大，因为自变量是固定的集合\n",
    "            'Coefficients': model.params, # Series, index是 'const', 'C_f_x_IMCp', ...\n",
    "            'P_values': model.pvalues,   # Series, index同上\n",
    "            'Std_Errors': model.bse,     # Series, index同上\n",
    "            'R_squared': model.rsquared,\n",
    "            'Adj_R_squared': model.rsquared_adj,\n",
    "            'F_statistic': model.fvalue,\n",
    "            'F_pvalue': model.f_pvalue,\n",
    "            'N': model.nobs\n",
    "        }\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 执行OLS回归时发生错误 for Model {i+1} ({dv}): {e}\")\n",
    "        print(\"可能的原因包括完全共线性（perfect multicollinearity）或数据问题。\")\n",
    "        continue # 跳到下一个模型\n",
    "\n",
    "# 检查是否有任何结果生成\n",
    "if not results:\n",
    "    print(\"\\n错误：没有成功生成任何模型结果。无法创建Excel文件。\")\n",
    "    exit(1)\n",
    "\n",
    "# --- 创建结果DataFrame ---\n",
    "output_file = 'Regression_Results_IMCp_Models_1_to_5.xlsx' # 修改输出文件名\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# --- 定义输出行的标签和对应的模型结果键名 ---\n",
    "# 这些是显示在 Excel 第一列的标签\n",
    "output_row_labels = ['Constant', 'IMCp'] + independent_vars[1:]\n",
    "# 这些是模型结果字典 ('result') 中对应的实际键名 (必须与模型输出匹配!)\n",
    "model_result_keys = ['const', 'C_f_x_IMCp'] + independent_vars[1:]\n",
    "\n",
    "# 确保两个列表长度一致 (除了最后的统计信息行)\n",
    "if len(output_row_labels) != len(model_result_keys):\n",
    "    print(\"错误：输出标签和模型结果键名数量不匹配！\")\n",
    "    print(f\"输出标签: {output_row_labels}\")\n",
    "    print(f\"模型结果键名: {model_result_keys}\")\n",
    "    exit(1)\n",
    "\n",
    "# 设置 Excel 第一列的显示名称\n",
    "result_df['Variable'] = output_row_labels + \\\n",
    "                        ['', 'Observations', 'R-squared', 'Adjusted R-squared', 'F-statistic', 'Prob > F']\n",
    "\n",
    "# --- 填充每个模型的结果 ---\n",
    "for result in results:\n",
    "    model_col = []\n",
    "\n",
    "    # 遍历我们定义的模型结果键名顺序\n",
    "    for key in model_result_keys:\n",
    "        # 检查这个实际的键名是否存在于模型结果中\n",
    "        if key in result['Coefficients'] and key in result['Std_Errors'] and key in result['P_values']:\n",
    "            coef = result['Coefficients'][key]\n",
    "            stderr = result['Std_Errors'][key]\n",
    "            pval = result['P_values'][key]\n",
    "\n",
    "            # 添加显著性星号\n",
    "            stars = ''\n",
    "            if pval < 0.01: stars = '***'\n",
    "            elif pval < 0.05: stars = '**'\n",
    "            elif pval < 0.1: stars = '*'\n",
    "\n",
    "            # 格式化系数和标准误\n",
    "            model_col.append(f\"{coef:.3f}{stars}\\n({stderr:.3f})\")\n",
    "        else:\n",
    "             # 如果某个变量（比如由于共线性被移除）不在结果中，则标记 N/A\n",
    "             print(f\"警告: 变量 '{key}' 在模型 {result['Model']} ({result['DV']}) 的结果中未找到。标记为 N/A。\")\n",
    "             model_col.append(\"N/A\")\n",
    "\n",
    "    # --- 添加统计信息行 ---\n",
    "    model_col.append('') # 空行\n",
    "    model_col.append(f\"{int(result['N'])}\")\n",
    "    model_col.append(f\"{result['R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['Adj_R_squared']:.3f}\")\n",
    "    model_col.append(f\"{result['F_statistic']:.3f}\")\n",
    "    # 对于非常小的p值，使用科学记数法或更小的阈值\n",
    "    f_pvalue_str = f\"{result['F_pvalue']:.6f}\"\n",
    "    if result['F_pvalue'] < 0.000001 and result['F_pvalue'] > 0:\n",
    "        f_pvalue_str = \"<0.000001\"\n",
    "    elif result['F_pvalue'] == 0: # 处理精确的0\n",
    "        f_pvalue_str = \"0.000000\"\n",
    "    elif pd.isna(result['F_pvalue']): # 处理 F p-value 为 NaN 的情况\n",
    "        f_pvalue_str = \"N/A\"\n",
    "\n",
    "    model_col.append(f_pvalue_str)\n",
    "\n",
    "    # 添加到结果DataFrame\n",
    "    result_df[f\"Model {result['Model'].split()[1]}\\n{result['DV']}\"] = model_col\n",
    "\n",
    "\n",
    "# --- 保存到Excel ---\n",
    "try:\n",
    "    result_df.to_excel(output_file, sheet_name='Regression Results', index=False)\n",
    "    print(f\"\\n初步结果已保存到 {output_file}\")\n",
    "except Exception as e:\n",
    "     print(f\"错误: 保存Excel文件 '{output_file}' 时失败: {e}\")\n",
    "     exit(1)\n",
    "\n",
    "\n",
    "# --- 格式化Excel文件 ---\n",
    "try:\n",
    "    wb = load_workbook(output_file)\n",
    "    ws = wb['Regression Results']\n",
    "\n",
    "    # 设置列宽和样式\n",
    "    for col_cells in ws.columns:\n",
    "        col_letter = col_cells[0].column_letter # 获取列字母\n",
    "        max_length = 0\n",
    "        for cell in col_cells:\n",
    "             try: # 防止对NoneType调用len\n",
    "                 cell_str = str(cell.value)\n",
    "                 # 处理包含换行符的单元格\n",
    "                 lines = cell_str.split('\\n')\n",
    "                 cell_max_len = max(len(line) for line in lines) if lines else 0\n",
    "                 if cell_max_len > max_length:\n",
    "                     max_length = cell_max_len\n",
    "             except:\n",
    "                 pass\n",
    "        # 调整宽度计算，给多行单元格更多空间，并设置最小宽度\n",
    "        adjusted_width = max(max_length + 5, 18 if col_letter != 'A' else 25) # 第一列宽一些\n",
    "        ws.column_dimensions[col_letter].width = adjusted_width\n",
    "\n",
    "    # 设置样式\n",
    "    header_font = Font(bold=True)\n",
    "    align_center = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "    align_left = Alignment(horizontal='left', vertical='center', wrap_text=True)\n",
    "    border = Border(left=Side(style='thin'), right=Side(style='thin'),\n",
    "                    top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "\n",
    "    # 应用样式\n",
    "    for row_idx, row in enumerate(ws.iter_rows(), 1): # 使用 iter_rows 获取行索引\n",
    "        for col_idx, cell in enumerate(row, 1):\n",
    "            cell.border = border\n",
    "\n",
    "            if row_idx == 1:  # 标题行\n",
    "                cell.font = header_font\n",
    "                cell.alignment = align_center\n",
    "            else:\n",
    "                if col_idx == 1:  # 变量名列\n",
    "                    # 对特定行（统计量行）也居中\n",
    "                    if cell.value in ['Observations', 'R-squared', 'Adjusted R-squared', 'F-statistic', 'Prob > F']:\n",
    "                        cell.alignment = align_center\n",
    "                    else: # 变量名左对齐\n",
    "                       cell.alignment = align_left\n",
    "                else: # 数据列居中\n",
    "                    cell.alignment = align_center\n",
    "\n",
    "    # 添加注释说明星号的含义\n",
    "    footnote_row = ws.max_row + 2\n",
    "    ws.cell(row=footnote_row, column=1, value=\"注: *** p<0.01, ** p<0.05, * p<0.1，括号内为标准误\")\n",
    "    # 合并脚注单元格以便阅读\n",
    "    ws.merge_cells(start_row=footnote_row, start_column=1, end_row=footnote_row, end_column=ws.max_column)\n",
    "    ws.cell(row=footnote_row, column=1).alignment = align_left # 左对齐脚注\n",
    "\n",
    "    # 保存格式化后的Excel\n",
    "    wb.save(output_file)\n",
    "\n",
    "    print(f\"回归结果已成功保存并格式化到 {output_file}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "     print(f\"错误: 无法加载 '{output_file}' 进行格式化。文件可能未成功创建。\")\n",
    "except Exception as e:\n",
    "     print(f\"错误: 格式化Excel文件时发生错误: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
